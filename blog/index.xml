<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blogs on Max Halford</title><link>https://maxhalford.github.io/blog/</link><description>Recent content in Blogs on Max Halford</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>maxhalford25@gmail.com (Max Halford)</managingEditor><webMaster>maxhalford25@gmail.com (Max Halford)</webMaster><lastBuildDate>Wed, 24 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://maxhalford.github.io/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Matrix inverse mini-batch updates</title><link>https://maxhalford.github.io/blog/matrix-inverse-mini-batch/</link><pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/matrix-inverse-mini-batch/</guid><description>The inverse covariance matrix, also called precision matrix, is useful in many places across the field of statistics. For instance, in machine learning, it is used for Bayesian regression and mixture modelling.
What&amp;rsquo;s interesting is that any batch model which uses a precision matrix can be turned into an online model. That is, provided the precision matrix can be estimated in a streaming fashion. For instance, scikit-learn&amp;rsquo;s elliptic envelope method could have an online variant with a partial_fit method.</description></item><item><title>A rant against dbt ref</title><link>https://maxhalford.github.io/blog/dbt-ref-rant/</link><pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/dbt-ref-rant/</guid><description>Disclaimer Let me be absolutely clear: I think dbt is a great tool. Although this post is a rant, the goal is to be constructive and suggest an improvement.
dbt in a nutshell dbt is a workflow orchestrator for SQL. In other words, it&amp;rsquo;s a fancy Make for data analytics. What makes dbt special is that it is the first workflow orchestrator that is dedicated to the SQL language. It said out loud what many data teams were thinking: you can get a lot done with SQL.</description></item><item><title>First IRL meetup with the River developers</title><link>https://maxhalford.github.io/blog/first-river-meetup/</link><pubDate>Thu, 09 Jun 2022 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/first-river-meetup/</guid><description>River is a Python software for doing online machine learning. It&amp;rsquo;s the result of a merger in early 2020 between creme and scikit-multiflow. Saulo Mastelini, Jacob Montiel, and myself are the three core developers. But there are many more people who contribute here and there!
This week Saulo Mastelini and I got to meet in person. This is worth mentioning because Saulo is originally from Brazil, whereas I&amp;rsquo;m based in Europe.</description></item><item><title>Fuzzy regex matching in Python</title><link>https://maxhalford.github.io/blog/fuzzy-regex-matching-in-python/</link><pubDate>Mon, 04 Apr 2022 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/fuzzy-regex-matching-in-python/</guid><description>Fuzzy string matching in a nutshell Say we&amp;rsquo;re looking for a pattern in a blob of text. If you know the text has no typos, then determining whether it contains a pattern is trivial. In Python you can use the in function. You can also write a regex pattern with the re module from the standard library. But what about if the text contains typos? For instance, this might be the case with user inputs on a website, or with OCR outputs.</description></item><item><title>OCR spelling correction is hard</title><link>https://maxhalford.github.io/blog/ocr-spelling-correction-is-hard/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/ocr-spelling-correction-is-hard/</guid><description>I recently saw SymSpell pop up on Hackernews. It claims to be a million times faster than Peter Norvig&amp;rsquo;s spelling corrector. I think it&amp;rsquo;s great that there&amp;rsquo;s a fast open source solution for spelling correction. But in my experience, the most challenging aspect of spelling correction is not necessarily speed.
When I worked at Alan, I mostly wrote logic to extract structured information from medical documents. After some months working on the topic, I have to admit I hadn&amp;rsquo;t cracked the problem.</description></item><item><title>Comic book panel segmentation</title><link>https://maxhalford.github.io/blog/comic-book-panel-segmentation/</link><pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/comic-book-panel-segmentation/</guid><description>I&amp;rsquo;ve recently been reading some comic books I used to devour as a kid. Especially those from the golden era of francophone comics: Thorgal, Lanfeust, XIII, Tintin, Largo Winch, Blacksad, Aldebaran, etc.
It&amp;rsquo;s not easy to get my hands on many of them. Luckily enough I found a website called ReadComicOnline which is delightfully profuse. It gives access to comics for free under the murky &amp;ldquo;fair use&amp;rdquo; copyright doctrine. I&amp;rsquo;m very doubtful about the legality of the website, but I&amp;rsquo;m still using it for lack of a better option.</description></item><item><title>The online machine learning predict/fit switcheroo</title><link>https://maxhalford.github.io/blog/predict-fit-switcheroo/</link><pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/predict-fit-switcheroo/</guid><description>Why I&amp;rsquo;m writing this Fact: designing open source software is hard. It&amp;rsquo;s difficult to make design decisions which don&amp;rsquo;t make any compromises. I like to fall back on Dieter Rams&amp;rsquo; 10 principles for good design. I feel like they apply rather well to software design. Especially when said software is open source, due to the many users and the plethora of use cases.
I had to make a significant design decision for River.</description></item><item><title>Weighted sampling without replacement in pure Python</title><link>https://maxhalford.github.io/blog/weighted-sampling-without-replacement/</link><pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/weighted-sampling-without-replacement/</guid><description>I&amp;rsquo;m working on a problem where I need to sample k items from a list without replacement. The sampling has to be weighted. In Python, numpy has random.choice method which allows doing this:
import numpy as np n = 10 k = 3 np.random.seed(42) population = np.arange(n) weights = np.random.dirichlet(np.ones_like(population)) np.random.choice(population, size=k, replace=False, p=weights) array([0, 9, 8]) I&amp;rsquo;m always wary of using numpy without thinking because I know it incurs some overhead.</description></item><item><title>Web scraping, upside down</title><link>https://maxhalford.github.io/blog/declarative-web-scraping/</link><pubDate>Thu, 11 Nov 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/declarative-web-scraping/</guid><description>Motivation Web scraping is the art of extracting information from web pages. A web page is essentially an amalgamation of HTML tags. Usually, we&amp;rsquo;re looking for a particular piece of information on a given web page. This may be done by fetching the HTML content of the page in question, and then running some HTML parsing logic. It&amp;rsquo;s quite straightforward.
There are many tools in the wild to perform web scraping.</description></item><item><title>One year at Alan</title><link>https://maxhalford.github.io/blog/one-year-at-alan/</link><pubDate>Tue, 26 Oct 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/one-year-at-alan/</guid><description>Context Today marks the 1 year anniversary since I started working at Alan. It&amp;rsquo;s my first real job, and certainly the place where I grew up the most professionally. I&amp;rsquo;m writing this post to summarise what I did and what I learnt at Alan.
Alan is a special company. It has a unique culture that is starting to become famous in France. I won&amp;rsquo;t expand on the way things work at Alan, and will simply focus on the way I experienced it.</description></item><item><title>Dashboards and GROUPING SETS</title><link>https://maxhalford.github.io/blog/grouping-sets/</link><pubDate>Fri, 10 Sep 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/grouping-sets/</guid><description>Motivation At Alan, we do almost all our data analysis in SQL. Our data warehouse used to be PostgreSQL, and have since switched to Snowflake for performance reasons. We load data into our warehouse with Airflow. This includes dumps of our production database, third-party data, and health data from other actors in the health ecosystem. This is raw data. We transform this into prepared data via an in-house tool that resembles dbt.</description></item><item><title>Homoglyphs: different characters that look identical</title><link>https://maxhalford.github.io/blog/homoglyphs/</link><pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/homoglyphs/</guid><description>A wild homoglyph appears For instance, can you tell if there&amp;rsquo;s a difference between H and Η? How about N and Ν? These characters may seem identical, but they are actually different. You can try this out for yourself in Python:
&amp;gt;&amp;gt;&amp;gt; &amp;#39;H&amp;#39; == &amp;#39;Η&amp;#39; False &amp;gt;&amp;gt;&amp;gt; &amp;#39;N&amp;#39; == &amp;#39;Ν&amp;#39; False Indeed, these all represent different Unicode characters:
&amp;gt;&amp;gt;&amp;gt; ord(&amp;#39;H&amp;#39;), ord(&amp;#39;Η&amp;#39;) (72, 919) &amp;gt;&amp;gt;&amp;gt; ord(&amp;#39;N&amp;#39;), ord(&amp;#39;Ν&amp;#39;) (78, 925) Η in fact represents the capital Eta letter, while Ν is a capital Nu.</description></item><item><title>Automated document processing at Alan</title><link>https://maxhalford.github.io/blog/medium-document-processing/</link><pubDate>Thu, 10 Jun 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/medium-document-processing/</guid><description/></item><item><title>Text classification by data compression</title><link>https://maxhalford.github.io/blog/text-classification-by-compression/</link><pubDate>Tue, 08 Jun 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/text-classification-by-compression/</guid><description>Edit: I posted this on Hackernews and got some valuable feedback. Many brought up the fact that you should be able to reuse the internal state of the compressor instead of recompressing the training data each time a prediction is made. There&amp;rsquo;s also some insightful references to data compression theory and its ties to statistical learning.
Last night I felt like reading Artificial Intelligence: A Modern Approach. I stumbled on something fun in the natural language processing chapter.</description></item><item><title>Reducing the memory footprint of a scikit-learn text classifier</title><link>https://maxhalford.github.io/blog/sklearn-text-classifier-memory-footprint-reduction/</link><pubDate>Sun, 11 Apr 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/sklearn-text-classifier-memory-footprint-reduction/</guid><description>Context This week at Alan I&amp;rsquo;ve been working on parsing French medical prescriptions. There are three types of prescriptions: lenses, glasses, and pharmaceutical prescriptions. Different information needs to be extracted depending on the prescription type. Therefore, the first step is to classify the prescription. The prescriptions we receive are pictures taken by users with their phone. We run each image through an OCR to obtain a text transcription of the image.</description></item><item><title>An overview of dataset time travel</title><link>https://maxhalford.github.io/blog/dataset-time-travel/</link><pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/dataset-time-travel/</guid><description>TLDR You&amp;rsquo;re a data scientist. The engineers in your company overwrite data in the production database. You want to access overwritten data to train your models. How?
I thought time travel only existed in the movies You&amp;rsquo;re probably right, expect maybe for this guy.
I want to discuss a concept that&amp;rsquo;s been on my mind for a while now. I like to call it &amp;ldquo;dataset time travel&amp;rdquo; because it has a nice ring to it.</description></item><item><title>Organising a Kaggle InClass competition with a fairness metric</title><link>https://maxhalford.github.io/blog/fairness-competition/</link><pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/fairness-competition/</guid><description>Some context I co-organised a data science competition during the second half of 2020. This was in fact the 5th edition of the &amp;ldquo;Défi IA&amp;rdquo;, which is a recurring event that happens on a yearly basis. It is essentially a supervised machine learning competition for students from French speaking universities and engineering schools. This year was the first time that Kaggle was used to host the competition. Before that we used a custom platform that I wrote during my student years.</description></item><item><title>Converting Amazon Textract tables to pandas DataFrames</title><link>https://maxhalford.github.io/blog/textract-table-to-pandas/</link><pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/textract-table-to-pandas/</guid><description>I&amp;rsquo;m currently doing a lot of document processing at work. One of my tasks is to extract tables from PDF files. I evaluated Amazon Textract&amp;rsquo;s table extraction capability as part of this task. It&amp;rsquo;s very well documented, as is the rest of Textract. I was slightly disappointed by the examples, but nothing serious.
I wanted to write this short blog post to share a piece of code I use to convert tables extracted through Amazon Textract to pandas.</description></item><item><title>What my PhD was about</title><link>https://maxhalford.github.io/blog/phd-about/</link><pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/phd-about/</guid><description>I defended my PhD thesis on the 12th of October 2020, exactly 3 years and 11 days after having started it. The title of my PhD is Machine learning for query selectivity estimation in relational databases. I thought it would be worthwhile to summarise what I did. Note sure anyone will read this, but at least I&amp;rsquo;ll be able to remember what I did when I grow old and senile.</description></item><item><title>Computing cross-correlations in SQL</title><link>https://maxhalford.github.io/blog/sql-cross-correlations/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/sql-cross-correlations/</guid><description>Introduction I&amp;rsquo;m currently working on a problem at work where I have to measure the impact of a growth initiative on a performance metric. Hypothetically, this might to answer the following kind of question:
I&amp;rsquo;ve spent X amount of money, what is the impact on the number of visitors on my website?
Of course, there are many measures that can be taken to answer such a question. I decided to measure the correlation between the initiative and the metric, with the latter being shifted forward in time.</description></item><item><title>Unsupervised text classification with word embeddings</title><link>https://maxhalford.github.io/blog/unsupervised-text-classification/</link><pubDate>Sat, 03 Oct 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/unsupervised-text-classification/</guid><description>Addendum: since writing this article, I have discovered that the method I describe is a form of zero-shot learning. So I guess you could say that this article is a tutorial on zero-shot learning for NLP.
I recently watched a lecture by Adam Tauman Kalai on stereotype bias in text data. The lecture is very good, but something that had nothing to do with the lecture&amp;rsquo;s main topic caught my attention.</description></item><item><title>Focal loss implementation for LightGBM</title><link>https://maxhalford.github.io/blog/lightgbm-focal-loss/</link><pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/lightgbm-focal-loss/</guid><description>Edit &amp;ndash; 2021-01-26
I initially wrote this blog post using version 2.3.1 of LightGBM. I&amp;rsquo;ve now updated it to use version 3.1.1. There are a couple of subtle but important differences between version 2.x.y and 3.x.y. If you&amp;rsquo;re using version 2.x.y, then I strongly recommend you to upgrade to version 3.x.y.
Motivation If you&amp;rsquo;re reading this blog post, then you&amp;rsquo;re likely to be aware of LightGBM. The latter is a best of breed gradient boosting library.</description></item><item><title>A few intermediate pandas tricks</title><link>https://maxhalford.github.io/blog/pandas-tricks/</link><pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/pandas-tricks/</guid><description>I want to use this post to share some pandas snippets that I find useful. I use them from time to time, in particular when I&amp;rsquo;m doing time series competitions on platforms such as Kaggle. Like any data scientist, I perform similar data processing steps on different datasets. Usually, I put repetitive patterns in xam, which is my personal data science toolbox. However, I think that the following snippets are too small and too specific for being added into a library.</description></item><item><title>The correct way to evaluate online machine learning models</title><link>https://maxhalford.github.io/blog/online-learning-evaluation/</link><pubDate>Sun, 07 Jun 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/online-learning-evaluation/</guid><description>Motivation Most supervised machine learning algorithms work in the batch setting, whereby they are fitted on a training set offline, and are used to predict the outcomes of new samples. The only way for batch machine learning algorithms to learn from new samples is to train them from scratch with both the old samples and the new ones. Meanwhile, some learning algorithms are online, and can predict as well as update themselves when new samples are available.</description></item><item><title>Server-sent events in Flask without extra dependencies</title><link>https://maxhalford.github.io/blog/flask-sse-no-deps/</link><pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/flask-sse-no-deps/</guid><description>Server-sent events (SSE) is a mechanism for sending updates from a server to a client. The fundamental difference with WebSockets is that the communication only goes in one direction. In other words, the client cannot send information to the server. For many usecases this is all you might need. Indeed, if you just want to receive notifications/updates/messages, then using a WebSocket is overkill. Once you&amp;rsquo;ve implemented the SSE functionality on your server, then all you need on a JavaScript client is an EventSource.</description></item><item><title>I got plagiarized and Google didn't help</title><link>https://maxhalford.github.io/blog/plagiarism-google-didnt-help/</link><pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/plagiarism-google-didnt-help/</guid><description>One of my most popular articles is the one on target encoding. It gets a fair amount of mentions on Kaggle discussions and I see it pop up from time to time in other contexts. It also brings me around 2500 unique monthly viewers. That&amp;rsquo;s quite a chunk of people for an unambitious blogger like me. Up to a few months ago, my article was on the first page of Google when you typed in searches such as &amp;ldquo;target encoding python&amp;rdquo; and &amp;ldquo;bayesian target encoding&amp;rdquo;.</description></item><item><title>Speeding up scikit-learn for single predictions</title><link>https://maxhalford.github.io/blog/speeding-up-sklearn-single-predictions/</link><pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/speeding-up-sklearn-single-predictions/</guid><description>It is now common practice to train machine learning models offline before putting them behind an API endpoint to serve predictions. Specifically, we want an API route which can make a prediction for a single row/instance/sample/data point/individual (call it what you want). Nowadays, we have great tools to do this that care of the nitty-gritty details, such as Cortex, MLFlow, Kubeflow, and Clipper. There are also paid services that hold your hand a bit more, such as DataRobot, H2O, and Cubonacci.</description></item><item><title>Machine learning for streaming data with creme</title><link>https://maxhalford.github.io/blog/medium-creme/</link><pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/medium-creme/</guid><description/></item><item><title>Bayesian linear regression for practitioners</title><link>https://maxhalford.github.io/blog/bayesian-linear-regression/</link><pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/bayesian-linear-regression/</guid><description>Motivation Suppose you have an infinite stream of feature vectors $x_i$ and targets $y_i$. In this case, $i$ denotes the order in which the data arrives. If you&amp;rsquo;re doing supervised learning, then your goal is to estimate $y_i$ before it is revealed to you. In order to do so, you have a model which is composed of parameters denoted $\theta_i$. For instance, $\theta_i$ represents the feature weights when using linear regression.</description></item><item><title>Under-sampling a dataset with desired ratios</title><link>https://maxhalford.github.io/blog/undersampling-ratios/</link><pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/undersampling-ratios/</guid><description>Introduction I&amp;rsquo;ve just spent a few hours looking at under-sampling and how it can help a classifier learn from an imbalanced dataset. The idea is quite simple: randomly sample the majority class and leave the minority class untouched. There are more sophisticated ways to do this &amp;ndash; for instance by creating synthetic observations from the minority class à la SMOTE &amp;ndash; but I won&amp;rsquo;t be discussing that here.
I checked out the imblearn library and noticed they have an implementation of random under-sampling aptly named RandomUnderSampler.</description></item><item><title>Finding fuzzy duplicates with pandas</title><link>https://maxhalford.github.io/blog/transitive-duplicates/</link><pubDate>Mon, 16 Sep 2019 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/transitive-duplicates/</guid><description>Duplicate detection is the task of finding two or more instances in a dataset that are in fact identical. As an example, take the following toy dataset:
First name Last name Email 0 Erlich Bachman eb@piedpiper.com 1 Erlich Bachmann eb@piedpiper.com 2 Erlik Bachman eb@piedpiper.co 3 Erlich Bachmann eb@piedpiper.com Each of these instances (rows, if you prefer) corresponds to the same &amp;ldquo;thing&amp;rdquo; &amp;ndash; note that I&amp;rsquo;m not using the word &amp;ldquo;entity&amp;rdquo; because entity resolution is a different, and yet related, concept.</description></item><item><title>A smooth approach to putting machine learning into production</title><link>https://maxhalford.github.io/blog/machine-learning-production/</link><pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/machine-learning-production/</guid><description>Putting machine learning into production is hard. Usually I&amp;rsquo;m doubtful of such statements, but in this case I&amp;rsquo;ve never met anyone for whom everything has gone smoothly. Most data scientists might agree that there is a huge gap between their local environment and a live environment. In fact, &amp;ldquo;productionalizing&amp;rdquo; machine learning is such a complex topic that entire companies have risen to address the issue. I&amp;rsquo;m not just talking about running a gigantic grid search and finding the best model, I&amp;rsquo;m talking about putting a machine learning model live so that it actually has a positive impact on your business/project.</description></item><item><title>Skyline queries in Python</title><link>https://maxhalford.github.io/blog/skyline-queries/</link><pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/skyline-queries/</guid><description>Imagine that you&amp;rsquo;re looking to buy a home. If you have an analytical mind then you might want to tackle this with a quantitative. Let&amp;rsquo;s suppose that you have a list of potential homes, and each home has some attributes that can help you compare them. As an example, we&amp;rsquo;ll consider three attributes:
The price of the house, which you want to minimize The size of the house, which you want to maximize The city where the house if located, which you don&amp;rsquo;t really care about Some houses will be objectively better than others because they will be cheaper and bigger.</description></item><item><title>SQL subquery enumeration</title><link>https://maxhalford.github.io/blog/sql-subquery-enumeration/</link><pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/sql-subquery-enumeration/</guid><description>I recently stumbled on a rather fun problem during my PhD. I wanted to generate all possible subqueries from a given SQL query. In this case an example is easily worth a 1000 thousand words. Take the following SQL query:
SELECT * FROM customers AS c, purchases AS p, shops AS s WHERE p.customer_id = c.id AND p.shop_id = s.id AND c.nationality = &amp;#39;Swedish&amp;#39; AND c.hair = &amp;#39;Blond&amp;#39; AND s.city = &amp;#39;Stockholm&amp;#39; Here all the possible subqueries that can be generated from the above query.</description></item><item><title>Morellet crosses with JavaScript</title><link>https://maxhalford.github.io/blog/morellet/</link><pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/morellet/</guid><description>The days I&amp;rsquo;m working on a deep learning project. I hate it but I promised myself to give it a real try. My scripts are taking a long time so I decided to do some procedural art while I waited. This time I&amp;rsquo;m going to reproduce the following crosses made by François Morellet. I saw them the last I went to the Musée Pompidou with some friends from university. I don&amp;rsquo;t have any smartphone anymore so one my friends was kind enough to take a few pictures for me, including this one.</description></item><item><title>Streaming groupbys in pandas for big datasets</title><link>https://maxhalford.github.io/blog/pandas-streaming-groupby/</link><pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/pandas-streaming-groupby/</guid><description>If you&amp;rsquo;ve done a bit of Kaggling, then you&amp;rsquo;ve probably been typing a fair share of df.groupby(some_col). That is, if you&amp;rsquo;re using Python. If you&amp;rsquo;re handling tabular data, then a lot of your features will revolve around computing aggregate statistics. This is very true for the ongoing PLAsTiCC Astronomical Classification challenge. The goal of the competition is to classify objects in the sky into one of 14 groups. The bulk of the available data is a set of so-called light curve.</description></item><item><title>Target encoding done the right way</title><link>https://maxhalford.github.io/blog/target-encoding/</link><pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/target-encoding/</guid><description>When you&amp;rsquo;re doing supervised learning, you often have to deal with categorical variables. That is, variables which don&amp;rsquo;t have a natural numerical representation. The problem is that most machine learning algorithms require the input data to be numerical. At some point or another a data science pipeline will require converting categorical variables to numerical variables.
There are many ways to do so:
Label encoding where you choose an arbitrary number for each category One-hot encoding where you create one binary column per category Vector representation a.</description></item><item><title>Stella triangles with JavaScript</title><link>https://maxhalford.github.io/blog/stella-triangles/</link><pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/stella-triangles/</guid><description>Around the same time last year I visited the San Francisco Museum of Modern Art. Frank Stella&amp;rsquo;s compositions really caught my eye. When I saw them I started thinking about how I could write a computer program to imitate his work. In this post I&amp;rsquo;m going to attempt to reproduce his so-called V Series.
Nice and simple right? Indeed in a lot of his work Frank Stella uses straight lines without much randomness.</description></item><item><title>Unknown pleasures with JavaScript</title><link>https://maxhalford.github.io/blog/unknown-pleasures/</link><pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/unknown-pleasures/</guid><description>No this blog post is not about how nice JavaScript can be, instead it&amp;rsquo;s just another one of my attempts at reproducing modern art with procedural generation and the HTML5 &amp;lt;canvas&amp;gt; element. This time I randomly generated images resembling the cover of the album by Joy Division called &amp;ldquo;Unknown Pleasures&amp;rdquo;.
According to Wikipedia, this somewhat iconic album cover is based on radio waves. I saw a poster of it in a bar not long ago and decided to reproduce the next time I had some time to kill.</description></item><item><title>Subsampling a training set to match a test set - Part 1</title><link>https://maxhalford.github.io/blog/subsampling-1/</link><pubDate>Mon, 19 Jun 2017 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/subsampling-1/</guid><description>Some friends and I recently qualified for the final of the 2017 edition of the Data Science Game competition. The first part was a Kaggle competition with data provided by Deezer. The problem was a binary classification task where one had to predict if a user was going to listen to a song that was proposed to him. Like many teams we extracted clever features and trained an XGBoost classifier, classic.</description></item><item><title>Halftoning with Go - Part 2</title><link>https://maxhalford.github.io/blog/halftoning-2/</link><pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/halftoning-2/</guid><description>The next stop on my travel through the world of halftoning will be the implementation of Weighted Voronoi Stippling as described in Adrian Secord&amp;rsquo;s 2002 paper. This method is more involved than the ones I detailed in my previous blog post, however the results are quite interesting. Again, I did the implementation in Go.
Notice the black dot in the middle of the white square? Overview I found a fair amount of resources about the method, most of them being implementations of Adrian Secord&amp;rsquo;s paper.</description></item><item><title>Grid paintings à la Mondrian with JavaScript</title><link>https://maxhalford.github.io/blog/mondrian/</link><pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/mondrian/</guid><description>I was at a laundrette today and had just finished my book so I had some time to kill. Naturally I devised an algorithm for generating drawings that would resemble the grid-like paintings that Piet Mondrian made famous. With the benefit of hindsight I guess I could indulge in saner activities while waiting for my laundry to dry!
I went through different ideas but in the end I settled on a recursive approach.</description></item><item><title>A short introduction and conclusion to the OpenBikes 2016 Challenge</title><link>https://maxhalford.github.io/blog/openbikes-challenge/</link><pubDate>Thu, 26 Jan 2017 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/openbikes-challenge/</guid><description>During my undergraduate internship in 2015 I started a side project called OpenBikes. The idea was to visualize and analyze bike sharing over multiple cities. Axel Bellec joined me and in 2016 we won a national open data competition. Since then we haven&amp;rsquo;t pursued anything major, instead we use OpenBikes to try out technologies and to apply concepts we learn at university and online.
Before the 2016 summer holidays one of my professors, Aurélien Garivier mentioned that he was considering using our data for a Kaggle-like competition between some statistics curriculums in France.</description></item><item><title>Halftoning with Go - Part 1</title><link>https://maxhalford.github.io/blog/halftoning-1/</link><pubDate>Sun, 27 Nov 2016 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/halftoning-1/</guid><description>Recently I stumbled upon this webpage which shows how to use a TSP solver as a halftoning technique. I began to read about related concepts like dithering and stippling. I don&amp;rsquo;t have any background in photography but I can appreciate the visual appeal of these techniques. As I understand it these techniques were first invented to save ink for printing. However nowadays printing has become cheaper and the modern use of these technique is mostly aesthetic, at least for images.</description></item><item><title>Recursive polygons with JavaScript</title><link>https://maxhalford.github.io/blog/recursive-polygons/</link><pubDate>Fri, 25 Mar 2016 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/recursive-polygons/</guid><description>I like modern art, I enjoy looking at the stuff that was made at the beginning of the 20th century and thinking how it is still shaping today&amp;rsquo;s style. I&amp;rsquo;m not an expert, it&amp;rsquo;s just a hobby of mine. I especially like the Centre Pompidou in Paris, it&amp;rsquo;s got loads of fascinating stuff. While I was going through the galleries it struck me that some of the paintings were very geometrical.</description></item><item><title>The Naïve Bayes classifier</title><link>https://maxhalford.github.io/blog/naive-bayes/</link><pubDate>Thu, 10 Sep 2015 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/naive-bayes/</guid><description>The objective of a classifier is to decide to which class (also called label) to assign an observation based on observed data. In supervised learning, this is done by taking into account previous classifications. In other words if we know that certain observations are classified in a certain way, the goal is to determine the class of a new observation. The first group of observations on which the classifier is built is called the training set.</description></item><item><title>An introduction to genetic algorithms</title><link>https://maxhalford.github.io/blog/genetic-algorithms-introduction/</link><pubDate>Sun, 02 Aug 2015 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/genetic-algorithms-introduction/</guid><description>The goal of genetic algorithms (GAs) is to solve problems whose solutions are not easily found (ie. NP problems, nonlinear optimization, etc.). For example, finding the shortest path from A to B in a directed graph is easily done with Djikstra&amp;rsquo;s algorithm, it can be solved in polynomial time. However the time to find the smallest path that joins all points on a non-directed graph, also known as the Travelling Salesman Problem (TSP) increases exponentially as the number of points increases.</description></item><item><title>Setting up a droplet to host a Flask app</title><link>https://maxhalford.github.io/blog/flask-droplet/</link><pubDate>Tue, 14 Jul 2015 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/flask-droplet/</guid><description>After having worked for some weeks on the OpenBikes website, it was time to put it online. Digital Ocean seemed to provide a good service and so I decided to give it a spin. Their documentation is quite good but it doesn&amp;rsquo;t cover exactly everything for setting up Flask. In this post I simply want to record every single step I took.
OpenBikes is a project with a Flask backend and a few upstart jobs.</description></item><item><title>Visualizing bike stations live data</title><link>https://maxhalford.github.io/blog/bike-stations/</link><pubDate>Wed, 03 Jun 2015 00:00:00 +0000</pubDate><author>maxhalford25@gmail.com (Max Halford)</author><guid>https://maxhalford.github.io/blog/bike-stations/</guid><description>Recently some friends and I decided to launch openbikes.co, a website for visualizing (and later on analyzing) urban bike traffic. We have a lot of ideas that we will progressively implement. Anyway, the point is that all of it started with me fiddling about with the JCDecaux API and the leaflet.js library and I would like to share it with you. Shall we?
Presentation In this post I want to show you the tools and the code to get a fully functional website for visualizing live data.</description></item></channel></rss>