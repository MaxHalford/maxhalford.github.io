<!doctype html><html lang=en><head><script async defer data-website-id=6023252a-3a97-470f-b4ee-5082d242bb9a src=https://umami.pourtan.eu/umami.js></script><meta charset=utf-8><meta name=generator content="Hugo 0.98.0"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Max Halford"><meta property="og:url" content="https://maxhalford.github.io/blog/fairness-competition/"><link rel=canonical href=https://maxhalford.github.io/blog/fairness-competition/><link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü¶î</text></svg>"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maxhalford.github.io\/"},"articleSection":"blog","name":"Organising a Kaggle InClass competition with a fairness metric","headline":"Organising a Kaggle InClass competition with a fairness metric","description":"Some context I co-organised a data science competition during the second half of 2020. This was in fact the 5th edition of the \u0026ldquo;D√©fi IA\u0026rdquo;, which is a recurring event that happens on a yearly basis. It is essentially a supervised machine learning competition for students from French speaking universities and engineering schools. This year was the first time that Kaggle was used to host the competition. Before that we used a custom platform that I wrote during my student years.","inLanguage":"en-US","author":"Max Halford","creator":"Max Halford","publisher":"Max Halford","accountablePerson":"Max Halford","copyrightHolder":"Max Halford","copyrightYear":"2021","datePublished":"2021-01-21 00:00:00 \u002b0000 UTC","dateModified":"2021-01-21 00:00:00 \u002b0000 UTC","url":"https:\/\/maxhalford.github.io\/blog\/fairness-competition\/","keywords":[]}</script><title>Organising a Kaggle InClass competition with a fairness metric ‚Ä¢ Max Halford</title><meta property="og:title" content="Organising a Kaggle InClass competition with a fairness metric ‚Ä¢ Max Halford"><meta property="og:type" content="article"><meta name=description content="Some context I co-organised a data science competition during the second half of 2020. This was in fact the 5th edition of the &ldquo;D√©fi IA&rdquo;, which is a recurring event that happens on a yearly basis. It is essentially a supervised machine learning competition for students from French speaking universities and engineering schools. This year was the first time that Kaggle was used to host the competition. Before that we used a custom platform that I wrote during my student years."><link rel=stylesheet href=/css/flexboxgrid-6.3.1.min.css><link rel=stylesheet href=/css/github-markdown.min.css><link rel=stylesheet href=/css/highlight/github.css><link rel=stylesheet href=/css/index.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=PT+Serif:wght@400;700&family=Permanent+Marker&display=swap" rel=stylesheet><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><article class=post id=article><div class="row center-xs" style=text-align:left><div class="col-xs-12 col-sm-10 col-md-7 col-lg-5"><div class=post-header><header><div class="signatures site-title"><a href=/>Max Halford „ÉÑ</a></div></header><div class="row end-xs"><div><a class=header-link href=/>Blog</a>
<a class=header-link href=/links/>Links</a>
<a class=header-link href=/bio/>Bio</a></div></div><div class=header-line></div></div><header class=post-header><h1 class=post-title>Organising a Kaggle InClass competition with a fairness metric</h1><div class="row post-desc"><div class=col-xs-12><time class=post-date datetime="2021-01-21 00:00:00 UTC">2021-01-21 ¬∑ 3825 words</time></div></div></header><div class="post-content markdown-body"><h2 id=toc>Table of contents</h2><nav id=TableOfContents><ul><li><a href=#some-context>Some context</a></li><li><a href=#the-fairness-metric>The fairness metric</a></li><li><a href=#what-people-did>What people did</a></li><li><a href=#rankings>Rankings</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav><h2 id=some-context>Some context</h2><p>I co-organised a data science competition during the second half of 2020. This was in fact the 5th edition of the &ldquo;D√©fi IA&rdquo;, which is a recurring event that happens on a yearly basis. It is essentially a supervised machine learning competition for students from French speaking universities and engineering schools. This year was the first time that Kaggle was used to host the competition. Before that we used a custom platform that I wrote during my student years. You can read more about this <a href=/blog/openbikes-challenge>here</a>.</p><p>I&rsquo;m not going to go into a lot of depth with regards to the competition details, si√πply because everything is <a href=https://www.kaggle.com/c/defi-ia-insa-toulouse/overview>already explained on Kaggle</a>. In a nutshell, the goal of the competition is to predict a person&rsquo;s job from their bio. A bio is a short description of said person. For instance, the following job description corresponds to a professor:</p><blockquote><p>She is also a Ronald D. Asmus Policy Entrepreneur Fellow with the German Marshall Fund and is a Visiting Fellow at the Centre for International Studies (CIS) at the University of Oxford. This commentary first appeared at Sada, an online journal published by the Carnegie Endowment for International Peace.</p></blockquote><p>Along with the bio and the job title, we also know each person&rsquo;s gender. For the sake of simplicity we only considered cisgender people, and not LGBTQIA+ people. We also only included 20 different jobs. Note that we obtained our data following the opensource code provided with the 2019 Microsoft paper entitled <a href=https://www.microsoft.com/en-us/research/publication/bias-in-bios-a-case-study-of-semantic-representation-bias-in-a-high-stakes-setting/><em>Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting</em></a>.</p><p>In the above example, it&rsquo;s quite easy to guess that the bio corresponds to a professor. Words such as &ldquo;university&rdquo; and &ldquo;published&rdquo; are highly indicative of a professor. In my perception of reality, a university professor isn&rsquo;t necessarily associated with any gender in particular. This gut feeling is verified if we look at the competition data:</p><table><thead><tr><th style=text-align:left>category</th><th style=text-align:left>part</th><th style=text-align:left>female</th><th style=text-align:left>male</th></tr></thead><tbody><tr><td style=text-align:left>accountant</td><td style=text-align:left>test</td><td style=text-align:left>40.69%</td><td style=text-align:left>59.31%</td></tr><tr><td style=text-align:left>accountant</td><td style=text-align:left>train</td><td style=text-align:left>36.17%</td><td style=text-align:left>63.83%</td></tr><tr><td style=text-align:left>architect</td><td style=text-align:left>test</td><td style=text-align:left>24.21%</td><td style=text-align:left>75.79%</td></tr><tr><td style=text-align:left>architect</td><td style=text-align:left>train</td><td style=text-align:left>22.50%</td><td style=text-align:left>77.50%</td></tr><tr><td style=text-align:left>attorney</td><td style=text-align:left>test</td><td style=text-align:left>37.77%</td><td style=text-align:left>62.23%</td></tr><tr><td style=text-align:left>attorney</td><td style=text-align:left>train</td><td style=text-align:left>37.76%</td><td style=text-align:left>62.24%</td></tr><tr><td style=text-align:left>chiropractor</td><td style=text-align:left>test</td><td style=text-align:left>28.92%</td><td style=text-align:left>71.08%</td></tr><tr><td style=text-align:left>chiropractor</td><td style=text-align:left>train</td><td style=text-align:left>27.81%</td><td style=text-align:left>72.19%</td></tr><tr><td style=text-align:left>comedian</td><td style=text-align:left>test</td><td style=text-align:left>21.91%</td><td style=text-align:left>78.09%</td></tr><tr><td style=text-align:left>comedian</td><td style=text-align:left>train</td><td style=text-align:left>21.05%</td><td style=text-align:left>78.95%</td></tr><tr><td style=text-align:left>composer</td><td style=text-align:left>test</td><td style=text-align:left>16.57%</td><td style=text-align:left>83.43%</td></tr><tr><td style=text-align:left>composer</td><td style=text-align:left>train</td><td style=text-align:left>16.29%</td><td style=text-align:left>83.71%</td></tr><tr><td style=text-align:left>dentist</td><td style=text-align:left>test</td><td style=text-align:left>34.85%</td><td style=text-align:left>65.15%</td></tr><tr><td style=text-align:left>dentist</td><td style=text-align:left>train</td><td style=text-align:left>34.77%</td><td style=text-align:left>65.23%</td></tr><tr><td style=text-align:left>dietitian</td><td style=text-align:left>test</td><td style=text-align:left>92.74%</td><td style=text-align:left>7.26%</td></tr><tr><td style=text-align:left>dietitian</td><td style=text-align:left>train</td><td style=text-align:left>92.66%</td><td style=text-align:left>7.34%</td></tr><tr><td style=text-align:left>dj</td><td style=text-align:left>test</td><td style=text-align:left>14.80%</td><td style=text-align:left>85.20%</td></tr><tr><td style=text-align:left>dj</td><td style=text-align:left>train</td><td style=text-align:left>15.04%</td><td style=text-align:left>84.96%</td></tr><tr><td style=text-align:left>filmmaker</td><td style=text-align:left>test</td><td style=text-align:left>30.63%</td><td style=text-align:left>69.37%</td></tr><tr><td style=text-align:left>filmmaker</td><td style=text-align:left>train</td><td style=text-align:left>33.80%</td><td style=text-align:left>66.20%</td></tr><tr><td style=text-align:left>interior_designer</td><td style=text-align:left>test</td><td style=text-align:left>78.04%</td><td style=text-align:left>21.96%</td></tr><tr><td style=text-align:left>interior_designer</td><td style=text-align:left>train</td><td style=text-align:left>80.89%</td><td style=text-align:left>19.11%</td></tr><tr><td style=text-align:left>journalist</td><td style=text-align:left>test</td><td style=text-align:left>48.60%</td><td style=text-align:left>51.40%</td></tr><tr><td style=text-align:left>journalist</td><td style=text-align:left>train</td><td style=text-align:left>49.80%</td><td style=text-align:left>50.20%</td></tr><tr><td style=text-align:left>model</td><td style=text-align:left>test</td><td style=text-align:left>77.81%</td><td style=text-align:left>22.19%</td></tr><tr><td style=text-align:left>model</td><td style=text-align:left>train</td><td style=text-align:left>82.58%</td><td style=text-align:left>17.42%</td></tr><tr><td style=text-align:left>nurse</td><td style=text-align:left>test</td><td style=text-align:left>91.03%</td><td style=text-align:left>8.97%</td></tr><tr><td style=text-align:left>nurse</td><td style=text-align:left>train</td><td style=text-align:left>91.06%</td><td style=text-align:left>8.94%</td></tr><tr><td style=text-align:left>painter</td><td style=text-align:left>test</td><td style=text-align:left>45.45%</td><td style=text-align:left>54.55%</td></tr><tr><td style=text-align:left>painter</td><td style=text-align:left>train</td><td style=text-align:left>46.12%</td><td style=text-align:left>53.88%</td></tr><tr><td style=text-align:left>paralegal</td><td style=text-align:left>test</td><td style=text-align:left>86.46%</td><td style=text-align:left>13.54%</td></tr><tr><td style=text-align:left>paralegal</td><td style=text-align:left>train</td><td style=text-align:left>84.18%</td><td style=text-align:left>15.82%</td></tr><tr><td style=text-align:left>pastor</td><td style=text-align:left>test</td><td style=text-align:left>24.10%</td><td style=text-align:left>75.90%</td></tr><tr><td style=text-align:left>pastor</td><td style=text-align:left>train</td><td style=text-align:left>24.05%</td><td style=text-align:left>75.95%</td></tr><tr><td style=text-align:left>personal_trainer</td><td style=text-align:left>test</td><td style=text-align:left>42.72%</td><td style=text-align:left>57.28%</td></tr><tr><td style=text-align:left>personal_trainer</td><td style=text-align:left>train</td><td style=text-align:left>45.11%</td><td style=text-align:left>54.89%</td></tr><tr><td style=text-align:left>photographer</td><td style=text-align:left>test</td><td style=text-align:left>35.18%</td><td style=text-align:left>64.82%</td></tr><tr><td style=text-align:left>photographer</td><td style=text-align:left>train</td><td style=text-align:left>35.02%</td><td style=text-align:left>64.98%</td></tr><tr><td style=text-align:left>physician</td><td style=text-align:left>test</td><td style=text-align:left>40.45%</td><td style=text-align:left>59.55%</td></tr><tr><td style=text-align:left>physician</td><td style=text-align:left>train</td><td style=text-align:left>39.47%</td><td style=text-align:left>60.53%</td></tr><tr><td style=text-align:left>poet</td><td style=text-align:left>test</td><td style=text-align:left>47.77%</td><td style=text-align:left>52.23%</td></tr><tr><td style=text-align:left>poet</td><td style=text-align:left>train</td><td style=text-align:left>50.16%</td><td style=text-align:left>49.84%</td></tr><tr><td style=text-align:left>professor</td><td style=text-align:left>test</td><td style=text-align:left>45.50%</td><td style=text-align:left>54.50%</td></tr><tr><td style=text-align:left>professor</td><td style=text-align:left>train</td><td style=text-align:left>44.88%</td><td style=text-align:left>55.12%</td></tr><tr><td style=text-align:left>psychologist</td><td style=text-align:left>test</td><td style=text-align:left>61.96%</td><td style=text-align:left>38.04%</td></tr><tr><td style=text-align:left>psychologist</td><td style=text-align:left>train</td><td style=text-align:left>61.76%</td><td style=text-align:left>38.24%</td></tr><tr><td style=text-align:left>rapper</td><td style=text-align:left>test</td><td style=text-align:left>12.25%</td><td style=text-align:left>87.75%</td></tr><tr><td style=text-align:left>rapper</td><td style=text-align:left>train</td><td style=text-align:left>8.17%</td><td style=text-align:left>91.83%</td></tr><tr><td style=text-align:left>software_engineer</td><td style=text-align:left>test</td><td style=text-align:left>16.06%</td><td style=text-align:left>83.94%</td></tr><tr><td style=text-align:left>software_engineer</td><td style=text-align:left>train</td><td style=text-align:left>15.10%</td><td style=text-align:left>84.90%</td></tr><tr><td style=text-align:left>surgeon</td><td style=text-align:left>test</td><td style=text-align:left>14.16%</td><td style=text-align:left>85.84%</td></tr><tr><td style=text-align:left>surgeon</td><td style=text-align:left>train</td><td style=text-align:left>13.45%</td><td style=text-align:left>86.55%</td></tr><tr><td style=text-align:left>teacher</td><td style=text-align:left>test</td><td style=text-align:left>58.43%</td><td style=text-align:left>41.57%</td></tr><tr><td style=text-align:left>teacher</td><td style=text-align:left>train</td><td style=text-align:left>59.27%</td><td style=text-align:left>40.73%</td></tr><tr><td style=text-align:left>yoga_teacher</td><td style=text-align:left>test</td><td style=text-align:left>80.57%</td><td style=text-align:left>19.43%</td></tr><tr><td style=text-align:left>yoga_teacher</td><td style=text-align:left>train</td><td style=text-align:left>85.06%</td><td style=text-align:left>14.94%</td></tr></tbody></table><p>Other jobs are more polarised. For instance, rappers are mostly men and yoga teachers are typically women. This is just the way things are in modern western societies. I am in no position to say if this state of things is good or bad. What I do know is that machine learning models replicate the bias that can be found in data in their predictions. Machine learning models are meant to be accurate, and therefore would rely on gendered words such as &ldquo;she&rdquo; and &ldquo;his&rdquo; to make their predictions. Machine learning is very pragmatic that way.</p><p>For whatever reason, we might want to build models that don&rsquo;t exploit gender to make a prediction. We might want to do this because as a society we believe that each gender should be equally represented in each job &ndash; note that I&rsquo;m not expressing an opinion. To do so we may want to break the negative reinforcement loop that automated decisions would entail. Concretely, we could prefer to have a decision process that is less accurate while being fairer. There is a whole area of research called <a href=https://www.wikiwand.com/en/Fairness_(machine_learning)>fair learning</a> that tackles these questions.</p><p>Fair learning is very exciting, and we thought it would be worthwhile to include fairness as a competition metric. The main goal being to encourage students to discover fair learning by themselves, as it not necessarily a topic that is being taught in their curriculums.</p><h2 id=the-fairness-metric>The fairness metric</h2><p>What is fair? It&rsquo;s a very vague concept when you think about it for a bit. I&rsquo;m not going to into a lot of detail as many things have already been written on the topic. For instance, see <a href=https://blog.acolyer.org/2020/02/03/measure-mismeasure-fairness/>this light article</a> by Adrian Colyer (aka the morning paper).</p><p><img src=/img/blog/fairness-competition/def.jpg width=80%></p><p>We went with the notion of <a href=https://www.wikiwand.com/en/Disparate_impact>disparate impact</a>. Essentially, our motivation was for the students to make predictions that are not biased towards one gender in particular. For instance, if we tallied up all the &ldquo;rapper&rdquo; predictions, well we would consider a model to be fair if 50% of those predictions are for women and 50% are for men. We compute the disparate impact for each job and average them in order to obtain a so-called &ldquo;macro disparate impact&rdquo;:</p><p>$$
\frac{1}{jobs} \sum_{job \in jobs} \frac{max(P(male \mid job), P(female \mid job))}{min(P(male \mid job), P(female \mid job))}
$$</p><p>This metric is very straighforward to compute. Say you have a <code>people</code> dataframe that associates job predictions with genders:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>people</span><span class=o>.</span><span class=n>head</span><span class=p>()</span>
</span></span><span class=line><span class=cl>           <span class=n>job</span> <span class=n>gender</span>
</span></span><span class=line><span class=cl><span class=mi>0</span>    <span class=n>professor</span>      <span class=n>F</span>
</span></span><span class=line><span class=cl><span class=mi>1</span>   <span class=n>accountant</span>      <span class=n>M</span>
</span></span><span class=line><span class=cl><span class=mi>2</span>    <span class=n>professor</span>      <span class=n>M</span>
</span></span><span class=line><span class=cl><span class=mi>3</span>    <span class=n>architect</span>      <span class=n>M</span>
</span></span><span class=line><span class=cl><span class=mi>4</span>    <span class=n>architect</span>      <span class=n>M</span>
</span></span></code></pre></div><p>The <code>job</code> column corresponds to the predictions made by a model. The <code>gender</code> column is a ground-truth. We simply have to build the pivot table I showed above and count the number of times each gender appears for each job.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=k>def</span> <span class=nf>macro_disparate_impact</span><span class=p>(</span><span class=n>people</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>counts</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>people</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>groupby</span><span class=p>([</span><span class=s1>&#39;job&#39;</span><span class=p>,</span> <span class=s1>&#39;gender&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>size</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=o>.</span><span class=n>unstack</span><span class=p>(</span><span class=s1>&#39;gender&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>disparate_impacts</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>counts</span><span class=p>[[</span><span class=s1>&#39;M&#39;</span><span class=p>,</span> <span class=s1>&#39;F&#39;</span><span class=p>]]</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=s1>&#39;columns&#39;</span><span class=p>)</span> <span class=o>/</span>
</span></span><span class=line><span class=cl>        <span class=n>counts</span><span class=p>[[</span><span class=s1>&#39;M&#39;</span><span class=p>,</span> <span class=s1>&#39;F&#39;</span><span class=p>]]</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=s1>&#39;columns&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>disparate_impacts</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span></code></pre></div><p>Note that the Kaggle leaderboard ranking used the macro F1 score proposed on the platform. Kaggle effectively locks you in and doesn&rsquo;t allow you to provide a custom metric. Therefore, once the competition was over, I downloaded the best private submission from each team and ran this metric myself on each submission. Thankfully, Kaggle&rsquo;s admin interface for managing submissions is quite good.</p><p>I picked this metric because it makes sense to me. It encourages a model to be discriminative in a good
way. To minimise the metric, a model has to restrain itself from assigning the most likely job to a person. In other words, the model <em>necessarily</em> has to be less accurate. But it&rsquo;s a tradeoff! I think this pretty cool, and as far as I know this hasn&rsquo;t been done on Kaggle before.</p><p>In the case of this competition, we assume that the goal is to reach a perfect balance of men and women for each job. However, we could perfectly well imagine a more nuanced goal. For instance, we could say that we would like 30% of rappers to be women and 70% to be men. This would still be &ldquo;better&rdquo; than a 10%/90% split &ndash; which is the reality &ndash; but might also be more realistic.</p><p>One thing to notice is that a perfect macro disparate impact of 1 is only achievable if the genders are balanced. I only realised this after starting the competition thanks a remark from Philippe Besse. It was kindly suggested to me to normalise by the size of each gender pool in order to account for gender imbalance. In the end it didn&rsquo;t matter that much because there are only slightly more men than women in the dataset. Moreover, the point of this metric is simply to rank the competitors, and this imbalance equally affects each competitor.</p><h2 id=what-people-did>What people did</h2><p>Once the competition was over, the students were instructed to send me their code. This was mostly to verify they hadn&rsquo;t cheated in any way. It also allowed me to inspect what they had done. Moreover, teams that didn&rsquo;t send their code were not eligible to the final ranking. Out of the 78 teams, only 30 sent me their code. Here are some statistics:</p><ul><li>Everyone used Python. That&rsquo;s somewhat interesting because during the past years there were still some teams that used R.</li><li>Apart from one team, everyone sent me one or more <a href=https://jupyter.org/>Jupyter Notebooks</a>. I wonder if they know about Jupyter Lab üòâ</li><li>14 used some flavor of <a href=https://www.wikiwand.com/en/BERT_(language_model)>BERT</a>.</li><li>14 preprocessed the text in some way (lowercasing, stemming, stop words, etc.)</li><li>Absolutely no team did any effort to make their model fairer with respect to both genders üò©</li><li>2 did <a href=https://www.wikiwand.com/en/Cross-validation_(statistics)>cross-validation</a>. The rest did a simple train/test split, if that.</li><li>8 used a <a href=https://www.wikiwand.com/en/Tf%E2%80%93idf>TF-IDF</a> approach.</li><li>16 really used <a href=https://scikit-learn.org/stable/>scikit-learn</a>. Other teams used scikit-learn only for metrics and train/test splitting.</li><li>My estimate is that 17 teams made a real effort. From what I can tell, the 12 others just mindlessly imported libraries, figured out the API, and <a href=https://tenor.com/view/and-thats-it-guys-its-awrap-finished-lets-call-it-aday-happy-gif-14375900>called it a day</a>.</li><li>10 used Hugging Face&rsquo;s <a href=https://huggingface.co/transformers/>transformers</a> library.</li><li>4 did data augmentation.</li><li>8 did exploratory data analysis (EDA), although others might have done but didn&rsquo;t include it in what they showed me.</li><li>12 used <a href=https://www.nltk.org/>NLTK</a>, which I find pretty cool considering how old it is.</li><li>2 attempted to <a href=https://github.com/scikit-learn-contrib/imbalanced-learn>rebalance</a> the dataset.</li><li>2 built their own model in <a href=https://pytorch.org/>PyTorch</a>.</li><li>8 built their own odel with <a href=https://keras.io/>Keras</a>.</li><li>3 built an <a href=https://www.wikiwand.com/en/Recurrent_neural_network>RNN</a>.</li><li>2 did <a href=https://www.wikiwand.com/en/Ensemble_learning>model ensembling</a>.</li><li>7 used the <a href=https://github.com/ThilinaRajapakse/simpletransformers>simpletransformers</a> library, which I find to be frightfully high level.</li><li>2 used <a href=https://spacy.io/>spaCy</a></li><li>2 used <a href=https://radimrehurek.com/gensim/>Gensim</a></li></ul><p>Overall, I found the code quality to be quite poor. Most notebooks were very bloated with dozens of imports, many commented lines, long uncommented blocks of obscure logic. Another striking observation is that there were few similarities between different notebooks in terms of code structure. The fit/predict paradigm remains, but there seems to be little convention as to the rest of the machine learning lifecycle. Each team invented its own little paradigms and didn&rsquo;t necessarily take the time to organise and rethink its approach. A positive note is that I can see that most teams made a good effort and spent time exploring the library ecosystem.</p><h2 id=rankings>Rankings</h2><p>The <a href=https://www.kaggle.com/c/defi-ia-insa-toulouse/leaderboard>Kaggle leaderboard</a> measured the macro F1 score of the job predictions. In other words, the goal was simply to be as accurate as possible. I then took the 10 highest performers on the private leaderboard and measured their macro disparate impact to establish the fairness rankings. I did this to highlight the tradeoff that had to be made between accuracy and fairness. For instance, a very accurate solution is cool but it won&rsquo;t get to be used in a real-world application if we know it&rsquo;s not fair. Likewise, it&rsquo;s very easy to provide a perfectly solution by simply flipping a coin, but there&rsquo;s no point in doing so if the predictions are not accurate as well.</p><p><img src=/img/blog/fairness-competition/scores.svg width=80%></p><p>I mentionned above that a perfect macro disparate impact is equal to 1. The macro disparate impact in the data is 3.62. That is, if we use the ground truth labels as predictions and compute the macro disparate impact, then we obtain 3.62. The point of this competition is to do better than this, and not just focus on the predictive performance of the model.</p><p>Sadly, it seems that no teams managed to really remove any bias whatsoever from their model. I&rsquo;ll be honest: I&rsquo;m very disappointed with the way this turned out. The best performing teams seem to have made no effort whatsoever. Fair learning is a relatively sophisticated topic, so I wouldn&rsquo;t be surprised that students had some difficulties. With the whole COVID 19 situation, the relationship between teachers and students might have been affected, and teachers might not have had the opportunity to discuss a topic that is not part of the official curriculum with their students.</p><p>And yet, my gut feeling is that many teams have had the wrong focus. Having looked at each team&rsquo;s code, most people used very sophisticated neural networks based on transformer architectures. That&rsquo;s great, because I know for a fact that the latter are not part of the official curriculum in French schools as well, so it shows some form of motivation. However, I&rsquo;m worried that students used a &ldquo;toolbox&rdquo; approach whereby they imported and trained a fancy model because it&rsquo;s the <em>go√ªt du jour</em>.</p><p>In my opinion, if a student is able to understand BERT and transformers, then surely she is capable of understanding fair learning. The problem is that I believe that they don&rsquo;t understand these notions very well. Instead, they only manage to figure out the API provided by a library they found on GitHub and imported in their notebook. I fear that they simply didn&rsquo;t do any fair learning because the toolboxes they used didn&rsquo;t provide any fair learning capability. That&rsquo;s very worrying. It might also hint at a blindspot in the library ecosystem. I would love to be wrong about all this.</p><p>Here is the ranking with respect to fairness for the top 10 competitors on the Kaggle private leaderboard:</p><table><thead><tr><th style=text-align:left>Country</th><th style=text-align:left>School</th><th style=text-align:left>Team name</th><th style=text-align:left>Macro F1</th><th style=text-align:left>Disparate impact</th><th style=text-align:center>Sent code</th></tr></thead><tbody><tr><td style=text-align:left>France</td><td style=text-align:left>UPS</td><td style=text-align:left>Test</td><td style=text-align:left>0.81971</td><td style=text-align:left>3.49578</td><td style=text-align:center>‚úÖ</td></tr><tr><td style=text-align:left>France</td><td style=text-align:left>ENSEEIHT</td><td style=text-align:left>Pyramids</td><td style=text-align:left>0.82685</td><td style=text-align:left>3.74924</td><td style=text-align:center>‚úÖ</td></tr><tr><td style=text-align:left>France</td><td style=text-align:left>UPS</td><td style=text-align:left>FairleNessSROnly</td><td style=text-align:left>0.81443</td><td style=text-align:left>3.94925</td><td style=text-align:center>‚ùå</td></tr><tr><td style=text-align:left>France</td><td style=text-align:left>INSA</td><td style=text-align:left>Salle104</td><td style=text-align:left>0.82598</td><td style=text-align:left>3.95849</td><td style=text-align:center>‚úÖ</td></tr><tr><td style=text-align:left>France</td><td style=text-align:left>UR2</td><td style=text-align:left>WeTried</td><td style=text-align:left>0.84247</td><td style=text-align:left>4.00975</td><td style=text-align:center>‚úÖ</td></tr><tr><td style=text-align:left>Cameroun</td><td style=text-align:left>ENSPY</td><td style=text-align:left>Fred</td><td style=text-align:left>0.82733</td><td style=text-align:left>4.03571</td><td style=text-align:center>‚úÖ</td></tr><tr><td style=text-align:left>France</td><td style=text-align:left>Universit√© de Bordeaux</td><td style=text-align:left>CMI ISI datadax</td><td style=text-align:left>0.81639</td><td style=text-align:left>4.10829</td><td style=text-align:center>‚úÖ</td></tr><tr><td style=text-align:left>Cameroun</td><td style=text-align:left>ENSPY</td><td style=text-align:left>GI</td><td style=text-align:left>0.82446</td><td style=text-align:left>4.13195</td><td style=text-align:center>‚úÖ</td></tr><tr><td style=text-align:left>France</td><td style=text-align:left>Universit√© Jean Monnet</td><td style=text-align:left>Minions</td><td style=text-align:left>0.82354</td><td style=text-align:left>4.23495</td><td style=text-align:center>‚úÖ</td></tr><tr><td style=text-align:left>France</td><td style=text-align:left>UJM</td><td style=text-align:left>BravoNils</td><td style=text-align:left>0.82932</td><td style=text-align:left>4.26414</td><td style=text-align:center>‚úÖ</td></tr></tbody></table><p><em>Note: I removed Olivier Chotin from the ranking because he&rsquo;s not a student.</em></p><p>Again, I&rsquo;m quite disappointed with these standings from an effort point of view. While writing this blog post, I took 10 minutes to see the effect of replacing &ldquo;he&rdquo; by &ldquo;she&rdquo; and &ldquo;his&rdquo; by &ldquo;her&rdquo; on a plain and simple logistic regression. In my cross-validation, the macro disparate impact went from 5.11 and 3.85 and the macro F1 score remained simple. It would have been nice to see at least a couple of teams that produced some decent fairness results. Alas, I&rsquo;m sorry to say, these models wouldn&rsquo;t be used. Regardless of their accuracy, the main objective of this competition was to reduce the disparate impact.</p><p>With regards to the macro F1 score that was used to establish the Kaggle leaderboard, here is a summary of the best solution with a breakdown by job:</p><pre tabindex=0><code>                   precision    recall  f1-score   support

       accountant       0.78      0.88      0.83       694
        architect       0.75      0.84      0.79      1371
         attorney       0.94      0.91      0.92      4832
     chiropractor       0.69      0.81      0.75       284
         comedian       0.86      0.88      0.87       386
         composer       0.94      0.89      0.91       897
          dentist       0.96      0.95      0.96      1463
        dietitian       0.87      0.88      0.87       545
               dj       0.83      0.88      0.86       211
        filmmaker       0.88      0.88      0.88      1012
interior_designer       0.78      0.83      0.80       201
       journalist       0.85      0.82      0.83      3068
            model       0.85      0.89      0.87       978
            nurse       0.87      0.91      0.89      2977
          painter       0.87      0.85      0.86      1128
        paralegal       0.69      0.91      0.78       174
           pastor       0.78      0.72      0.75       393
 personal_trainer       0.79      0.84      0.81       194
     photographer       0.92      0.90      0.91      3731
        physician       0.77      0.81      0.79      2715
             poet       0.84      0.84      0.84      1107
        professor       0.95      0.92      0.93     18266
     psychologist       0.81      0.85      0.83      2514
           rapper       0.90      0.86      0.88       212
software_engineer       0.83      0.79      0.81      1013
          surgeon       0.80      0.86      0.83      1516
          teacher       0.69      0.72      0.71      2147
     yoga_teacher       0.81      0.74      0.78       271

         accuracy                           0.88     54300
        macro avg       0.83      0.85      0.84     54300
     weighted avg       0.88      0.88      0.88     54300
</code></pre><p>It seems that the F1 scores are lower for jobs that are less biased towards either gender. For instance, the model performs worse for physicians and teachers than for rappers and nurses. This could be indicative that the model uses gendered words to help it make its predictions, which is worrying. Then again, the model performs very well for teachers, but that could also be because teachers are easy to identify. I didn&rsquo;t go very deep into any kind of analysis, but I&rsquo;m confident it would yield interesting results.</p><p>It turns out that 1,927 out of the 54,300 test documents were incorrectly classified by each of the 78 teams. Here are some of these documents:</p><details><summary>14023 - everyone said yoga teacher</summary><p style="margin:0 11px">She offers a free and creative approach to Yoga. Reni's classes are designed intelligently to achieve specific goals and energetic effects. Her teaching is based on the method of Therapeutic Yoga in order to promote wellbeing and health in people's life. Find out more...</p><details style="margin:9px 11px"><summary>Ground truth label</summary><p style="margin:0 11px">teacher</p></details></details><details><summary>15386 - everyone said professor</summary><p style="margin:0 11px">He is working on a project tentatively titled "Slaves and Soldiers in the Red and Black Atlantic: A Transnational and Revolutionary History of the American Civil War." He earned his Ph.D. from the University of California, San Diego in 1998 and has published numerous books including "Cotton Booms, Cotton Busts, and the Civil War in West Africa," "Primitive Art, Primitive Accumulation, and the Origin of the Work of Art in German New Guinea," and "Three Logics of Race: Theory and Exception in the Transnational History of Empire.</p><details style="margin:9px 11px"><summary>Ground truth label</summary><p style="margin:0 11px">teacher</p></details></details><details><summary>37968 - everyone said professor</summary><p style="margin:0 11px">Broadly her research focuses on behavioral and social responses to maternal and child wellness. For her dissertation, she received a NRSA pre-doctoral fellowship from NIMH to conduct an RCT using a theory-based approach to promote exclusive breastfeeding among women living with HIV in South Africa. Dr. Tuthill is particularly interested in developing sustainable solutions for perinatal women that address the dynamic intersections of mental health, food insecurity, infant feeding and overall health (including disease risk and status) for mothers and their infants, both domestically and globally.</p><details style="margin:9px 11px"><summary>Ground truth label</summary><p style="margin:0 11px">nurse</p></details></details><details><summary>1517 - 46 said photographer, 32 said painter</summary><p style="margin:0 11px">He recently returned from performing at the Montreal Just For Laugh's Festival and is part of the Top 30 YouTube comedy channel ‚ÄúKeepTheHeat‚Äù. Their sketches and parodies have more than 260,000,000 views. As far as comedy style is concerned, Dominic takes pride in being a joke-teller and not a story-teller.</p><details style="margin:9px 11px"><summary>Ground truth label</summary><p style="margin:0 11px">comedian</p></details></details><details><summary>5775 - everyone said professor</summary><p style="margin:0 11px">Her research interests are in blended learning and the use of information technology in education. Previously, she has published several papers on student motivation, satisfaction, achievement, and critical thinking and problem-solving skills in tertiary education.</p><details style="margin:9px 11px"><summary>Ground truth label</summary><p style="margin:0 11px">teacher</p></details></details><details><summary>2750 - 36 said teacher, 18 said teacher, 14 said journalist</summary><p style="margin:0 11px">He was a contributor for OP‚Äôs issue No. 2, ‚ÄúParis Existrans 2009,‚Äù which was an exclusive man-on-the-street spread highlighting Paris Trans March. Most recently, Elliot contributed to the OP blog with Buck Angel: Swedish Exclusive.</p><details style="margin:9px 11px"><summary>Ground truth label</summary><p style="margin:0 11px">photographer</p></details></details><details><summary>38146 - most people said journalist, some said professor</summary><p style="margin:0 11px">Contact him at: snorre_lindquist@hotmail.com. Lasse Wilhelmson is a commentator on the situation in the Middle East, and has been a member of a local government in Sweden for 23 years, four of which in an executive position. Contact him at: lassewilhelmson@bredband.net. Read other articles by Snorre Lindquist and Lasse Wilhelmson.</p><details style="margin:9px 11px"><summary>Ground truth label</summary><p style="margin:0 11px">architect</p></details></details><p>The above examples explain why the model performances are not closer to 100%. Some labels are very similar in meaning (professor ‚âÉ teacher). Some observations seem to be mislabeled, such as the last one, which is clearly not an architect. Welcome to the real world of dirty data!</p><p>Here are some a couple examples where roughly half of the teams were correct and the rest were not:</p><details><summary>937 - 36 said professor, 42 said psychologist</summary><p style="margin:0 11px">His experience includes working for Microsoft, HSBC Bank Argentina in Human Resources and several mental health facilities performing clinical work . In 2008 he was recruited in Argentina by the Devereux Foundation, the biggest mental health care provider in the USA as a residential counselor and then subsequently changed positions into coordinating and managing some of the foundation's programs. Check out his site http://fernandotarnogol.com/.</p><details style="margin:9px 11px"><summary>Ground truth label</summary><p style="margin:0 11px">psychologist</p></details></details><details><summary>1037 - 37 said professor, 40 said physician, 1 said surgeon</summary><p style="margin:0 11px">His specializes in neuro-ophthalmology, with special interest in the treatment of thyroid eye disease, disorders that cause double vision in adults and orbital and skull base tumors. His clinical practice includes patients with all types of disorders of the optic nerve and orbit. Dr. Subramanian is the principal investigator in clinical trials on treatments for thyroid eye disease and idiopathic intracranial hypertension and is conducting research on how to treat vision problems in patients with traumatic brain injury.</p><details style="margin:9px 11px"><summary>Ground truth label</summary><p style="margin:0 11px">professor</p></details></details><p>Regarding tidyness, there are three teams that stood out to me in the following order:</p><ol><li>&ldquo;ANALYTICS&rdquo; from Yamoussoukro&rsquo;s INPHB.</li><li>&ldquo;Fred&rdquo; from Yaounde&rsquo;s ENSPY.</li><li>&ldquo;ISI datadax&rdquo; from the University of Bordeaux.</li></ol><p>They did a good job at organising their code. They also explained what they were doing, and demonstrated that they made a real effort to understand what they were doing. There was some confusion along the way in certain cases, but overall it was decent.</p><h2 id=conclusion>Conclusion</h2><p>I would like to thank the professors that contributed to organising this competition. Hopefully this competition helped to shed some light on the need to teach the basics of fair machine learning to data science students.</p><p>On a personal level, I&rsquo;m mildly disappointed with the turn out. Until now, the competition kept growing in size. I actually thought that COVID 19 would increase the turnout because this was a completely virtual event. I&rsquo;m not a student anymore so I&rsquo;m not sure what is the state of things though. In any case, this edition wasn&rsquo;t very rewarding for me. I do this <em>pro bono</em> so it helps when people are actively participating. I also got a lot of emails ranting about the fairness metric without proposing any alternative. Many students asked me questions that I had clearly instructed the teachers to provide to said students. Nobody used the forum and instead sent me personal emails, which I find sad. The whole point of these competitions is to create a sense of togetherness and allow students from differents schools/countries to meet each other.</p><p>Nonetheless, I got some positive feedback from a significant number of students. Hopefully, this competition will have provided them with a decent setting to explore the ever-changing world of NLP. Even though it seems the students didn&rsquo;t put a lot of effort into the fair learning aspect, hopefully they&rsquo;re now aware of the concept and will it in mind during their professional career.</p><p>For the participants, here are the <a href=/files/fairness_competition/test_labels.csv>test labels</a> as well as the <a href=/files/fairness_competition/standings.csv>final standings</a>.</p><p>Feel free to reach out and/or comment if you have any questions!</p><p>Edit: after having presented this blog post to the students on Zoom, I realised that some teams had in fact tackled the fairness problem. I sincerely apologise for being so brash in saying that no team made any effort. I believe I mostly missed this because the fairness scores of the teams that sent me their solution didn&rsquo;t do that well in terms of fairness.</p></div><script type=text/javascript>var s=document.createElement("script");s.setAttribute("src","https://utteranc.es/client.js"),s.setAttribute("repo","MaxHalford/maxhalford.github.io"),s.setAttribute("issue-term","pathname"),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",null),s.setAttribute("theme","github-light"),document.body.appendChild(s)</script><div class=footer><div class=do-the-thing><div class=elevator><svg class="sweet-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" enable-background="new 0 0 100 100" height="100" width="100"><path d="M70 47.5H30c-1.4.0-2.5 1.1-2.5 2.5v40c0 1.4 1.1 2.5 2.5 2.5h40c1.4.0 2.5-1.1 2.5-2.5V50C72.5 48.6 71.4 47.5 70 47.5zm-22.5 40h-5v-25h5v25zm10 0h-5v-25h5v25zm10 0h-5V60c0-1.4-1.1-2.5-2.5-2.5H40c-1.4.0-2.5 1.1-2.5 2.5v27.5h-5v-35h35v35z"/><path d="M50 42.5c1.4.0 2.5-1.1 2.5-2.5V16l5.7 5.7c.5.5 1.1.7 1.8.7s1.3-.2 1.8-.7c1-1 1-2.6.0-3.5l-10-10c-1-1-2.6-1-3.5.0l-10 10c-1 1-1 2.6.0 3.5 1 1 2.6 1 3.5.0l5.7-5.7v24c0 1.4 1.1 2.5 2.5 2.5z"/></svg>Back to the top</div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/elevator.js/1.0.0/elevator.min.js></script>
<script>var elementButton=document.querySelector(".elevator"),elevator=new Elevator({element:elementButton,mainAudio:"/music/elevator.mp3",endAudio:"/music/ding.mp3"})</script><style>.down-arrow{font-size:120px;margin-top:90px;margin-bottom:90px;text-shadow:0 -20px #0c1f31,0 0 #c33329;color:transparent;-webkit-transform:scaleY(.8);-moz-transform:scaleY(.8);transform:scaleY(.8)}.elevator{text-align:center;cursor:pointer;width:140px;margin:auto}.elevator:hover{opacity:.7}.elevator svg{width:40px;height:40px;display:block;margin:auto;margin-bottom:5px}</style><div class=site-footer><div class=site-footer-item><a href=/index.xml><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M12.8 16C12.8 8.978 7.022 3.2.0 3.2V0c8.777.0 16 7.223 16 16h-3.2zM2.194 11.61c1.21.0 2.195.985 2.195 2.196.0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017.0 13.806c0-1.21.983-2.195 2.194-2.195zM10.606 16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818.0 10.606 4.79 10.606 10.607z"/></svg></span></a></div><div class=site-footer-item><a href=https://github.com/MaxHalford><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M8 0C3.58.0.0 3.582.0 8c0 3.535 2.292 6.533 5.47 7.59.4.075.547-.172.547-.385.0-.19-.007-.693-.01-1.36-2.226.483-2.695-1.073-2.695-1.073-.364-.924-.89-1.17-.89-1.17-.725-.496.056-.486.056-.486.803.056 1.225.824 1.225.824.714 1.223 1.873.87 2.33.665.072-.517.278-.87.507-1.07-1.777-.2-3.644-.888-3.644-3.953.0-.873.31-1.587.823-2.147-.09-.202-.36-1.015.07-2.117.0.0.67-.215 2.2.82.64-.178 1.32-.266 2-.27.68.004 1.36.092 2 .27 1.52-1.035 2.19-.82 2.19-.82.43 1.102.16 1.915.08 2.117.51.56.82 1.274.82 2.147.0 3.073-1.87 3.75-3.65 3.947.28.24.54.73.54 1.48.0 1.07-.01 1.93-.01 2.19.0.21.14.46.55.38C13.71 14.53 16 11.53 16 8c0-4.418-3.582-8-8-8"/></svg></span></a></div><div class=site-footer-item><a href=https://linkedin.com/in/maxhalford><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M13.632 13.635h-2.37V9.922c0-.886-.018-2.025-1.234-2.025-1.235.0-1.424.964-1.424 1.96v3.778h-2.37V6H8.51v1.04h.03c.318-.6 1.092-1.233 2.247-1.233 2.4.0 2.845 1.58 2.845 3.637v4.188zM3.558 4.955c-.762.0-1.376-.617-1.376-1.377.0-.758.614-1.375 1.376-1.375.76.0 1.376.617 1.376 1.375.0.76-.617 1.377-1.376 1.377zm1.188 8.68H2.37V6h2.376v7.635zM14.816.0H1.18C.528.0.0.516.0 1.153v13.694C0 15.484.528 16 1.18 16h13.635c.652.0 1.185-.516 1.185-1.153V1.153C16 .516 15.467.0 14.815.0z" fill-rule="nonzero"/></svg></span></a></div><div class=site-footer-item><a href=https://twitter.com/halford_max><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M16 3.038c-.59.26-1.22.437-1.885.517.677-.407 1.198-1.05 1.443-1.816-.634.37-1.337.64-2.085.79-.598-.64-1.45-1.04-2.396-1.04-1.812.0-3.282 1.47-3.282 3.28.0.26.03.51.085.75-2.728-.13-5.147-1.44-6.766-3.42C.83 2.58.67 3.14.67 3.75c0 1.14.58 2.143 1.46 2.732-.538-.017-1.045-.165-1.487-.41v.04c0 1.59 1.13 2.918 2.633 3.22-.276.074-.566.114-.865.114-.21.0-.41-.02-.61-.058.42 1.304 1.63 2.253 3.07 2.28-1.12.88-2.54 1.404-4.07 1.404-.26.0-.52-.015-.78-.045 1.46.93 3.18 1.474 5.04 1.474 6.04.0 9.34-5 9.34-9.33.0-.14.0-.28-.01-.42.64-.46 1.2-1.04 1.64-1.7z" fill-rule="nonzero"/></svg></span></a></div><div class=site-footer-item><a href=https://kaggle.com/maxhalford><span class=inline-svg><svg role="img" viewBox="0 0 26 26" xmlns="http://www.w3.org/2000/svg"><title>Kaggle icon</title><path fill="currentcolor" d="M18.825 23.859c-.022.092-.117.141-.281.141h-3.139c-.187.0-.351-.082-.492-.248l-5.178-6.589-1.448 1.374v5.111c0 .235-.117.352-.351.352H5.505c-.236.0-.354-.117-.354-.352V.353c0-.233.118-.353.354-.353h2.431c.234.0.351.12.351.353v14.343l6.203-6.272c.165-.165.33-.246.495-.246h3.239c.144.0.236.06.285.18.046.149.034.255-.036.315l-6.555 6.344 6.836 8.507c.095.104.117.208.07.358"/></svg></span></a></div><div class=site-footer-item><a href=/files/resume_max_halford.pdf><span class=inline-svg><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 392.533 392.533" style="enable-background:new 0 0 392.533 392.533"><g><g><path fill="currentcolor" d="M292.396 324.849H99.879c-6.012.0-10.925 4.848-10.925 10.925.0 6.012 4.849 10.925 10.925 10.925h192.582c6.012.0 10.925-4.849 10.925-10.925C303.321 329.697 298.473 324.849 292.396 324.849z"/></g></g><g><g><path fill="currentcolor" d="M292.396 277.01H99.879c-6.012.0-10.925 4.848-10.925 10.925.0 6.012 4.849 10.925 10.925 10.925h192.582c6.012.0 10.925-4.849 10.925-10.925C303.321 281.859 298.473 277.01 292.396 277.01z"/></g></g><g><g><path fill="currentcolor" d="M196.137 45.834c-25.859.0-46.998 21.075-46.998 46.998.0 25.859 21.139 46.933 46.998 46.933s46.998-21.075 46.998-46.998-21.139-46.933-46.998-46.933zm0 72.017c-13.77.0-25.083-11.313-25.083-25.083s11.248-25.083 25.083-25.083 25.083 11.313 25.083 25.083c0 13.769-11.313 25.083-25.083 25.083z"/></g></g><g><g><path fill="currentcolor" d="M258.521 163.362c-39.887-15.515-84.752-15.515-124.638.0-13.059 5.107-21.786 18.101-21.786 32.388v44.347c-.065 6.012 4.849 10.925 10.861 10.925h146.424c6.012.0 10.925-4.848 10.925-10.925V195.75C280.307 181.463 271.58 168.469 258.521 163.362zm0 65.874H133.883v-33.422c0-5.301 3.168-10.214 7.887-12.024 34.844-13.511 74.02-13.511 108.865.0 4.719 1.875 7.887 6.659 7.887 12.024v33.422z"/></g></g><g><g><path fill="currentcolor" d="M313.083.0H131.491c-8.404.0-16.291 3.232-22.238 9.18L57.018 61.414c-5.947 5.948-9.18 13.834-9.18 22.238v277.333c0 17.39 14.158 31.547 31.547 31.547h233.762c17.39.0 31.547-14.158 31.547-31.547V31.547C344.501 14.158 330.343.0 313.083.0zM112.032 37.236v27.022H85.01l27.022-27.022zm210.683 79.58h-40.598c-6.012.0-10.925 4.849-10.925 10.925.0 6.012 4.848 10.925 10.925 10.925h40.598v19.394h-14.869c-6.012.0-10.925 4.848-10.925 10.925.0 6.012 4.849 10.925 10.925 10.925h14.869v181.139c0 5.366-4.331 9.697-9.632 9.697H79.192c-5.301.0-9.632-4.331-9.632-9.632V86.044h53.398c6.012.0 10.925-4.848 10.925-10.925V21.721h179.2c5.301.0 9.632 4.331 9.632 9.632v85.463z"/></g></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></span></a></div><div class=site-footer-item><a href="https://scholar.google.com/citations?user=erRNNi0AAAAJ&hl=en"><span class=inline-svg><svg viewBox="0 0 1755 1755" xmlns="http://www.w3.org/2000/svg"><path fill="currentcolor" transform="translate(0 1610) scale(1 -1)" d="M896.76 1130.189c-27.618 30.838-59.618 46.19-95.802 46.19-40.952.0-72.382-14.738-94.288-44.15-21.906-29.322-32.864-64.848-32.864-106.584.0-35.548 5.998-71.738 18-108.64 11.958-36.886 31.524-69.814 58.954-98.838 27.334-29.096 59.144-43.616 95.284-43.616 40.288.0 71.76 13.502 94.332 40.492 22.476 26.954 33.756 60.98 33.756 101.962.0 34.904-5.954 71.454-17.906 109.664-11.894 38.262-31.752 72.784-59.466 103.52zm762.098 382.384c-64.358 64.424-141.86 96.57-232.572 96.57H329.144c-90.712.0-168.14-32.146-232.572-96.57-64.424-64.286-96.57-141.86-96.57-232.572V182.859c0-90.712 32.146-168.288 96.57-232.712 64.432-64.146 142-96.432 232.572-96.432h1097.142c90.712.0 168.214 32.286 232.572 96.57 64.432 64.432 96.644 141.86 96.644 232.572v1097.142c0 90.712-32.22 168.288-96.644 232.572zM1297.81 1154.159V762.033c0-18.154-14.856-33.016-33.016-33.016h-12.156c-18.162.0-33.016 14.856-33.016 33.016v392.126c0 16.12-2.34 29.578 20.188 32.41v52.172l-173.43-142.24c2.004-3.716 3.906-6.092 5.712-9.208 15.242-26.976 23.004-60.526 23.004-101.53.0-31.43-5.238-59.662-15.858-84.598-10.57-24.928-23.428-45.29-38.43-60.972-15.002-15.74-30.048-30.128-45.092-43.074-15.046-12.976-27.904-26.506-38.436-40.55-10.614-14-15.894-28.474-15.894-43.476.0-15.024 6.854-30.288 20.524-45.67 13.62-15.426 30.376-30.376 50.19-45.144 19.85-14.666 39.658-30.946 59.472-48.662 19.858-17.694 36.52-40.456 50.14-68.096 13.722-27.744 20.568-58.288 20.568-91.86.0-44.288-11.294-84.282-33.806-119.882-22.58-35.446-51.998-63.73-88.144-84.472-36.242-20.882-75-36.6-116.334-47.214-41.42-10.518-82.52-15.806-123.568-15.806-25.908.0-52.048 1.996-78.336 6.1-26.382 4.096-52.81 11.33-79.426 21.526-26.668 10.262-50.286 22.864-70.758 37.998-20.524 14.98-37.046 34.312-49.716 57.856-12.668 23.552-18.958 50.022-18.958 79.426.0 34.882 9.714 67.24 29.192 97.404 19.478 29.944 45.282 54.952 77.378 74.76 55.998 34.838 143.858 56.364 263.432 64.498-27.334 34.172-41.048 66.334-41.048 96.432.0 17.122 4.476 35.474 13.334 55.288-14.284-1.996-28.994-3.124-44.002-3.124-64.234.0-118.476 20.882-162.524 62.932-44.046 41.976-66.048 94.522-66.048 158.048.0 6.642.19 12.492.672 18.974H292.574l393.618 342.17h651.856l-60.24-47.024v-82.996c22.368-2.874 20.004-16.318 20.004-32.394zM900.382 544.929c-7.52 1.36-18.088 2.122-31.708 2.122-29.382.0-58.288-2.596-86.666-7.782-28.38-5.046-56.378-13.568-83.998-25.592-27.722-11.952-50.096-29.528-67.146-52.766-17.144-23.208-25.666-50.542-25.666-81.994.0-29.974 7.52-56.714 22.572-80.004 15.002-23.142 34.808-41.26 59.428-54.236 24.62-12.998 50.432-22.814 77.378-29.264 26.998-6.408 54.476-9.736 82.476-9.736 55.376.0 103.05 12.47 143.046 37.406 39.906 24.928 59.904 63.422 59.904 115.382.0 10.928-1.522 21.686-4.528 32.19-3.138 10.62-6.24 19.712-9.282 27.26-3.05 7.41-8.858 16.332-17.43 26.616-8.522 10.314-15.046 17.934-19.434 23.004-4.476 5.238-12.852 12.712-25.19 22.594-12.236 9.926-20.048 16.114-23.522 18.402-3.43 2.406-12.332 8.908-26.668 19.456-14.328 10.634-22.184 16.274-23.566 16.94z"/></svg></span></a></div><div class=site-footer-item><a href=https://www.imdb.com/user/ur73044771><span class=inline-svg><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><g><g><path fill="currentcolor" d="M425.17 73.146c.179-1.577.268-3.169.268-4.771.0-23.25-18.915-42.165-42.165-42.165-6.849.0-13.444 1.619-19.354 4.678-9.531-14.757-26.054-24.056-44.185-24.056-11.414.0-22.244 3.62-31.163 10.214C280.754 6.589 268.271.0 254.743.0c-13.007.0-25.097 6.068-32.975 15.906-8.628-5.856-18.899-9.075-29.515-9.075-18.126.0-34.646 9.302-44.176 24.06-5.913-3.06-12.508-4.682-19.351-4.682-23.25.0-42.166 18.915-42.166 42.165.0 1.603.088 3.195.266 4.769-21.658 6.642-36.909 26.605-36.909 50.229.0 11.817 3.952 23.172 11.184 32.401l43.004 347.699c.603 4.871 4.74 8.528 9.648 8.528h284.485c4.907.0 9.046-3.658 9.648-8.528l43.004-347.7c7.238-9.225 11.194-20.578 11.194-32.4C462.083 99.751 446.832 79.789 425.17 73.146zM122.346 492.557 81.465 162.025h44.764l26.618 330.532H122.346zm50.007.0-26.618-330.532H201.2l3.161 104.598c-17.168 14.634-28.086 36.393-28.086 60.667.0 26.007 12.521 49.142 31.849 63.703l3.065 101.563H172.353zm108.993.0h-50.704l-2.736-90.671c8.743 3.303 18.205 5.125 28.09 5.125 9.887.0 19.352-1.823 28.096-5.128L281.346 492.557zm-25.35-104.989c-33.237.0-60.277-27.04-60.277-60.277s27.04-60.277 60.277-60.277 60.277 27.04 60.277 60.277-27.04 60.277-60.277 60.277zM220.653 162.025h70.696l-2.797 92.523c-9.95-4.469-20.962-6.977-32.555-6.977-11.591.0-22.602 2.507-32.548 6.975L220.653 162.025zm80.144 330.532 3.076-101.568c19.325-14.562 31.844-37.694 31.844-63.698.0-24.27-10.915-46.027-28.078-60.661l3.16-104.605h55.457l-26.618 330.532H300.797zm88.847.0h-30.501l26.618-330.532h44.766L389.644 492.557zm46.819-349.975H75.531c-3.986-5.588-6.171-12.266-6.171-19.21.0-15.23 10.052-28.041 24.192-31.923 5.136 7.347 14.332 15.089 27.853 15.089 1.412.0 2.87-.084 4.376-.262 5.086-.601 9.169-4.831 9.023-9.951-.169-5.868-5.336-10.151-11.005-9.396-10.908 1.458-15.263-7.828-16.038-9.747-.013-.032-.029-.062-.042-.095-.012-.027-.017-.057-.029-.084-.779-1.9-1.29-3.885-1.53-5.925-1.495-12.753 8.151-24.497 20.961-25.373 6.62-.452 12.93 1.908 17.606 6.533 1.819 1.799 4.249 2.929 6.806 2.967 4.322.064 8.035-2.652 9.379-6.564 4.598-13.379 17.192-22.369 31.338-22.369 9.432.0 18.433 4.035 24.706 11.075 1.729 1.94 4.172 3.177 6.769 3.314 4.373.231 8.223-2.412 9.675-6.342 3.285-8.897 11.862-14.876 21.341-14.876 9.948.0 18.848 6.611 21.743 16.113.844 2.769 2.688 5.187 5.322 6.388 4.237 1.929 9.045.642 11.766-2.852 6.344-8.145 15.88-12.817 26.163-12.817 12.52.0 23.811 7.04 29.437 17.921-1.79 2.84-3.768 6.681-5.037 11.285-3.664 13.302.342 26.651 11.28 37.59 1.898 1.899 4.386 2.848 6.874 2.848 2.445.0 4.889-.916 6.775-2.749 3.908-3.798 3.579-10.276-.227-14.178-5.623-5.764-7.618-11.593-6.097-17.81.165-.673.362-1.321.582-1.939 1.859-5.235 5.847-9.536 10.945-11.741 3.526-1.524 7.439-2.141 11.453-1.724 11.438 1.189 20.292 11.127 20.277 22.625-.004 2.949-.569 5.829-1.682 8.559-.872 2.139-.985 4.557-.26 6.751 1.247 3.773 4.581 6.325 8.393 6.66 16.932 1.484 30.195 15.978 30.195 33C442.642 130.32 440.454 136.998 436.463 142.582z"/></g></g><g><g><path fill="currentcolor" d="M261.257 62.341c-7.484.0-14.638 1.996-20.875 5.741-6.452-5.745-14.886-9.073-23.702-9.073-19.656.0-35.646 15.99-35.646 35.646s15.989 35.646 35.644 35.646c5.369.0 9.721-4.353 9.721-9.721.0-5.369-4.353-9.721-9.721-9.721-8.935.0-16.203-7.268-16.203-16.203s7.268-16.203 16.203-16.203c5.773.0 10.987 2.99 13.945 7.999 1.542 2.612 4.217 4.354 7.229 4.71 3.015.358 6.02-.714 8.128-2.893 4.047-4.182 9.473-6.484 15.277-6.484 11.725.0 21.264 9.539 21.264 21.266.0 5.369 4.351 9.722 9.721 9.722s9.721-4.353 9.721-9.722C301.965 80.603 283.704 62.341 261.257 62.341z"/></g></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></span></a></div><div class=site-footer-item><a href=https://play.spotify.com/user/1166811350><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 168 168"><path fill="currentcolor" d="m83.996.277C37.747.277.253 37.77.253 84.019c0 46.251 37.494 83.741 83.743 83.741 46.254.0 83.744-37.49 83.744-83.741.0-46.246-37.49-83.738-83.745-83.738l.001-.004zm38.404 120.78c-1.5 2.46-4.72 3.24-7.18 1.73-19.662-12.01-44.414-14.73-73.564-8.07-2.809.64-5.609-1.12-6.249-3.93-.643-2.81 1.11-5.61 3.926-6.25 31.9-7.291 59.263-4.15 81.337 9.34 2.46 1.51 3.24 4.72 1.73 7.18zm10.25-22.805c-1.89 3.075-5.91 4.045-8.98 2.155-22.51-13.839-56.823-17.846-83.448-9.764-3.453 1.043-7.1-.903-8.148-4.35-1.04-3.453.907-7.093 4.354-8.143 30.413-9.228 68.222-4.758 94.072 11.127 3.07 1.89 4.04 5.91 2.15 8.976v-.001zm.88-23.744c-26.99-16.031-71.52-17.505-97.289-9.684-4.138 1.255-8.514-1.081-9.768-5.219-1.254-4.14 1.08-8.513 5.221-9.771 29.581-8.98 78.756-7.245 109.83 11.202 3.73 2.209 4.95 7.016 2.74 10.733-2.2 3.722-7.02 4.949-10.73 2.739z"/></svg></span></a></div><div class=site-footer-item><a href=https://www.goodreads.com/user/show/67553795-lemax><span class=inline-svg><svg id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 463 463" style="enable-background:new 0 0 463 463"><g><path fill="currentcolor" d="M270.615 229.128l-24-72c-1.021-3.063-3.887-5.128-7.115-5.128s-6.094 2.066-7.115 5.128l-24 72c-.513 1.54-.513 3.204.0 4.743l24 72c1.021 3.063 3.887 5.128 7.115 5.128s6.094-2.066 7.115-5.128l24-72C271.128 232.332 271.128 230.668 270.615 229.128zM239.5 279.783 223.406 231.5l16.094-48.283 16.094 48.283L239.5 279.783z"/><path fill="currentcolor" d="M375.5 48h-64c-2.997.0-5.862.57-8.5 1.597V23.5C303 10.542 292.458.0 279.5.0h-80C186.542.0 176 10.542 176 23.5v42.097C173.362 64.57 170.497 64 167.5 64h-80C74.542 64 64 74.542 64 87.5v352c0 12.958 10.542 23.5 23.5 23.5h80c6.177.0 11.801-2.399 16-6.31 4.199 3.911 9.823 6.31 16 6.31h80c6.177.0 11.801-2.399 16-6.31 4.199 3.911 9.823 6.31 16 6.31h64c12.958.0 23.5-10.542 23.5-23.5v-368C399 58.542 388.458 48 375.5 48zM79 135h97v257H79V135zM191 87.5V87h97v289h-97V87.5zm97-16V72h-97V55h97V71.5zM191 391h97v17h-97V391zM303 119h81v273h-81V119zm8.5-56h64c4.687.0 8.5 3.813 8.5 8.5V104h-81V71.5C303 66.813 306.813 63 311.5 63zm-112-48h80c4.687.0 8.5 3.813 8.5 8.5V40h-97V23.5C191 18.813 194.813 15 199.5 15zM87.5 79h80c4.687.0 8.5 3.813 8.5 8.5V120H79V87.5c0-4.687 3.813-8.5 8.5-8.5zm80 369h-80c-4.687.0-8.5-3.813-8.5-8.5V407h97v32.5C176 444.187 172.187 448 167.5 448zm112 0h-80c-4.687.0-8.5-3.813-8.5-8.5V423h97v16.5C288 444.187 284.187 448 279.5 448zm96 0h-64c-4.687.0-8.5-3.813-8.5-8.5V407h81v32.5C384 444.187 380.187 448 375.5 448z"/><path fill="currentcolor" d="M374.615 253.128l-24-72c-1.021-3.063-3.887-5.128-7.115-5.128s-6.094 2.066-7.115 5.128l-24 72c-.513 1.54-.513 3.204.0 4.743l24 72c1.021 3.063 3.887 5.128 7.115 5.128s6.094-2.066 7.115-5.128l24-72C375.128 256.332 375.128 254.668 374.615 253.128zM343.5 303.783 327.406 255.5l16.094-48.283 16.094 48.283L343.5 303.783z"/><path fill="currentcolor" d="M158.615 261.128l-24-72c-1.021-3.063-3.887-5.128-7.115-5.128s-6.094 2.066-7.115 5.128l-24 72c-.513 1.54-.513 3.204.0 4.743l24 72c1.021 3.063 3.887 5.128 7.115 5.128s6.094-2.066 7.115-5.128l24-72C159.128 264.332 159.128 262.668 158.615 261.128zM127.5 311.783 111.406 263.5l16.094-48.283 16.094 48.283L127.5 311.783z"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></span></a></div><div class=site-footer-item><a href=mailto:maxhalford25@gmail.com><span class=inline-svg><svg viewBox="0 0 15 20" xmlns="http://www.w3.org/2000/svg"><title>mail</title><path fill="currentcolor" d="M0 4v8c0 .55.45 1 1 1h12c.55.0 1-.45 1-1V4c0-.55-.45-1-1-1H1c-.55.0-1 .45-1 1zm13 0L7 9 1 4h12zM1 5.5l4 3-4 3v-6zM2 12l3.5-3L7 10.5 8.5 9l3.5 3H2zm11-.5-4-3 4-3v6z" fill="#000" fill-rule="evenodd"/></svg></span></a></div></div><div style=margin-bottom:50px;display:flex;justify-content:center><iframe src=https://github.com/sponsors/MaxHalford/button title="Sponsor MaxHalford" height=35 width=116 style=border:0></iframe></div></div></div></article><script></script></body></html>