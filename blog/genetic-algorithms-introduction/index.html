<!doctype html><html lang=en><head><script defer src=https://unpkg.com/@tinybirdco/flock.js data-host=https://api.tinybird.co data-token=p.eyJ1IjogImMwMjJhMjg1LWJmY2YtNDc0OC1hYzczLTJhMDQ1Njk3NTI0YyIsICJpZCI6ICIzNjc3NjQ3Ny04MTE2LTRmYWQtYjcwMy1iZmM3YjMwZGJjMjMifQ.A0vHm-VWbXG6uBFZiwuspN_AyfSYNrdZE3IgwgWSt4g></script><meta charset=utf-8><meta name=generator content="Hugo 0.113.0"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Max Halford"><meta property="og:url" content="https://maxhalford.github.io/blog/genetic-algorithms-introduction/"><link rel=canonical href=https://maxhalford.github.io/blog/genetic-algorithms-introduction/><meta property="og:title" content="An introduction to genetic algorithms"><meta property="og:description" content="The goal of genetic algorithms (GAs) is to solve problems whose solutions are not easily found (ie. NP problems, nonlinear optimization, etc.). For example, finding the shortest path from A to B in a directed graph is easily done with Djikstra&rsquo;s algorithm, it can be solved in polynomial time. However the time to find the smallest path that joins all points on a non-directed graph, also known as the Travelling Salesman Problem (TSP) increases exponentially as the number of points increases."><meta property="og:type" content="article"><meta property="og:url" content="https://maxhalford.github.io/blog/genetic-algorithms-introduction/"><meta property="og:image" content="https://maxhalford.github.io/img/beach.jpg"><meta property="article:section" content="blog"><meta property="article:published_time" content="2015-08-02T00:00:00+00:00"><meta property="article:modified_time" content="2015-08-02T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://maxhalford.github.io/img/beach.jpg"><meta name=twitter:title content="An introduction to genetic algorithms"><meta name=twitter:description content="The goal of genetic algorithms (GAs) is to solve problems whose solutions are not easily found (ie. NP problems, nonlinear optimization, etc.). For example, finding the shortest path from A to B in a directed graph is easily done with Djikstra&rsquo;s algorithm, it can be solved in polynomial time. However the time to find the smallest path that joins all points on a non-directed graph, also known as the Travelling Salesman Problem (TSP) increases exponentially as the number of points increases."><link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¦”</text></svg>"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maxhalford.github.io\/"},"articleSection":"blog","name":"An introduction to genetic algorithms","headline":"An introduction to genetic algorithms","description":"The goal of genetic algorithms (GAs) is to solve problems whose solutions are not easily found (ie. NP problems, nonlinear optimization, etc.). For example, finding the shortest path from A to B in a directed graph is easily done with Djikstra\u0026rsquo;s algorithm, it can be solved in polynomial time. However the time to find the smallest path that joins all points on a non-directed graph, also known as the Travelling Salesman Problem (TSP) increases exponentially as the number of points increases.","inLanguage":"en-US","author":"Max Halford","creator":"Max Halford","publisher":"Max Halford","accountablePerson":"Max Halford","copyrightHolder":"Max Halford","copyrightYear":"2015","datePublished":"2015-08-02 00:00:00 \u002b0000 UTC","dateModified":"2015-08-02 00:00:00 \u002b0000 UTC","url":"https:\/\/maxhalford.github.io\/blog\/genetic-algorithms-introduction\/","keywords":["machine-learning"]}</script><title>An introduction to genetic algorithms â€¢ Max Halford</title><meta property="og:title" content="An introduction to genetic algorithms â€¢ Max Halford"><meta property="og:type" content="article"><meta name=description content="The goal of genetic algorithms (GAs) is to solve problems whose solutions are not easily found (ie. NP problems, nonlinear optimization, etc.). For example, finding the shortest path from A to B in a directed graph is easily done with Djikstra&rsquo;s algorithm, it can be solved in polynomial time. However the time to find the smallest path that joins all points on a non-directed graph, also known as the Travelling Salesman Problem (TSP) increases exponentially as the number of points increases."><link rel=stylesheet href=/css/flexboxgrid-6.3.1.min.css><link rel=stylesheet href=/css/github-markdown.min.css><link rel=stylesheet href=/css/highlight/github.css><link rel=stylesheet href=/css/index.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=PT+Serif:wght@400;700&family=Permanent+Marker&display=swap" rel=stylesheet><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><article class=post id=article><div class="row center-xs" style=text-align:left><div class="col-xs-12 col-sm-10 col-md-7 col-lg-5"><div class=header><header class=header-parts><div class="signatures site-title"><a href=/>Max Halford ðŸ¦”</a></div><div class=header-links><a class=header-link href=/>Blog</a>
<a class=header-link href=/links/>Links</a>
<a class=header-link href=/bio/>Bio</a></div></header></div><header class=post-header><h1 class=post-title>An introduction to genetic algorithms</h1><div class="row post-desc"><div class="col-xs-12 post-desc-items"><time class=post-date datetime="2015-08-02 00:00:00 UTC">2015-08-02</time>
<span class=posts-line-tag>machine-learning</span></div></div></header><div class="post-content markdown-body"><p>The goal of genetic algorithms (GAs) is to solve problems whose solutions are not easily found (ie. NP problems, nonlinear optimization, etc.). For example, finding the shortest path from A to B in a directed graph is easily done with <em>Djikstra&rsquo;s algorithm</em>, it can be solved in polynomial time. However the time to find the smallest path that joins all points on a non-directed graph, also known as the <a href=http://www.wikiwand.com/en/Travelling_salesman_problem>Travelling Salesman Problem</a> (TSP) increases exponentially as the number of points increases. More generally, GAs are useful for problems where an analytical approach is complicated or even impossible. By giving up on perfection they manage to find a good approximation of the optimal solution.</p><p>GAs are part of a higher class of algorithms: heuristic algorithms. Heuristic algorithms give up precision for power. They are not designed to find the optimal solution, instead they return a very good approximation of the solution. If the search space for the answer is quite smooth they even have a chance of finding the optimal solution. This is the point where some people give up reading because they want a simple algorithm that can solve anything. For those I recommend reading <a href=https://www.wikiwand.com/en/No_free_lunch_theorem>the following</a>.</p><p>Obviously GAs are not the only heuristic problem solvers out there, actually there are a lot of them. The two main benchmarks that rank them are <em>speed</em> and the <em>intelligence</em> of the program. Heuristic algorithms are greedy in resources, that&rsquo;s one of the reasons they were not very popular at a time when computers were not as powerful as they are today.</p><p>I have a lot of experience with GAs. I believe that they solve problems very well if they are properly tuned. With GAs I&rsquo;ve programmed a polynomial curve fitter, a TSP solver, a function optimization program and a racetrack car.</p><p>The first part of this notebook might seem a bit theoretical but I have to give some background to the examples given further on. For every application there is a different GA, the core stays the same but the randomness changes. It&rsquo;s important to understand the problem that to be solved and how the GA operates in order to make it reach it&rsquo;s full potential.</p><h2 id=approach>Approach</h2><h3 id=fitness-function>Fitness function</h3><p>To find the best solution we have to be able to measure the <em>performance</em> of a candidate solution. We want to be able to rank candidate solutions.</p><ul><li>In the case of the TSP this is the sum of distances between each consecutive node.</li><li>In the case of a function minimization problem, the measure is simply the function itself.</li><li>In the case of fitting a polynomial to a curve we can measure the least squares error.</li></ul><p>It is interesting to note that without knowing the global solution to a problem we know what properties it has. It might seem obvious that the best polynomial that fits a curve is the one that has the lowest least squares error, but for more complicated problems the fitness functions are not as obvious. In any case, pay attention when choosing the fitness function, it&rsquo;s crucial. On a side note, fitness functions are also called objective functions in the literature.</p><h3 id=dna>DNA</h3><p>By DNA I mean the parameters that are inputed into the objective function we want to optimize, these are the candidate solutions.</p><ul><li>In the case of the TSP the DNA is a list of consecutives nodes.</li><li>In the case of a function minimization problem, the DNA is a vector.</li><li>In the case of fitting a polynomial to a curve the DNA is a list of coefficients.</li></ul><p>The objective is to find the DNA that optimizes the chosen objective function.</p><h3 id=crossover>Crossover</h3><p>Say we have two DNAs that are <em>good</em> according to a fitness function. The idea of the crossover is to produce a new DNA by mixing up both DNAs. In the case of two vectors you could split both in half and create a new individual by sticking the first half of the first vector with the second part of the second vector. However crossovers are not always possible. For example you cannot take the first half of nodes in a TSP path and glue it with the second half of another path because there could be repetitions of nodes. It is mostly down to common sense and creativity, thus understanding the problem to be solved greatly helps. Crossovers can be very good at generating better DNAs, but if they are not based on some mathematical or logical background they could possibly make things worse.</p><h3 id=mutation>Mutation</h3><p>Some resources will briefly mention mutation, instead they will focus on crossovers. In my experience, mutations have had more success that crossovers. Mutations modify part of the DNA, they don&rsquo;t require mixing DNA up. For example for minimizing a multivariate function, we could modify a little bit one parameter and see if the fitness function returns a better value, if so then we can keep the mutation. By a little bit I mean, well, that&rsquo;s the problem, anything. If we suppose that we don&rsquo;t anything about what the solution looks like, then we don&rsquo;t have a preference between increasing or reducing the parameter, neither do we have any preference for the amplitude of the mutation. Therefore the mutation is <em>random</em>. The examples further on will make this clearer.</p><h3 id=population>Population</h3><p>A population is a group of potential solutions to a problem. At the beginning the population is composed of random DNAs (called individuals). Every step in time is called a generation. At each generation we have to pick a group of individuals that will reproduce to produce new (hopefully better) solutions. The new solutions are called <em>offsprings</em>. After having judiciously chosen $k$ individuals, every individual can generate $m$ offsprings. Thus every generation will be of size $k \times m$.</p><h3 id=selection>Selection</h3><p>If we have measured every individual in a population according to a fitness function we need a method for keeping a good subset that will produce new individuals. The most basic method is called <em>elitism selection</em>, very naively it simply keeps the $k$ best individuals. While this is a good short term selection method, nothing is certain on the long term. If at every generation the same lineage of individuals is selected then the population will not be very heterogenous. In other words the search space will not be fully explored and the candidate solutions will converge to a local optimum. The idea is to have a selection method that preserves variety in the population in order to have the most chances of finding the global optimum.</p><p>The literature often mentions <em>roulette selection</em>. Basically, you assign a relative fitness to each DNA (for example the DNA&rsquo;s fitness divided by the sum of all fitness), generate a random number between 0 and 1 and see where it lies. Of course the DNA with the highest fitness will get selected with a higher probability, however by experience I feel that this method still converges to local optima too fast. But don&rsquo;t take my word for granted! It&rsquo;s important to test each selection method for every problem. On a more or less convex space converging quickly can be a good thing because there are not many local optima to converge to.</p><p>My favorite selection method is called <em>tournament selection</em>. The idea is the following, select at random a sample of DNA of size $n$ and only keep the best individual. It&rsquo;s very simple, and yet it allows adjusting the convergence of the algorithm very easily. Indeed, if $n$ is small, then the best DNAs don&rsquo;t have a lot of chance of being selected and so it doesn&rsquo;t <em>kill</em> the other solutions quickly, thus preserving variety in the population. On the contrary, if $n$ is large then the best DNA quickly dominate and the algorithm converges quickly.</p><h3 id=convergence>Convergence</h3><p>We have to tell the algorithm when to stop. There are two ways of doing this:</p><ul><li>Generate offsprings a given number of times.</li><li>Stop when the population doesn&rsquo;t get better for a given period of time.</li></ul><h3 id=method>Method</h3><p>The algorithm runs as follows:</p><ol><li>Generate a random initial population.</li><li>Measure every individual of the population.</li><li>Select $k$ individuals with an appropriate method.</li><li>Cross/mutate them and create new individuals.</li><li>Save the best individuals from the old population and the new population.</li><li>Start over from step 2 as many times as you wish or when the population converges.</li></ol><p>I don&rsquo;t think I&rsquo;m being obnoxious in saying that the previous pseudo-algorithm is fairly simple. I won&rsquo;t comment on it, I think the best is to jump into some code and learn it the hard way. If you want to run the following code yourself you will have to <a href=https://github.com/MaxHalford/Genetic-Curve-Fitting>download it from GitHub</a>.</p><h2 id=example>Example</h2><h3 id=fitting-a-polynomial-curve-to-a-list-of-points>Fitting a polynomial curve to a list of points</h3><p>As an example I&rsquo;m going to be building a <em>polynomial curve fitter</em>. First of all the <a href=http://mathworld.wolfram.com/WeierstrassApproximationTheorem.html>Weierstrass Approximation Theorem</a> tells us that any smooth function can be pretty well approximated by a polynomial function. The idea is to find a curve that fits a list of points without knowing what function produced them.</p><p>A one variable polynomial of degree $n$ polynomial looks like</p><p>$$P(x) = a_0 + a_1x + a_2x^2 + a_3x^3 + \dots + a_nx^n$$</p><p>For the sake of simplicity we won&rsquo;t consider multivariate polynomials, however they are implemented. Also we won&rsquo;t consider non-linear multivariate polynomials, <em>ie.</em> where $x$ can multiply $y$ but this would be a good thing to do yourself.</p><p>The question is the following: which tuple of size $n+1$ $(a_0, a_1, a_2, \dots, a_n)$ gives the polynomial that best approximates a function $f(X)$, where $X$ is a vector of any size.</p><p>Let&rsquo;s define <em>the polynomial that bests approximates a function</em>. A good measure for this is the least squares. Indeed if we have a list of $k$ points $(x_i, y_i)$, we simply have to measure a candidate polynomial $P$ in every $x_i$ and measure the squared difference between $P(x_i)$ and $y_i$. One could also use the absolute value function instead of the square function.</p><h3 id=initialization>Initialization</h3><p>First of all let&rsquo;s generate a dataframe that contains a list of points. Do as you please! For this example I computed $x^2$ for $x$ between (-2, 2) with a step of size $0.2$. In this case we know which function generated the sample of points to fit so we can measure the performance of the GA. In this case if should return $x^2$.</p><p>Let&rsquo;s open it with the <em>pandas</em> module and convert it to a lookup table, <em>ie.</em> a dictionary where we can easily check for point values.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=c1># Create a dataframe</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mf>2.2</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>),</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;square&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>]</span> <span class=o>**</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=c1># Create the lookup table</span>
</span></span><span class=line><span class=cl><span class=n>lookupTable</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>record</span> <span class=ow>in</span> <span class=n>df</span><span class=o>.</span><span class=n>iterrows</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>key</span> <span class=o>=</span> <span class=n>record</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>lookupTable</span><span class=p>[</span><span class=n>key</span><span class=p>]</span> <span class=o>=</span> <span class=n>record</span><span class=p>[</span><span class=s1>&#39;square&#39;</span><span class=p>]</span>
</span></span></code></pre></div><h3 id=coding-the-genetic-algorithm>Coding the genetic algorithm</h3><p>Now let&rsquo;s create our genetic algorithm. I will organize everything in classes, so as to keep the syntax clean tidy. First of all let&rsquo;s import the needed modules.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy.random</span> <span class=k>as</span> <span class=nn>rand</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>copy</span> <span class=kn>import</span> <span class=n>deepcopy</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span></code></pre></div><p>And then let&rsquo;s create an <em>Individual</em> class, which is basically the DNA I was talking about earlier. It will be the object of what is composed a <em>Population</em>. The individual has two parameters:</p><ul><li>The list of coefficients that define a polynomial.</li><li>It&rsquo;s fitness.</li></ul><p>We can start by generating $c$ random coefficients where $c$ is the degree of the polynomial and is specified by the user. Indeed in real applications there is no reasonable way to know to which degree a polynomial should in order to best fit a given sample of points. Also, if we know that the points are sampled from a very high degree polynomial we may wish to fit the points with a lower degree, simpler, polynomial. Of course the degree could be taken into as another variable in the optimization process! However this is a tad more complicated to put in place and further users are welcome to put this in place for themselves.</p><p>The number of variables, <code>d</code>, is 1 in our case.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Individual</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># c is the number of coefficients</span>
</span></span><span class=line><span class=cl>    <span class=c1># d is the number of variables</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=n>d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Generate normal distributed coefficients for each variable</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>values</span> <span class=o>=</span> <span class=p>[[</span><span class=n>rand</span><span class=o>.</span><span class=n>normal</span><span class=p>()</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>c</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>                       <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>d</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fitness</span> <span class=o>=</span> <span class=kc>None</span>
</span></span></code></pre></div><p>Next we have to able to evaluate the performance (or <em>fitness</em>) of an individual, in other words how good it fits a list of points. For this we compute the squared error described previously.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>lookupTable</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fitness</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=c1># For each input</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>lookupTable</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>image</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>            <span class=c1># For each variable</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>variable</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>values</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># For each coefficient</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>power</span><span class=p>,</span> <span class=n>coefficient</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>variable</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=c1># Compute polynomial image</span>
</span></span><span class=line><span class=cl>                    <span class=n>image</span> <span class=o>+=</span> <span class=n>coefficient</span> <span class=o>*</span> <span class=n>x</span> <span class=o>**</span> <span class=n>power</span>
</span></span><span class=line><span class=cl>            <span class=c1># Compute squared error</span>
</span></span><span class=line><span class=cl>            <span class=n>target</span> <span class=o>=</span> <span class=n>lookupTable</span><span class=p>[</span><span class=n>x</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>mse</span> <span class=o>=</span> <span class=p>(</span><span class=n>target</span> <span class=o>-</span> <span class=n>image</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>fitness</span> <span class=o>+=</span> <span class=n>mse</span>
</span></span></code></pre></div><p>In this case I didn&rsquo;t work out any good crossover, instead I only implemented a simple mutation. Very naively, each coefficient can take a random value in its neighborhood. This is very crude and should be sophisticated for more precision. However as we will see it does the job for simple cases.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>mutate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>rate</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Coefficients take a random value in their neighborhood</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>values</span> <span class=o>=</span> <span class=p>[[</span><span class=n>rand</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=n>c</span> <span class=o>-</span> <span class=n>rate</span><span class=p>,</span> <span class=n>c</span> <span class=o>+</span> <span class=n>rate</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                       <span class=k>for</span> <span class=n>c</span> <span class=ow>in</span> <span class=n>variable</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                       <span class=k>for</span> <span class=n>variable</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>values</span><span class=p>]</span>
</span></span></code></pre></div><p>We also will need to extract the information about the individual in a clean manner. I won&rsquo;t delve into the next function, it&rsquo;s simply string manipulation.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>display</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>intercept</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span> <span class=p>(</span><span class=s1>&#39;Polynomial form&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span> <span class=p>(</span><span class=s1>&#39;---------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>index</span><span class=p>,</span> <span class=n>variable</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>values</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>intercept</span> <span class=o>+=</span> <span class=n>variable</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>power</span><span class=p>,</span> <span class=n>coefficient</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>variable</span><span class=p>[</span><span class=mi>1</span><span class=p>:]):</span>
</span></span><span class=line><span class=cl>                    <span class=nb>print</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>coefficient</span><span class=p>)</span> <span class=o>+</span> <span class=s1>&#39; * &#39;</span> <span class=o>+</span> <span class=s1>&#39;x&#39;</span> <span class=o>+</span> \
</span></span><span class=line><span class=cl>                          <span class=nb>str</span><span class=p>(</span><span class=n>index</span><span class=p>)</span> <span class=o>+</span> <span class=s1>&#39;**&#39;</span> <span class=o>+</span> <span class=nb>str</span><span class=p>(</span><span class=n>power</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=s1>&#39; + &#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span> <span class=p>(</span><span class=n>intercept</span><span class=p>)</span>
</span></span></code></pre></div><p>Now that we have defined an individual (you can call it DNA or polynomial if you wish, I just find that <em>individual</em> is more general), we have to create a list of individuals from which we will be able to compare and select individuals. Basically we have to create a list of individuals.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Population</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=n>d</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>100</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Create individuals</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>individuals</span> <span class=o>=</span> <span class=p>[</span><span class=n>Individual</span><span class=p>(</span><span class=n>c</span><span class=p>,</span> <span class=n>d</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>size</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=c1># Store the best individuals</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best</span> <span class=o>=</span> <span class=p>[</span><span class=n>Individual</span><span class=p>(</span><span class=n>c</span><span class=p>,</span> <span class=n>d</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=c1># Mutation rate</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>rate</span> <span class=o>=</span> <span class=mf>0.1</span>
</span></span></code></pre></div><p>The first parameter is a list comprehension that generates random individuals from the class created above. We will store the best individual so as not to lose it through unlucky mutations. We also define a mutation rate for the <code>mutate(rate)</code> procedure of the <code>Individual</code> class. The greater this rate the higher the amplitude of the changes of each coefficient of the polynomials. This avoids getting <em>stuck</em> and enables the population to generate more varied offsprings.</p><p>Next up we have to be able to sort the population according to each individual&rsquo;s fitness. This can be done with a one-liner in Python.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>sort</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>individuals</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>individuals</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>indi</span><span class=p>:</span> <span class=n>indi</span><span class=o>.</span><span class=n>fitness</span><span class=p>)</span>
</span></span></code></pre></div><p>However in order to sort the population we have to able to evaluate the population. We have already created a procedure to evaluate one individual so it is easy to generalize.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>lookupTable</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>indi</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>individuals</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>indi</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>lookupTable</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sort</span><span class=p>()</span>
</span></span></code></pre></div><p>Now for the (slightly) trickier part. We now have all the tools to evaluate, sort and modify a population. Let&rsquo;s put all the pieces together.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>enhance</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>lookupTable</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>newIndividuals</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=c1># Go through top 10 individuals</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>individual</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>individuals</span><span class=p>[:</span><span class=mi>10</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=c1># Create 1 exact copy of each top 10 individuals</span>
</span></span><span class=line><span class=cl>            <span class=n>newIndividuals</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>individual</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=c1># Create 4 mutated individuals</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>newIndividual</span> <span class=o>=</span> <span class=n>deepcopy</span><span class=p>(</span><span class=n>individual</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>newIndividual</span><span class=o>.</span><span class=n>mutate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>rate</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>newIndividuals</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>newIndividual</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Replace the old population with the new population</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>individuals</span> <span class=o>=</span> <span class=n>newIndividuals</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>lookupTable</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sort</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># Store the new best individual</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>individuals</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=c1># Increment the mutation rate if the population didn&#39;t change</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>best</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>fitness</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>best</span><span class=p>[</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>fitness</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>rate</span> <span class=o>+=</span> <span class=mf>0.01</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>rate</span> <span class=o>=</span> <span class=mf>0.1</span>
</span></span></code></pre></div><p>I think that the process speaks for itself but I will go through it in plain english. We create a list of new individuals. We go through each one of the top 10 individuals (this is elitism). We keep a copy of the individual and add it to the new population. Then we create 4 mutated versions of the individual (called <em>offsprings</em>) and add them to new population. Once we have generated our 50 new individuals ($10 \times (1 + 4)$) we replace the old population. Now we can evaluate the new population, sort it, add the new best individual to a list and keep on going.</p><p>A few remarks:</p><ul><li><p>The use of <code>deepcopy()</code> is out of the scope of this tutorial. Basically when we mutate a new individual we don&rsquo;t want to mutate the old individual. If we coded <code>newIndividual = individual</code> instead of <code>newIndividual = deepcopy(individual)</code> then both would be changed, voilÃ .</p></li><li><p>The last part of the enhancement is not essential but it starts addressing a larger problem: getting stuck in a local optima. The idea behind the four last lines is to check increase the mutation rate if the the new population doesn&rsquo;t contain a new best individual.</p></li><li><p>There is a of lot of room to move in this script. The number of offsprings, the number of individuals that are saved, the number of iterations, the mutation rate&mldr; These parameters should not affect the result too much, however if you are not satisfied with the end result then these are the culprits. In general it is always tinkering about with the parameters of the GA in order to get a satisfying result. This is the common of all heuristic algorithms: you need to hold their hand.</p></li></ul><h3 id=applying-it-to-our-simple-example>Applying it to our simple example</h3><p>Now, for the fun part, let&rsquo;s put it all into practice. As a refresher we are trying to fit a polynomial to the mono-variable square function. Let&rsquo;s define some parameters.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>generations</span> <span class=o>=</span> <span class=mi>300</span>
</span></span><span class=line><span class=cl><span class=n>degrees</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>variables</span> <span class=o>=</span> <span class=mi>1</span>
</span></span></code></pre></div><p>The <code>generations</code> parameter simply defines the number of times the GA will try and enhance the population. The more the better. Usually, after a certain number of iterations, the GA will get stuck on a local optima and no better offsprings will be produced, this is called a <code>convergence</code>.</p><p>Let&rsquo;s create an initial population and evaluate it a first time.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>polynomials</span> <span class=o>=</span> <span class=n>Population</span><span class=p>(</span><span class=n>degrees</span><span class=p>,</span> <span class=n>variables</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>polynomials</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>lookupTable</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>polynomials</span><span class=o>.</span><span class=n>sort</span><span class=p>()</span>
</span></span></code></pre></div><p>Let&rsquo;s enhance it 100 times.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Iterate through generations</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>g</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>generations</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Enhance the population</span>
</span></span><span class=line><span class=cl>    <span class=n>polynomials</span><span class=o>.</span><span class=n>enhance</span><span class=p>(</span><span class=n>lookupTable</span><span class=p>)</span>
</span></span></code></pre></div><p>And display the best polynomial.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>polynomials</span><span class=o>.</span><span class=n>best</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>display</span><span class=p>()</span>
</span></span></code></pre></div><pre><code>Polynomial form
---------------
0.010587779398717412 * x0**1 +
0.9804601148158121 * x0**2 +
0.04182274968452471
</code></pre><p>We wanted to find $x^2$ so this is pretty close! However the example was fairly simple, let&rsquo;s try it with something a tad more complicated.</p><h3 id=applying-it-to-more-complicated-data>Applying it to more complicated data</h3><p>Let&rsquo;s try to these a polynomial of degree 4 with more complex data.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=c1># Create a dataframe</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mf>2.2</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>),</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;square&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>]</span> <span class=o>**</span> <span class=mi>3</span> <span class=o>+</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>]</span> <span class=o>**</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=c1># Create the lookup table</span>
</span></span><span class=line><span class=cl><span class=n>lookupTable</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>record</span> <span class=ow>in</span> <span class=n>df</span><span class=o>.</span><span class=n>iterrows</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>key</span> <span class=o>=</span> <span class=n>record</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>lookupTable</span><span class=p>[</span><span class=n>key</span><span class=p>]</span> <span class=o>=</span> <span class=n>record</span><span class=p>[</span><span class=s1>&#39;square&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Parameters</span>
</span></span><span class=line><span class=cl><span class=n>generations</span> <span class=o>=</span> <span class=mi>300</span>
</span></span><span class=line><span class=cl><span class=n>degrees</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>variables</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize a population</span>
</span></span><span class=line><span class=cl><span class=n>polynomials</span> <span class=o>=</span> <span class=n>Population</span><span class=p>(</span><span class=n>degrees</span><span class=p>,</span> <span class=n>variables</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>polynomials</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>lookupTable</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>polynomials</span><span class=o>.</span><span class=n>sort</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Iterate through generations</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>g</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>generations</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Enhance the population</span>
</span></span><span class=line><span class=cl>    <span class=n>polynomials</span><span class=o>.</span><span class=n>enhance</span><span class=p>(</span><span class=n>lookupTable</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>polynomials</span><span class=o>.</span><span class=n>best</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>display</span><span class=p>()</span>
</span></span></code></pre></div><p>As a measure of how well the algorithm did check out the following graph.</p><p><img src=http://i.imgur.com/wAI6j3U.png alt="Genetic Curve fitting to more complicated data"></p><p>Not too shabby!</p><h2 id=remarks>Remarks</h2><p>There is still a lot to be said for this specific use case and many improvements can be made. However I think that the algorithm is not too complicated to put in place and doesn&rsquo;t require complicated mathematics. The example tries to mimic a more general problem: <em>interpolation</em>, a more mathematical approach to curve fitting that gets very messy once the number of points increases. The nice feature of this script is that the user can specify the degree of the polynomial he wants to fit.</p><p>The two main ways for improving the algorithm better are</p><ul><li>coding a better mutation.</li><li>implementing different selection methods.</li></ul><p>It&rsquo;s important to understand the philosophy of these algorithms, the idea is that the solutions they spit out will never be the same because they are heuristic in nature.</p><p>All the code is available <a href=https://github.com/MaxHalford/Genetic-Curve-Fitting>on my GitHub</a>. I added a few more things that were not essential for this tutorial (for example the code for producing plots). You&rsquo;ll need Python 3 to use it. Also everything is nicely packaged so that you can easily use it for other projects.</p><p>Thanks for reading this, I hope you enjoyed it.</p></div><script type=text/javascript>var s=document.createElement("script");s.setAttribute("src","https://utteranc.es/client.js"),s.setAttribute("repo","MaxHalford/maxhalford.github.io"),s.setAttribute("issue-term","pathname"),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",null),s.setAttribute("theme","github-light"),document.body.appendChild(s)</script><div style=display:flex;flex-direction:row;justify-content:center;align-items:center;gap:20px;margin-bottom:30px><div class=do-the-thing><div class=elevator><svg class="sweet-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" enable-background="new 0 0 100 100" height="100" width="100"><path d="M70 47.5H30c-1.4.0-2.5 1.1-2.5 2.5v40c0 1.4 1.1 2.5 2.5 2.5h40c1.4.0 2.5-1.1 2.5-2.5V50C72.5 48.6 71.4 47.5 70 47.5zm-22.5 40h-5v-25h5v25zm10 0h-5v-25h5v25zm10 0h-5V60c0-1.4-1.1-2.5-2.5-2.5H40c-1.4.0-2.5 1.1-2.5 2.5v27.5h-5v-35h35v35z"/><path d="M50 42.5c1.4.0 2.5-1.1 2.5-2.5V16l5.7 5.7c.5.5 1.1.7 1.8.7s1.3-.2 1.8-.7c1-1 1-2.6.0-3.5l-10-10c-1-1-2.6-1-3.5.0l-10 10c-1 1-1 2.6.0 3.5 1 1 2.6 1 3.5.0l5.7-5.7v24c0 1.4 1.1 2.5 2.5 2.5z"/></svg>Back to the top</div></div><iframe src=https://github.com/sponsors/MaxHalford/button title="Sponsor MaxHalford" height=32 width=114 style=border:0;border-radius:6px></iframe></div><script src=https://cdnjs.cloudflare.com/ajax/libs/elevator.js/1.0.1/elevator.min.js></script>
<script>var elementButton=document.querySelector(".elevator"),elevator=new Elevator({element:elementButton,mainAudio:"/music/elevator.mp3",endAudio:"/music/ding.mp3"})</script><style>.down-arrow{font-size:120px;margin-top:90px;margin-bottom:90px;text-shadow:0 -20px #0c1f31,0 0 #c33329;color:transparent;-webkit-transform:scaleY(.8);-moz-transform:scaleY(.8);transform:scaleY(.8)}.elevator{text-align:center;cursor:pointer;width:140px;margin:auto}.elevator:hover{opacity:.7}.elevator svg{width:40px;height:40px;display:block;margin:auto;margin-bottom:5px}</style></div></div></article><script></script></body></html>