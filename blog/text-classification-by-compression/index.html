<!doctype html><html lang=en>
<head>
<script async defer data-website-id=6023252a-3a97-470f-b4ee-5082d242bb9a src=https://umami.pourtan.eu/umami.js></script>
<meta charset=utf-8>
<meta name=generator content="Hugo 0.88.1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=author content="Max Halford">
<meta property="og:url" content="https://maxhalford.github.io/blog/text-classification-by-compression/">
<link rel=canonical href=https://maxhalford.github.io/blog/text-classification-by-compression/>
<link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¦”</text></svg>">
<script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maxhalford.github.io\/"},"articleSection":"blog","name":"Text classification by data compression","headline":"Text classification by data compression","description":"Edit: I posted this on Hackernews and got some valuable feedback. Many brought up the fact that you should be able to reuse the internal state of the compressor instead of recompressing the training data each time a prediction is made. There\u0026rsquo;s also some insightful references to data compression theory and its ties to statistical learning.\n Last night I felt like reading Artificial Intelligence: A Modern Approach. I stumbled on something fun in the natural language processing chapter.","inLanguage":"en-US","author":"Max Halford","creator":"Max Halford","publisher":"Max Halford","accountablePerson":"Max Halford","copyrightHolder":"Max Halford","copyrightYear":"2021","datePublished":"2021-06-08 00:00:00 \u002b0000 UTC","dateModified":"2021-06-08 00:00:00 \u002b0000 UTC","url":"https:\/\/maxhalford.github.io\/blog\/text-classification-by-compression\/","keywords":[]}</script>
<title>Text classification by data compression - Max Halford</title>
<meta property="og:title" content="Text classification by data compression - Max Halford">
<meta property="og:type" content="article">
<meta name=description content="Edit: I posted this on Hackernews and got some valuable feedback. Many brought up the fact that you should be able to reuse the internal state of the compressor instead of recompressing the training data each time a prediction is made. There&rsquo;s also some insightful references to data compression theory and its ties to statistical learning.
 Last night I felt like reading Artificial Intelligence: A Modern Approach. I stumbled on something fun in the natural language processing chapter.">
<link rel=stylesheet href=/css/flexboxgrid-6.3.1.min.css>
<link rel=stylesheet href=/css/github-markdown.min.css>
<link rel=stylesheet href=/css/highlight/github.css>
<link rel=stylesheet href=/css/index.css>
<link rel=preconnect href=https://fonts.gstatic.com>
<link href="https://fonts.googleapis.com/css2?family=PT+Serif:wght@400;700&family=Permanent+Marker&display=swap" rel=stylesheet>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:!0,processEnvironments:!0,tags:'ams'},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}},window.addEventListener('load',a=>{document.querySelectorAll('mjx-container').forEach(function(a){a.parentElement.classList+='has-jax'})})</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
</head>
<body>
<article class=post id=article>
<div class="row center-xs" style=text-align:left>
<div class="col-xs-12 col-sm-10 col-md-7 col-lg-5">
<div class=post-header>
<header>
<div class="signatures site-title">
<a href=/>Max Halford</a>
</div>
</header>
<div class="row end-xs">
<div>
<a class=header-link href=/>Blog</a>
<a class=header-link href=/links/>Links</a>
<a class=header-link href=/bio/>Bio</a>
</div>
</div>
<div class=header-line></div>
</div>
<header class=post-header>
<h1 class=post-title>Text classification by data compression</h1>
<div class="row post-desc">
<div class=col-xs-12>
<time class=post-date datetime="2021-06-08 00:00:00 UTC">
2021-06-08 Â· 6 minute read
</time>
</div>
</div>
</header>
<div class="post-content markdown-body">
<blockquote>
<p>Edit: I posted this <a href="https://news.ycombinator.com/item?id=27440093">on Hackernews</a> and got some valuable feedback. Many brought up the fact that you should be able to reuse the internal state of the compressor instead of recompressing the training data each time a prediction is made. There&rsquo;s also some insightful references to data compression theory and its ties to statistical learning.</p>
</blockquote>
<p>Last night I felt like reading <a href=http://aima.cs.berkeley.edu/><em>Artificial Intelligence: A Modern Approach</em></a>. I stumbled on something fun in the natural language processing chapter. The section I was reading dealt with classifying text. The idea of the particular subsection I was reading was to classify documents by using a <a href=https://www.wikiwand.com/en/Data_compression>compression algorithm</a>. This is such a left field idea, and yet it does make sense when you think about it. To quote the book:</p>
<blockquote>
<p>In effect, compression algorithms are creating a language model. The <a href=https://www.wikiwand.com/en/Lempel%E2%80%93Ziv%E2%80%93Welch>LZW algorithm</a> in particular directly models a maximum-entropy probability distribution.</p>
</blockquote>
<p>In other words, a compression algorithm has some knowledge of the distribution of words in a corpus. It can thus be used to classify documents. The learning algorithm is quite straightforward:</p>
<ol>
<li>Take a labeled training set of documents.</li>
<li>Build a single document per label by concatenating the texts that belong to that label.</li>
<li>Compress each obtained document and measure the size of each result.</li>
</ol>
<p>To classify a document, proceed as so:</p>
<ol>
<li>Concatenate the document with the concatenated document of each label.</li>
<li>Compress each of these concatenations and measure the size.</li>
<li>Return the label for which the size increased the least.</li>
</ol>
<p>The idea is that if a document is similar to the training texts associated with a particular label, they will share patterns that will get exploited by the compression algorithm. Ideally, the size increase of compressing the training texts with the new text should be correlated with the similarity between the text and the training texts. The smaller the increase, the more likely the label should be assigned.</p>
<p>I think this is an elegant idea. It&rsquo;s not sophisticated, and I don&rsquo;t expect it to perform better than a plain and simple logistic regression. Moreover, it&rsquo;s expensive because the training texts of each label have to be recompressed for each test document. Still, I found the idea intriguing and decided to implement it in Python.</p>
<p>Here I&rsquo;ll use the <a href=http://qwone.com/~jason/20Newsgroups/>newsgroup20 dataset</a> from scikit-learn. I&rsquo;m using the same four categories they use in their <a href=https://scikit-learn.org/stable/datasets/real_world.html#converting-text-to-vectors>user guide</a> to have something to compare against.</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>

<span class=n>categories</span> <span class=o>=</span> <span class=p>[</span>
    <span class=s1>&#39;alt.atheism&#39;</span><span class=p>,</span>
    <span class=s1>&#39;talk.religion.misc&#39;</span><span class=p>,</span>
    <span class=s1>&#39;comp.graphics&#39;</span><span class=p>,</span>
    <span class=s1>&#39;sci.space&#39;</span>
<span class=p>]</span>

<span class=n>train</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span>
    <span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>,</span>
    <span class=n>categories</span><span class=o>=</span><span class=n>categories</span>
<span class=p>)</span>
</code></pre></div><p>The first step is to concatenate the texts that belong to each of the four categories. I&rsquo;m adding a space before each text so that the last word isn&rsquo;t glued with the first word of the next text.</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>

<span class=n>label_texts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>str</span><span class=p>)</span>

<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>text</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train</span><span class=p>[</span><span class=s1>&#39;data&#39;</span><span class=p>]):</span>
    <span class=n>label</span> <span class=o>=</span> <span class=n>train</span><span class=p>[</span><span class=s1>&#39;target_names&#39;</span><span class=p>][</span><span class=n>train</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>][</span><span class=n>i</span><span class=p>]]</span>
    <span class=n>label_texts</span><span class=p>[</span><span class=n>label</span><span class=p>]</span> <span class=o>+=</span> <span class=s1>&#39; &#39;</span> <span class=o>+</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
</code></pre></div><p>The next step is to compress each of these big texts and measure the size of the compressed result. It&rsquo;s quite easy to do this in Python. Indeed, Python provides high-level functions that compress a sequence of bytes into a smaller sequence of bytes. The <code>len</code> method gives us the number of bytes in the sequence. I picked <a href=https://docs.python.org/3/library/gzip.html><code>gzip</code></a> at random from the compression methods listed <a href=https://docs.python.org/3/library/archiving.html>here</a>. Each of these provides an easy-to-use <a href=https://docs.python.org/3/library/gzip.html#gzip.compress><code>compress</code></a> method.</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=kn>import</span> <span class=nn>gzip</span>

<span class=n>METHOD</span> <span class=o>=</span> <span class=n>gzip</span>

<span class=n>original_sizes</span> <span class=o>=</span> <span class=p>{</span>
    <span class=n>label</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>METHOD</span><span class=o>.</span><span class=n>compress</span><span class=p>(</span><span class=n>text</span><span class=o>.</span><span class=n>encode</span><span class=p>()))</span>
    <span class=k>for</span> <span class=n>label</span><span class=p>,</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>label_texts</span><span class=o>.</span><span class=n>items</span><span class=p>()</span>
<span class=p>}</span>

<span class=nb>print</span><span class=p>(</span><span class=n>original_sizes</span><span class=p>)</span>
</code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=p>{</span>
    <span class=s1>&#39;comp.graphics&#39;</span><span class=p>:</span> <span class=mi>252268</span><span class=p>,</span>
    <span class=s1>&#39;talk.religion.misc&#39;</span><span class=p>:</span> <span class=mi>224228</span><span class=p>,</span>
    <span class=s1>&#39;sci.space&#39;</span><span class=p>:</span> <span class=mi>310524</span><span class=p>,</span>
    <span class=s1>&#39;alt.atheism&#39;</span><span class=p>:</span> <span class=mi>266440</span>
<span class=p>}</span>
</code></pre></div><p>That&rsquo;s all there is to the training phase. The training texts have to be kept in memory because they have to be used for the prediction phase. Let&rsquo;s say we&rsquo;re given a list of unlabeled texts. The idea for each text is to concatenate it with each training text, compress the result, and then measure the size of the compressed result.</p>
<p>When that&rsquo;s done, we just need to compare the obtained sizes with the original and return the label for which the size increased the least. Note that there is no notion of probability. There might be some weird way to cook up some probabilities, but they wouldn&rsquo;t be <a href=https://scikit-learn.org/stable/modules/calibration.html>calibrated</a>.</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=n>test</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;test&#39;</span><span class=p>,</span> <span class=n>categories</span><span class=o>=</span><span class=n>categories</span><span class=p>)</span>
<span class=n>predictions</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>test</span><span class=p>[</span><span class=s1>&#39;data&#39;</span><span class=p>]:</span>

    <span class=n>sizes</span> <span class=o>=</span> <span class=p>{</span>
        <span class=n>label</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>METHOD</span><span class=o>.</span><span class=n>compress</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>label_text</span><span class=si>}</span><span class=s1> </span><span class=si>{</span><span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span><span class=si>}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>encode</span><span class=p>()))</span>
        <span class=k>for</span> <span class=n>label</span><span class=p>,</span> <span class=n>label_text</span> <span class=ow>in</span> <span class=n>label_texts</span><span class=o>.</span><span class=n>items</span><span class=p>()</span>
    <span class=p>}</span>

    <span class=n>predicted_label</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span>
        <span class=n>sizes</span><span class=p>,</span>
        <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>label</span><span class=p>:</span> <span class=n>sizes</span><span class=p>[</span><span class=n>label</span><span class=p>]</span> <span class=o>-</span> <span class=n>original_sizes</span><span class=p>[</span><span class=n>label</span><span class=p>]</span>
    <span class=p>)</span>

    <span class=n>predictions</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>predicted_label</span><span class=p>)</span>
</code></pre></div><p>So how well does this fair? Well, it takes over 5 minutes to run on my laptop for only 1,353 test cases. That&rsquo;s 0.2 seconds per document, which is rather slow! Here&rsquo;s the classification report:</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>classification_report</span>

<span class=n>test_labels</span> <span class=o>=</span> <span class=p>[</span>
    <span class=n>test</span><span class=p>[</span><span class=s1>&#39;target_names&#39;</span><span class=p>][</span><span class=n>label</span><span class=p>]</span>
    <span class=k>for</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>test</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>]</span>
<span class=p>]</span>

<span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span>
    <span class=n>test_labels</span><span class=p>,</span>
    <span class=n>predictions</span><span class=p>,</span>
    <span class=n>digits</span><span class=o>=</span><span class=mi>3</span>
<span class=p>))</span>
</code></pre></div><pre tabindex=0><code>                    precision    recall  f1-score   support

       alt.atheism      0.678     0.680     0.679       319
     comp.graphics      0.784     0.897     0.837       389
         sci.space      0.878     0.746     0.807       394
talk.religion.misc      0.609     0.614     0.611       251

          accuracy                          0.749      1353
         macro avg      0.737     0.734     0.733      1353
      weighted avg      0.754     0.749     0.749      1353
</code></pre><p>Is that good? No, not really. A multinomial Naive Bayes classifier achieves a macro F1-score of 0.88 with the same categories and train/test split. It&rsquo;s also dramatically faster. Is there anything we can do? We can try other compression algorithms. Here are the results for <a href=https://docs.python.org/3/library/zlib.html><code>zlib</code></a>, which was a bit faster and took just over 4 minutes to run:</p>
<pre tabindex=0><code>                    precision    recall  f1-score   support

       alt.atheism      0.656     0.687     0.671       319
     comp.graphics      0.782     0.902     0.838       389
         sci.space      0.880     0.744     0.806       394
talk.religion.misc      0.612     0.578     0.594       251

          accuracy                          0.745      1353
         macro avg      0.732     0.728     0.727      1353
      weighted avg      0.749     0.745     0.744      1353
</code></pre><p>The performance with <code>zlib</code> seems to be worse than with <code>gzip</code>. What about <a href=https://docs.python.org/3/library/bz2.html><code>bz2</code></a>?</p>
<pre tabindex=0><code>                    precision    recall  f1-score   support

       alt.atheism      0.648     0.110     0.188       319
     comp.graphics      0.732     0.584     0.649       389
         sci.space      0.923     0.305     0.458       394
talk.religion.misc      0.271     0.928     0.420       251

          accuracy                          0.455      1353
         macro avg      0.644     0.482     0.429      1353
      weighted avg      0.682     0.455     0.442      1353
</code></pre><p>The performance is awful in comparison. Also, it took more than 7 minutes to run. Now how about <a href=https://docs.python.org/3/library/lzma.html><code>lzma</code></a>?</p>
<pre tabindex=0><code>                    precision    recall  f1-score   support

       alt.atheism      0.851     0.875     0.862       319
     comp.graphics      0.923     0.959     0.941       389
         sci.space      0.927     0.934     0.930       394
talk.religion.misc      0.866     0.773     0.817       251

          accuracy                          0.897      1353
         macro avg      0.892     0.885     0.888      1353
      weighted avg      0.897     0.897     0.896      1353
</code></pre><p>The performance is surprisingly good! But this comes at a cost: it took 32 minutes to complete, which is ~1.4 seconds per document. Still, it&rsquo;s very interesting to see this kind of result for an algorithm that wasn&rsquo;t at all designed to classify documents. Well, the <code>lzma</code> in fact implements the LZW algorithm that is mentioned in the <em>Artificial Intelligence: A Modern Approach</em> book, which might explain why it does so well!</p>
<p>There&rsquo;s probably some fine-tuning that could be done to improve this kind of approach. However, it would most probably not be worth using such an approach because of the prohibitive computational cost. This should simply be seen as an interesting example of thinking outside the box. It also goes to show that statistical modelling and information theory are very much intertwined.</p>
</div>
<script type=text/javascript>var s=document.createElement('script');s.setAttribute('src','https://utteranc.es/client.js'),s.setAttribute('repo','MaxHalford/maxhalford.github.io'),s.setAttribute('issue-term','pathname'),s.setAttribute('crossorigin','anonymous'),s.setAttribute('async',null),s.setAttribute('theme','github-light'),document.body.appendChild(s)</script>
<div class=footer>
<div class=do-the-thing>
<div class=elevator><svg class="sweet-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" enable-background="new 0 0 100 100" height="100" width="100"><path d="M70 47.5H30c-1.4.0-2.5 1.1-2.5 2.5v40c0 1.4 1.1 2.5 2.5 2.5h40c1.4.0 2.5-1.1 2.5-2.5V50C72.5 48.6 71.4 47.5 70 47.5zm-22.5 40h-5v-25h5v25zm10 0h-5v-25h5v25zm10 0h-5V60c0-1.4-1.1-2.5-2.5-2.5H40c-1.4.0-2.5 1.1-2.5 2.5v27.5h-5v-35h35v35z"/><path d="M50 42.5c1.4.0 2.5-1.1 2.5-2.5V16l5.7 5.7c.5.5 1.1.7 1.8.7s1.3-.2 1.8-.7c1-1 1-2.6.0-3.5l-10-10c-1-1-2.6-1-3.5.0l-10 10c-1 1-1 2.6.0 3.5 1 1 2.6 1 3.5.0l5.7-5.7v24c0 1.4 1.1 2.5 2.5 2.5z"/></svg>
Back to the top
</div>
</div>
</div>
<script src=https://cdnjs.cloudflare.com/ajax/libs/elevator.js/1.0.0/elevator.min.js></script>
<script>var elementButton=document.querySelector('.elevator'),elevator=new Elevator({element:elementButton,mainAudio:'/music/elevator.mp3',endAudio:'/music/ding.mp3'})</script>
<style>.down-arrow{font-size:120px;margin-top:90px;margin-bottom:90px;text-shadow:0 -20px #0c1f31,0 0 #c33329;color:transparent;-webkit-transform:scaleY(.8);-moz-transform:scaleY(.8);transform:scaleY(.8)}.elevator{text-align:center;cursor:pointer;width:140px;margin:auto}.elevator:hover{opacity:.7}.elevator svg{width:40px;height:40px;display:block;margin:auto;margin-bottom:5px}</style>
<div class=site-footer>
<div class=site-footer-item>
<a href=https://github.com/MaxHalford><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M8 0C3.58.0.0 3.582.0 8c0 3.535 2.292 6.533 5.47 7.59.4.075.547-.172.547-.385.0-.19-.007-.693-.01-1.36-2.226.483-2.695-1.073-2.695-1.073-.364-.924-.89-1.17-.89-1.17-.725-.496.056-.486.056-.486.803.056 1.225.824 1.225.824.714 1.223 1.873.87 2.33.665.072-.517.278-.87.507-1.07-1.777-.2-3.644-.888-3.644-3.953.0-.873.31-1.587.823-2.147-.09-.202-.36-1.015.07-2.117.0.0.67-.215 2.2.82.64-.178 1.32-.266 2-.27.68.004 1.36.092 2 .27 1.52-1.035 2.19-.82 2.19-.82.43 1.102.16 1.915.08 2.117.51.56.82 1.274.82 2.147.0 3.073-1.87 3.75-3.65 3.947.28.24.54.73.54 1.48.0 1.07-.01 1.93-.01 2.19.0.21.14.46.55.38C13.71 14.53 16 11.53 16 8c0-4.418-3.582-8-8-8"/></svg>
</span>
</a>
</div>
<div class=site-footer-item>
<a href=https://linkedin.com/in/maxhalford><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M13.632 13.635h-2.37V9.922c0-.886-.018-2.025-1.234-2.025-1.235.0-1.424.964-1.424 1.96v3.778h-2.37V6H8.51v1.04h.03c.318-.6 1.092-1.233 2.247-1.233 2.4.0 2.845 1.58 2.845 3.637v4.188zM3.558 4.955c-.762.0-1.376-.617-1.376-1.377.0-.758.614-1.375 1.376-1.375.76.0 1.376.617 1.376 1.375.0.76-.617 1.377-1.376 1.377zm1.188 8.68H2.37V6h2.376v7.635zM14.816.0H1.18C.528.0.0.516.0 1.153v13.694C0 15.484.528 16 1.18 16h13.635c.652.0 1.185-.516 1.185-1.153V1.153C16 .516 15.467.0 14.815.0z" fill-rule="nonzero"/></svg>
</span>
</a>
</div>
<div class=site-footer-item>
<a href=https://twitter.com/halford_max><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M16 3.038c-.59.26-1.22.437-1.885.517.677-.407 1.198-1.05 1.443-1.816-.634.37-1.337.64-2.085.79-.598-.64-1.45-1.04-2.396-1.04-1.812.0-3.282 1.47-3.282 3.28.0.26.03.51.085.75-2.728-.13-5.147-1.44-6.766-3.42C.83 2.58.67 3.14.67 3.75c0 1.14.58 2.143 1.46 2.732-.538-.017-1.045-.165-1.487-.41v.04c0 1.59 1.13 2.918 2.633 3.22-.276.074-.566.114-.865.114-.21.0-.41-.02-.61-.058.42 1.304 1.63 2.253 3.07 2.28-1.12.88-2.54 1.404-4.07 1.404-.26.0-.52-.015-.78-.045 1.46.93 3.18 1.474 5.04 1.474 6.04.0 9.34-5 9.34-9.33.0-.14.0-.28-.01-.42.64-.46 1.2-1.04 1.64-1.7z" fill-rule="nonzero"/></svg>
</span>
</a>
</div>
<div class=site-footer-item>
<a href=https://kaggle.com/maxhalford><span class=inline-svg><svg role="img" viewBox="0 0 26 26" xmlns="http://www.w3.org/2000/svg"><title>Kaggle icon</title><path fill="currentcolor" d="M18.825 23.859c-.022.092-.117.141-.281.141h-3.139c-.187.0-.351-.082-.492-.248l-5.178-6.589-1.448 1.374v5.111c0 .235-.117.352-.351.352H5.505c-.236.0-.354-.117-.354-.352V.353c0-.233.118-.353.354-.353h2.431c.234.0.351.12.351.353v14.343l6.203-6.272c.165-.165.33-.246.495-.246h3.239c.144.0.236.06.285.18.046.149.034.255-.036.315l-6.555 6.344 6.836 8.507c.095.104.117.208.07.358"/></svg>
</span>
</a>
</div>
<div class=site-footer-item>
<a href="https://scholar.google.com/citations?user=erRNNi0AAAAJ&hl=en"><span class=inline-svg><svg viewBox="0 0 1755 1755" xmlns="http://www.w3.org/2000/svg"><path fill="currentcolor" transform="translate(0 1610) scale(1 -1)" d="M896.76 1130.189c-27.618 30.838-59.618 46.19-95.802 46.19-40.952.0-72.382-14.738-94.288-44.15-21.906-29.322-32.864-64.848-32.864-106.584.0-35.548 5.998-71.738 18-108.64 11.958-36.886 31.524-69.814 58.954-98.838 27.334-29.096 59.144-43.616 95.284-43.616 40.288.0 71.76 13.502 94.332 40.492 22.476 26.954 33.756 60.98 33.756 101.962.0 34.904-5.954 71.454-17.906 109.664-11.894 38.262-31.752 72.784-59.466 103.52zm762.098 382.384c-64.358 64.424-141.86 96.57-232.572 96.57H329.144c-90.712.0-168.14-32.146-232.572-96.57-64.424-64.286-96.57-141.86-96.57-232.572V182.859c0-90.712 32.146-168.288 96.57-232.712 64.432-64.146 142-96.432 232.572-96.432h1097.142c90.712.0 168.214 32.286 232.572 96.57 64.432 64.432 96.644 141.86 96.644 232.572v1097.142c0 90.712-32.22 168.288-96.644 232.572zM1297.81 1154.159V762.033c0-18.154-14.856-33.016-33.016-33.016h-12.156c-18.162.0-33.016 14.856-33.016 33.016v392.126c0 16.12-2.34 29.578 20.188 32.41v52.172l-173.43-142.24c2.004-3.716 3.906-6.092 5.712-9.208 15.242-26.976 23.004-60.526 23.004-101.53.0-31.43-5.238-59.662-15.858-84.598-10.57-24.928-23.428-45.29-38.43-60.972-15.002-15.74-30.048-30.128-45.092-43.074-15.046-12.976-27.904-26.506-38.436-40.55-10.614-14-15.894-28.474-15.894-43.476.0-15.024 6.854-30.288 20.524-45.67 13.62-15.426 30.376-30.376 50.19-45.144 19.85-14.666 39.658-30.946 59.472-48.662 19.858-17.694 36.52-40.456 50.14-68.096 13.722-27.744 20.568-58.288 20.568-91.86.0-44.288-11.294-84.282-33.806-119.882-22.58-35.446-51.998-63.73-88.144-84.472-36.242-20.882-75-36.6-116.334-47.214-41.42-10.518-82.52-15.806-123.568-15.806-25.908.0-52.048 1.996-78.336 6.1-26.382 4.096-52.81 11.33-79.426 21.526-26.668 10.262-50.286 22.864-70.758 37.998-20.524 14.98-37.046 34.312-49.716 57.856-12.668 23.552-18.958 50.022-18.958 79.426.0 34.882 9.714 67.24 29.192 97.404 19.478 29.944 45.282 54.952 77.378 74.76 55.998 34.838 143.858 56.364 263.432 64.498-27.334 34.172-41.048 66.334-41.048 96.432.0 17.122 4.476 35.474 13.334 55.288-14.284-1.996-28.994-3.124-44.002-3.124-64.234.0-118.476 20.882-162.524 62.932-44.046 41.976-66.048 94.522-66.048 158.048.0 6.642.19 12.492.672 18.974H292.574l393.618 342.17h651.856l-60.24-47.024v-82.996c22.368-2.874 20.004-16.318 20.004-32.394zM900.382 544.929c-7.52 1.36-18.088 2.122-31.708 2.122-29.382.0-58.288-2.596-86.666-7.782-28.38-5.046-56.378-13.568-83.998-25.592-27.722-11.952-50.096-29.528-67.146-52.766-17.144-23.208-25.666-50.542-25.666-81.994.0-29.974 7.52-56.714 22.572-80.004 15.002-23.142 34.808-41.26 59.428-54.236 24.62-12.998 50.432-22.814 77.378-29.264 26.998-6.408 54.476-9.736 82.476-9.736 55.376.0 103.05 12.47 143.046 37.406 39.906 24.928 59.904 63.422 59.904 115.382.0 10.928-1.522 21.686-4.528 32.19-3.138 10.62-6.24 19.712-9.282 27.26-3.05 7.41-8.858 16.332-17.43 26.616-8.522 10.314-15.046 17.934-19.434 23.004-4.476 5.238-12.852 12.712-25.19 22.594-12.236 9.926-20.048 16.114-23.522 18.402-3.43 2.406-12.332 8.908-26.668 19.456-14.328 10.634-22.184 16.274-23.566 16.94z"/></svg>
</span>
</a>
</div>
<div class=site-footer-item>
<a href=/files/resume_max_halford.pdf><span class=inline-svg><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 392.533 392.533" style="enable-background:new 0 0 392.533 392.533"><g><g><path fill="currentcolor" d="M292.396 324.849H99.879c-6.012.0-10.925 4.848-10.925 10.925.0 6.012 4.849 10.925 10.925 10.925h192.582c6.012.0 10.925-4.849 10.925-10.925C303.321 329.697 298.473 324.849 292.396 324.849z"/></g></g><g><g><path fill="currentcolor" d="M292.396 277.01H99.879c-6.012.0-10.925 4.848-10.925 10.925.0 6.012 4.849 10.925 10.925 10.925h192.582c6.012.0 10.925-4.849 10.925-10.925C303.321 281.859 298.473 277.01 292.396 277.01z"/></g></g><g><g><path fill="currentcolor" d="M196.137 45.834c-25.859.0-46.998 21.075-46.998 46.998.0 25.859 21.139 46.933 46.998 46.933s46.998-21.075 46.998-46.998-21.139-46.933-46.998-46.933zm0 72.017c-13.77.0-25.083-11.313-25.083-25.083s11.248-25.083 25.083-25.083 25.083 11.313 25.083 25.083c0 13.769-11.313 25.083-25.083 25.083z"/></g></g><g><g><path fill="currentcolor" d="M258.521 163.362c-39.887-15.515-84.752-15.515-124.638.0-13.059 5.107-21.786 18.101-21.786 32.388v44.347c-.065 6.012 4.849 10.925 10.861 10.925h146.424c6.012.0 10.925-4.848 10.925-10.925V195.75C280.307 181.463 271.58 168.469 258.521 163.362zm0 65.874H133.883v-33.422c0-5.301 3.168-10.214 7.887-12.024 34.844-13.511 74.02-13.511 108.865.0 4.719 1.875 7.887 6.659 7.887 12.024v33.422z"/></g></g><g><g><path fill="currentcolor" d="M313.083.0H131.491c-8.404.0-16.291 3.232-22.238 9.18L57.018 61.414c-5.947 5.948-9.18 13.834-9.18 22.238v277.333c0 17.39 14.158 31.547 31.547 31.547h233.762c17.39.0 31.547-14.158 31.547-31.547V31.547C344.501 14.158 330.343.0 313.083.0zM112.032 37.236v27.022H85.01l27.022-27.022zm210.683 79.58h-40.598c-6.012.0-10.925 4.849-10.925 10.925.0 6.012 4.848 10.925 10.925 10.925h40.598v19.394h-14.869c-6.012.0-10.925 4.848-10.925 10.925.0 6.012 4.849 10.925 10.925 10.925h14.869v181.139c0 5.366-4.331 9.697-9.632 9.697H79.192c-5.301.0-9.632-4.331-9.632-9.632V86.044h53.398c6.012.0 10.925-4.848 10.925-10.925V21.721h179.2c5.301.0 9.632 4.331 9.632 9.632v85.463z"/></g></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg>
</span>
</a>
</div>
<div class=site-footer-item>
<a href=https://play.spotify.com/user/1166811350><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 168 168"><path fill="currentcolor" d="m83.996.277C37.747.277.253 37.77.253 84.019c0 46.251 37.494 83.741 83.743 83.741 46.254.0 83.744-37.49 83.744-83.741.0-46.246-37.49-83.738-83.745-83.738l.001-.004zm38.404 120.78c-1.5 2.46-4.72 3.24-7.18 1.73-19.662-12.01-44.414-14.73-73.564-8.07-2.809.64-5.609-1.12-6.249-3.93-.643-2.81 1.11-5.61 3.926-6.25 31.9-7.291 59.263-4.15 81.337 9.34 2.46 1.51 3.24 4.72 1.73 7.18zm10.25-22.805c-1.89 3.075-5.91 4.045-8.98 2.155-22.51-13.839-56.823-17.846-83.448-9.764-3.453 1.043-7.1-.903-8.148-4.35-1.04-3.453.907-7.093 4.354-8.143 30.413-9.228 68.222-4.758 94.072 11.127 3.07 1.89 4.04 5.91 2.15 8.976v-.001zm.88-23.744c-26.99-16.031-71.52-17.505-97.289-9.684-4.138 1.255-8.514-1.081-9.768-5.219-1.254-4.14 1.08-8.513 5.221-9.771 29.581-8.98 78.756-7.245 109.83 11.202 3.73 2.209 4.95 7.016 2.74 10.733-2.2 3.722-7.02 4.949-10.73 2.739z"/></svg>
</span>
</a>
</div>
<div class=site-footer-item>
<a href=mailto:maxhalford25@gmail.com><span class=inline-svg><svg viewBox="0 0 15 20" xmlns="http://www.w3.org/2000/svg"><title>mail</title><path fill="currentcolor" d="M0 4v8c0 .55.45 1 1 1h12c.55.0 1-.45 1-1V4c0-.55-.45-1-1-1H1c-.55.0-1 .45-1 1zm13 0L7 9 1 4h12zM1 5.5l4 3-4 3v-6zM2 12l3.5-3L7 10.5 8.5 9l3.5 3H2zm11-.5-4-3 4-3v6z" fill="#000" fill-rule="evenodd"/></svg>
</span>
</a>
</div>
<div class=site-footer-item>
<a href=/index.xml><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M12.8 16C12.8 8.978 7.022 3.2.0 3.2V0c8.777.0 16 7.223 16 16h-3.2zM2.194 11.61c1.21.0 2.195.985 2.195 2.196.0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017.0 13.806c0-1.21.983-2.195 2.194-2.195zM10.606 16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818.0 10.606 4.79 10.606 10.607z"/></svg>
</span>
</a>
</div>
</div>
<div style=margin-bottom:50px;display:flex;justify-content:center>
<iframe src=https://github.com/sponsors/MaxHalford/button title="Sponsor MaxHalford" height=35 width=116 style=border:0></iframe>
</div>
</div>
</div>
</article>
<script></script>
</body>
</html>