<!doctype html><html lang=en><head><script defer src=https://unpkg.com/@tinybirdco/flock.js data-host=https://api.tinybird.co data-token=p.eyJ1IjogImMwMjJhMjg1LWJmY2YtNDc0OC1hYzczLTJhMDQ1Njk3NTI0YyIsICJpZCI6ICIzNjc3NjQ3Ny04MTE2LTRmYWQtYjcwMy1iZmM3YjMwZGJjMjMifQ.A0vHm-VWbXG6uBFZiwuspN_AyfSYNrdZE3IgwgWSt4g></script><meta charset=utf-8><meta name=generator content="Hugo 0.123.7"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Max Halford"><meta property="og:url" content="https://maxhalford.github.io/slides/the-benefits-of-online-learning/"><link rel=canonical href=https://maxhalford.github.io/slides/the-benefits-of-online-learning/><meta property="og:title" content><meta property="og:description" content="<!DOCTYPE html> The Benefits of Online Learning class: center, middle ## The Benefits of Online Learning ### (and other shenanigans) #### Max Halford      ??? Hello! --- class: middle ## Outline    --- ### A bit about me .left-column[    ] .right-column[ - 3rd year PhD student in Toulouse - PhD on Bayesian networks applied to database cost models - Topics of interest: - Online machine learning - Systems for machine learning - Machine learning for systems - Competitive machine learning - Fair and explainable learning - Into opensource (mostly Python) - Kaggle Master (rank 247) ] --- ### Batch learning in a nutshell ."><meta property="og:type" content="article"><meta property="og:url" content="https://maxhalford.github.io/slides/the-benefits-of-online-learning/"><meta property="og:image" content="https://maxhalford.github.io/img/belle-ile.jpg"><meta property="article:section" content="slides"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://maxhalford.github.io/img/belle-ile.jpg"><meta name=twitter:title content><meta name=twitter:description content="<!DOCTYPE html> The Benefits of Online Learning class: center, middle ## The Benefits of Online Learning ### (and other shenanigans) #### Max Halford      ??? Hello! --- class: middle ## Outline    --- ### A bit about me .left-column[    ] .right-column[ - 3rd year PhD student in Toulouse - PhD on Bayesian networks applied to database cost models - Topics of interest: - Online machine learning - Systems for machine learning - Machine learning for systems - Competitive machine learning - Fair and explainable learning - Into opensource (mostly Python) - Kaggle Master (rank 247) ] --- ### Batch learning in a nutshell ."><link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü¶Ü</text></svg>"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maxhalford.github.io\/"},"articleSection":"slides","name":"","headline":"","description":"\u003c!DOCTYPE html\u003e The Benefits of Online Learning class: center, middle ## The Benefits of Online Learning ### (and other shenanigans) #### Max Halford \u003cdiv style=\u0022display: flex; flex-direction: row; justify-content: center;\u0022\u003e \u003cdiv align=\u0022center\u0022\u003e \u003cimg height=\u0022180px\u0022 src=\u0022\/img\/slides\/creme\/creme.svg\u0022 \/\u003e \u003c\/div\u003e \u003c\/div\u003e ??? Hello! --- class: middle ## Outline \u003cdiv align=\u0022center\u0022\u003e \u003cimg height=\u0022300px\u0022 src=\u0022\/img\/slides\/creme\/knowledge.jpg\u0022 \/\u003e \u003c\/div\u003e --- ### A bit about me .left-column[ \u003cdiv align=\u0022center\u0022\u003e \u003cimg height=\u0022500px\u0022 src=\u0022\/img\/slides\/creme\/moneyball.jpg\u0022 \/\u003e \u003c\/div\u003e ] .right-column[ - 3rd year PhD student in Toulouse - PhD on Bayesian networks applied to database cost models - Topics of interest: - Online machine learning - Systems for machine learning - Machine learning for systems - Competitive machine learning - Fair and explainable learning - Into opensource (mostly Python) - Kaggle Master (rank 247) ] --- ### Batch learning in a nutshell .","inLanguage":"en-US","author":"Max Halford","creator":"Max Halford","publisher":"Max Halford","accountablePerson":"Max Halford","copyrightHolder":"Max Halford","copyrightYear":"0001","datePublished":"0001-01-01 00:00:00 \u002b0000 UTC","dateModified":"0001-01-01 00:00:00 \u002b0000 UTC","url":"https:\/\/maxhalford.github.io\/slides\/the-benefits-of-online-learning\/","keywords":[]}</script><title>‚Ä¢ Max Halford</title>
<meta property="og:title" content=" ‚Ä¢ Max Halford"><meta property="og:type" content="article"><meta name=description content="<!DOCTYPE html> The Benefits of Online Learning class: center, middle ## The Benefits of Online Learning ### (and other shenanigans) #### Max Halford      ??? Hello! --- class: middle ## Outline    --- ### A bit about me .left-column[    ] .right-column[ - 3rd year PhD student in Toulouse - PhD on Bayesian networks applied to database cost models - Topics of interest: - Online machine learning - Systems for machine learning - Machine learning for systems - Competitive machine learning - Fair and explainable learning - Into opensource (mostly Python) - Kaggle Master (rank 247) ] --- ### Batch learning in a nutshell ."><link rel=stylesheet href=/css/flexboxgrid-6.3.1.min.css><link rel=stylesheet href=/css/github-markdown.min.css><link rel=stylesheet href=/css/highlight/github.css><link rel=stylesheet href=/css/index.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=PT+Serif:wght@400;700&family=Permanent+Marker&display=swap" rel=stylesheet><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,tags:"ams"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><article class=post id=article><div class="row center-xs" style=text-align:left><div class="col-xs-12 col-sm-10 col-md-7 col-lg-5"><div class=header><header class=header-parts><div class="signatures site-title"><a href=/>Max Halford ü¶Ü</a></div><div class=header-links><a class=header-link href=/>Blog</a>
<a class=header-link href=/links/>Links</a>
<a class=header-link href=/bio/>Bio</a></div></header></div><header class=post-header><h1 class=post-title></h1></header><div class="post-content markdown-body"><!doctype html><html><head><title>The Benefits of Online Learning</title>
<meta charset=utf-8><style>@import "https://fonts.googleapis.com/css?family=Open+Sans:700";@import "https://fonts.googleapis.com/css?family=Fira+Mono:400,700,400italic";body,h1,h2,h3{font-family:open sans}h1,h2,h3{text-align:center}.bullets{display:flex;flex-direction:row;justify-content:center}.bigbullets{display:flex;flex-direction:row;justify-content:center;font-size:35px}.remark-slide-content{font-size:25px;color:#1f282d}.remark-code,.remark-inline-code{font-family:fira mono}.remark-inline-code{background:#f0f0f0;padding:0 4px}.left-column{width:50%;float:left}.right-column{width:50%;float:right}.white{color:snow}.title-slide .remark-slide-number{display:none}blockquote{background:#f9f9f9;border-left:10px solid #ccc;margin:1.5em 10px;padding:.5em 10px;quotes:"\201C""\201D""\2018""\2019"}blockquote:before{color:#ccc;content:open-quote;font-size:4em;line-height:.1em;margin-right:.25em;vertical-align:-.4em}blockquote p{display:inline}a{color:hotpink;text-decoration:none}li{margin:10px 0}.green{color:green}.red{color:red}.pure-table{font-size:17px;border-style:hidden!important}.pure-table td{border-left:0!important}.pure-table th{border-left:0!important}</style></head><body><textarea id=source>

class: center, middle

## The Benefits of Online Learning

### (and other shenanigans)

#### Max Halford

<div style="display: flex; flex-direction: row; justify-content: center;">

  <div align="center">
    <img height="180px" src="/img/slides/creme/creme.svg" />
  </div>

</div>

???

Hello!

---

class: middle

## Outline

<div align="center">
  <img height="300px" src="/img/slides/creme/knowledge.jpg" />
</div>

---

### A bit about me

.left-column[
<div align="center">
  <img height="500px" src="/img/slides/creme/moneyball.jpg" />
</div>
]

.right-column[
- 3rd year PhD student in Toulouse
- PhD on Bayesian networks applied to database cost models
- Topics of interest:
  - Online machine learning
  - Systems for machine learning
  - Machine learning for systems
  - Competitive machine learning
  - Fair and explainable learning
- Into opensource (mostly Python)
- Kaggle Master (rank 247)
]

---

### Batch learning in a nutshell

.bullets[
1. Collect features $X$ and labels $Y$
2. Train a model on $(X, Y)$
3. Save the model somewhere
4. Load the model to make predictions
]

With code:

```python
>>> model.fit(X_train, y_train)
>>> dump(model, 'model.json')
>>> model = load('model.json')
>>> y_pred = model.predict(X_test)
```

---

## Lambda architecture

<div align="center">
  <img height="500px" src="/img/slides/creme/lambda_architecture.svg" />
</div>

---

background-color: #e66868ff
class: middle, white

## Batch learning in production has issues

.bigbullets[

1. Models are retrained from scratch with new data üïí
2. Models require powerful machines üí∞
3. Models are static and "rot" faster than bananas üçå
4. Models that work in development don't always work in production  ü§∑
]

???

- [Continuum: a platform for cost-aware low-latency continual learning](https://blog.acolyer.org/2018/11/21/continuum-a-platform-for-cost-aware-low-latency-continual-learning/)
- [Applied machine learning at Facebook: a datacenter infrastructure perspective](https://blog.acolyer.org/2018/12/17/applied-machine-learning-at-facebook-a-datacenter-infrastructure-perspective/)

As we looked at last month with Continuum, the latency of incorporating the latest data into the models is also really important. There‚Äôs a nice section of this paper where the authors study the impact of losing the ability to train models for a period of time and have to serve requests from stale models. The Community Integrity team for example rely on frequently trained models to keep up with the ever changing ways adversaries try to bypass Facebook‚Äôs protections and show objectionable content to users. Here training iterations take on the order of days. Even more dependent on the incorporation of recent data into models is the news feed ranking. ‚ÄúStale News Feed models have a measurable impact on quality.‚Äù And if we look at the very core of the business, the Ads Ranking models, ‚Äúwe learned that the impact of leveraging a stale ML model is measured in hours. In other words, using a one-day-old model is measurably worse than using a one-hour old model.‚Äù One of the conclusions in this section of the paper is that disaster recovery / high availability for training workloads is key importance. (Another place to practice your chaos engineering ;) ).

---

## Banana rotting time

<div align="center">
  <img height="440px" src="/img/slides/creme/banana_rotting_time.png" />
</div>

---

### "If everyone's doing it, it's got to be the best way, right?"

<div align="center">
  <img height="480px" src="/img/slides/creme/everyone_is_doing_it.png" />
</div>

---

## Kappa architecture

<div align="center">
  <img height="500px" src="/img/slides/creme/kappa_architecture.svg" />
</div>

???

This looks great, but our favorite models such as LightGBM, can be updated incrementally.

---

background-color: #b5ddd1
class: middle

## Online machine learning

.bigbullets[
- Subdiscipline of machine learning
- Data is a stream, potentially infinite
- Models learn from one observation at a time
- Features and labels can be dynamic
- Can be supervised or unsupervised
]

---

background-color: #2ac380
class: middle, white

## Different names, same thing ü§î

.bigbullets[
- Online learning
- Incremental learning
- Sequential learning
- Iterative learning
- Continuous learning
- Out-of-core learning
]

---

background-color: #607bd4
class: middle, white

## Benefits of online machine learning

.bigbullets[
1. Models don't have to be retrained
2. Nothing is too big
3. Online models (usually) adapt to drift
4. Model development is closer to reality
5. Training can be monitored in real-time
]

---

background-color: #e69138
class: middle, white

## Applications

.bigbullets[
- Time series forecasting
- Spam filtering
- Recommender systems
- Ad placement
- Internet of things
- Basically, <span style="text-decoration:underline">anything event based</span>
]

---

background-color: #FF7F50
class: middle, white

## Why is batch learning so popular?

.bigbullets[
- Taught at university üéì
- (Bad) habits
- Hype
- Kaggle üéØ
- Library availability
]

---

class: center, middle

<img height="400px" src="/img/slides/creme/edward-bear-bump-bump.png" />

> It is, as far as he knows, the only way of coming downstairs, but sometimes he feels that there really is another way, if only he could stop bumping for a moment and think of it.

???

And just like Winnie the Pooh, we're spending too much time banging our heads to be able to think about a better way of doing things.

---

class: middle

<div align="center">
  <img height="250" src="/img/slides/creme/creme.svg" alt="creme_logo"/>
</div>

.bullets[
- Online machine learning library for Python üêç
- Easy to pick up API inspired by scikit-learn
- Written with production scenarios in mind
- First commit in January 2019
- Version `0.4.3` released this week (with wheels!)
]

---

class: center, middle

### PyData Amsterdam, May 2019 üêç üá≥üá± üßÄ

<div align="center">
  <img height="400px" src="/img/slides/creme/max_pydata.jpg" />
</div>

---

class: middle

### Features

Representing a set of features using a `dict` is natural:

```python
x = {
    'date': dt.datetime(2019, 4, 22),
    'price': 42.95,
    'shop': 'Ikea'
}
```

- Values can be of any type
- Feature names can be used instead of array indexes
- Web request payloads are dictionaries

---

class: middle

### Targets

A target's type depends on the context:

```python
# Regression
y = 42

# Binary classification
y = True

# Multi-class classification
y = 'setosa'

# Multi-output regression
y = {
    'height': 29.7,
    'width': 21
}
```

---

class: middle

### Streaming data

```python
from creme import stream

X_y = stream.iter_csv('some/csv/file.csv')

for x, y in X_y:
    print(x, y)
```

- `X_y` is a **generator**, it doesn't hold data in memory
- Source depends on your use case (CSV file, Kafka consumer, HTTP requests)

---

class: middle

### Training with `fit_one`

```python
from creme import linear_model
from creme import stream

X_y = stream.iter_csv('some/csv/file.csv')

model = linear_model.LogisticRegression()

for x, y in X_y:
*   model.fit_one(x, y)
```

Every `creme` estimator has a `fit_one` method

---

class: middle

### Predicting with `predict_one`

```python
from creme import linear_model
from creme import stream

X_y = stream.iter_csv('some/csv/file.csv')

model = linear_model.LogisticRegression()

for x, y in X_y:
*   y_pred = model.predict_one(x)
    model.fit_one(x, y)
```

- Classifiers also have a `predict_proba_one` method
- Transformers have a `transform_one` method
- Training and predicting phases are inter-leaved

---

class: middle

### Progressive validation üíØ

```python
from creme import linear_model
from creme import metrics
from creme import stream

X_y = stream.iter_csv('some/csv/file.csv')

model = linear_model.LogisticRegression()

metric = metrics.Accuracy()

for x, y in X_y:
    y_pred = model.predict_one(x)
    model.fit_one(x, y)
*   metric.update(y, y_pred)
    print(metric)
```

Validation score is available for free! No need for cross-validation. You can also use `online_score` from the `model_selection` module.

---

class: middle

### Composing estimators is easy

.left-column[
```python
from creme import *

counts = feature_extraction.CountVectorizer()
tdidf = feature_extraction.TFIDFVectorizer()

scale = preprocessing.StandardScaler()

log_reg = linear_model.LogisticRegression()

model = (counts + tdidf) | scale | log_reg

model.draw()
```
]

.right-column[
<div align="center">
  <img height="400px" src="/img/slides/creme/pipeline.svg" />
</div>
]

---

### Online mean

For every incoming $x$, do:

1. $n = n + 1$
2. $\mu\_{i+1} = \mu\_{i} + \frac{x - \mu\_{i}}{n}$

```python
>>> mean = creme.stats.Mean()

>>> mean.update(5)
>>> mean.get()
5

>>> mean.update(10)
>>> mean.get()
7.5
```

---

### Online variance

For every incoming $x$, do:

1. $n = n + 1$
2. $\mu\_{i+1} = \mu\_{i} + \frac{x - \mu\_{i}}{n}$
3. $s\_{i+1} = s\_i + (x - \mu\_{i}) \times (x - \mu\_{i+1})$
4. $\sigma\_{i+1} = \frac{s\_{i+1}}{n}$

```python
>>> variance = creme.stats.Variance()

>>> X = [2, 3, 4, 5]
>>> for x in X:
...     variance.update(x)
>>> variance.get()
1.25

>>> numpy.var(X)
1.25

```

???

This is called Welford's algorithm, it can be extended to skew and kurtosis

---

class: middle

### Standard scaling

Using the mean and the variance, we can rescale incoming data.

```python
>>> scaler = creme.preprocessing.StandardScaler()

>>> for x in [2, 3, 4, 5]:
...     features = {'x': x}
...     scaler.fit_one(features)
...     new_x = scaler.transform_one(features)['x']
...     print(f'{x} becomes {new_x})
2 becomes 0.0
3 becomes 0.9999999999999996
4 becomes 1.224744871391589
5 becomes 1.3416407864998738

```

In practice, works better than normalized gradient descent üò≤

---

class: middle

### Linear models

Model is:

$$\hat{y}_t = f(w_t, x_t) + b_t$$

Update weights with gradients:

$$w_{t+1}  = u(w_t, x_t, \partial L(y_t, \hat{y}_t))$$

Many models can be derived, for example:

- Use Hinge loss for SVM
- Add L1/L2 regularisation for LASSO/ridge
- Add interactions for factorization machines

---

class: middle

### Many online optimizers to choose from

.bullets[
- Stochastic gradient descent (SGD)
- Passive-Aggressive (PA)
- ADAM
- RMSProp
- Follow the Regularized Leader (FTRL)
- Approximate Large Margin Algorithm (ALMA)
]

<div align="center">
Many variants of each, as you know
</div>

---

class: middle

### Bayesian linear models

We want the posterior target distribution on the target:

$$\color{forestgreen} p(y\_t | x\_t) \color{black} \propto \color{crimson} p(y_t | w_t, x_t) \color{royalblue} p(w_t)$$

We first need to compute the posterior distribution of the weights:

$$\color{blueviolet} p(w\_{t} | w\_{t-1}, x\_t, y\_t) \color{black} \propto \color{crimson} p(y\_t | w\_{t-1}, x\_t) \color{royalblue} p(w\_{t-1})$$

This is old-school Bayesian learning, it is different from and predecesses the Monte-Carlo mumbo-jumbo.

---

class: middle

### Online belief updating

Before any data comes in, the model parameters follow the initial distribution we picked, which is $\color{royalblue} p(w\_0)$. Next, once the first observation $(x\_0, y\_0)$ arrives, we can obtain the distribution of $w\_1$:

$$\color{blueviolet} p(w\_1 | w\_0, x\_0, y\_0) \color{black} \propto \color{crimson} p(y\_0 | w\_0, x\_0) \color{royalblue} p(w\_0)$$

Once the second observation $(x\_1, y\_1)$ is available, the distribution of the model parameters is obtained in the same way:

$$\color{blueviolet} p(w\_2 | w\_1, x\_1, y\_1) \color{black} \propto \color{crimson} p(y\_1 | w\_1, x\_1) \color{royalblue} p(w\_1) \propto \color{crimson} p(y\_1 | w\_1, x\_1) \color{blueviolet} p(w\_1 | w\_0, x\_0, y\_0)$$

The $\propto$ symbol means there is an analytical formula that can be derived.

---

class: middle

### Nearest neighbors

.bullets[
- Three parameters:
  1. The distance function
  2. The number of neighbors
  3. The window size
- .green[Naturally adapts to drift]
- .red[Lazy]
]

---

class: middle

### Decision trees üå≥

- A version of Hoeffding trees is being implemented
- Basic idea:
  - Start with a leaf üçÉ
  - Find the leaf where an observation belongs üîé
  - Update the leaf's "sufficient statistics" üìä
  - Measure information gain every so often üî¨
  - Split when the information gain is good enough üçÇ
- Mondrian trees üë®‚Äçüé® are another possibility but they only work for continuous attributes

---

class: middle

### Decision trees üå≥

Quality criterion of split $x < t$ can be evaluated with:

$$P(y \mid x < t) = \frac{P(x < t \mid y) \times P(y)}{P(x < t)}$$

and:

$$P(y \mid x \geq t) = \frac{(1 - P(x < t \mid y)) \times P(y)}{1 - P(x < t)}$$

- For classification, $P(x < t \mid y)$ is a set of online CDFs and $P(y)$ is a PMF.
- For regression, $P(x < t \mid y)$ is a 2D CDF and $P(y)$ is a PDF
- All these distributions can be updated online

---

class: middle

### Bagging

Each observation is sampled $K$ times where $K$ follows a binomial distribution:

$$P(K=k) = {n \choose k} \times (\frac{1}{n})^k \times (1 - \frac{1}{n})^{n-k}$$

As $n$ grows towards infinity, $K$ can be approximated by a Poisson(1):

$$P(K=k) \sim \frac{e^{-1}}{k!} $$

This leads to a simple and efficient online algorithm:

```python
for model in models:
    for _ in range(random.poisson(Œª=1)):
        model.fit_one(x, y)
```

---

class: middle

### (S)(N)(AR)(I)(MA)(X)

ARMA model is defined as so:

$$\hat{y}\_t = \sum\_{i=1}^p \alpha\_i y\_{t-i} + \sum\_{i=1}^q \beta\_i (y\_{t-i} - \hat{y}\_{t-i}) $$

Classically, Kalman filters are used to find the weights $\alpha\_i$ and $\beta\_i$. But $y\_{t-i}$ and $\hat{y}\_{t-i}$ can also be [seen as features in an online setting](https://dl.acm.org/citation.cfm?id=3016160):

- Seasonality can be handled online
- Any online learning model can be used
- Detrending by differencing can be done online
- Heteroscedasticity can be handled online
- Exogenous variables can be added

---

class: middle

### Online aggregated features

```python
>>> import creme

>>> X = [
...     {'meal': 'tika masala', 'sales': 42},
...     {'meal': 'kale salad', 'sales': 16},
...     {'meal': 'kale salad', 'sales': 24},
...     {'meal': 'tika masala', 'sales': 58}
... ]

>>> agg = creme.feature_extraction.Agg(
...     on='sales',
...     by='meal',
...     how=creme.stats.Mean()
... )

>>> for x in X:
...     print(agg.fit_one(x).transform_one(x))
{'sales_mean_by_meal': 42.0}
{'sales_mean_by_meal': 16.0}
{'sales_mean_by_meal': 20.0}
{'sales_mean_by_meal': 50.0}
```

---

background-color: #008080
class: middle, white

## There is much more

.bullets[
- Half-space trees for anomaly detection
- $k$-means clustering
- Latent Dirichlet allocation (LDA)
- Expert learning
- Stacking
- Recommendation systems
- See [creme-ml.github.io/api](https://creme-ml.github.io/api.html)
]

---

### Alternative frameworks

<div align="center">
  <img height="500px" src="/img/slides/creme/others.svg" />
</div>

---

class: center, middle

### Binary classification benchmark with default parameters

<div align="center">
.pure-table.pure-table-striped[
| Library | Method | Accuracy | Average fit time | Average predict time |
|---------|------------|----------|------------------|----------------------|
| creme | LogisticRegression | 0.61810 | .green[26Œºs] | .green[10Œºs] |
| creme | PAClassifier | 0.55009 | 35Œºs | 22Œºs |
| creme      | DecisionTreeClassifier       | 0.64663      | 356Œºs       |  15Œºs      |
| creme      | RandomForestClassifier       | .green[0.65915]      | 3ms, 972Œºs       |  208Œºs      |
| Keras on TF (CPU) | Dense | 0.61840 | 463Œºs | 534Œºs |
| PyTorch (CPU) | Linear | 0.61840 | 926Œºs | 621Œºs |
| scikit-garden | MondrianTreeClassifier | .red[0.53875] | 864Œºs | 208Œºs |
| scikit-garden | MondrianForestClassifier | 0.60061 | .red[9ms, 773Œºs] | .red[1ms, 233Œºs] |
| scikit-learn | SGDClassifier | 0.56161 | 420Œºs | 116Œºs |
| scikit-learn | PassiveAggressiveClassifier | 0.55009 | 398Œºs | 114Œºs |
]
</div>

---

class: center, middle

### Linear regression benchmark

<div align="center">
.pure-table.pure-table-striped[
| Library | Method | MSE | Average fit time | Average predict time |
|---------|------------|----------|------------------|----------------------|
| creme | LinearRegression | 23.035085 | 18Œºs | 4Œºs |
| Keras on TF (CPU) | Dense | 23.035086 | 1ms, 208Œºs | 722Œºs |
| PyTorch (CPU) | Linear | 23.035086 | 577Œºs | 187Œºs |
| scikit-learn | SGDRegressor | 25.295369 | 305Œºs | 108Œºs |
]
</div>

---

background-color: #1f282d
class: middle, white

## Current work (1)

.bullets[
- Boosting, many methods but no clear winner:
  - [Online Bagging and Boosting (Oza-Russell, 2005)](https://ti.arc.nasa.gov/m/profile/oza/files/ozru01a.pdf)
  - [Online Gradient Boosting (Beygelzimer, 2015)](https://arxiv.org/pdf/1506.04820.pdf)
  - [Optimal and Adaptive Algorithms for Online Boosting (Beygelzimer, 2015)](http://proceedings.mlr.press/v37/beygelzimer15.pdf)
- Mixture models through expectation-maximization:
  - [Recursive Parameter Estimation Using Incomplete Data (Titterington, 1982)](https://apps.dtic.mil/dtic/tr/fulltext/u2/a116190.pdf)
  - [A View of the EM Algorithm that Justifies Incremental, Sparse, and other Variants (Neal-Hinton, 1998)](http://www.cs.toronto.edu/~fritz/absps/emk.pdf)
  - [Online EM Algorithm for Latent Data Models (Capp√©-Moulines 2009)](https://hal.archives-ouvertes.fr/hal-00201327/document)
]

---

background-color: #1f282d
class: middle, white

## Current work (2)

.bullets[
- Field-aware factorization machines (FFM):
  - [Factorization Machines (Rendle, 2010)](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)
  - [Field-aware Factorization Machines for CTR Prediction (Juan et al., 2016)](https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf)
  - [Field-aware Factorization Machines in a Real-world Online Advertising System (Juan-Lefortier-Chappelle, 2017)](https://arxiv.org/pdf/1701.04099.pdf)
- Metric learning:
  - [Online and Batch Learning of Pseudo-Metrics (Shwartz-Singer-Ng, 2004)](https://ai.stanford.edu/~ang/papers/icml04-onlinemetric.pdf)
  - [Information-Theoretic Metric Learning (Davis et al., 2007)](http://www.cs.utexas.edu/users/pjain/pubs/metriclearning_icml.pdf)
  - [Online Metric Learning and Fast Similarity Search (Jain et al., 2009)](http://people.bu.edu/bkulis/pubs/nips_online.pdf)
]

---

background-color: #85144b
class: middle, white

## You can help

.bigbullets[
- Use it and tell us about it
- Share it with others
- Take on issues on GitHub
- Become a core contributor
]

---

class: center, middle

# Thanks for listening!

.left-column[
<div align="center">
  <img height="440px" src="/img/slides/creme/yoda.jpg" />
</div>
]

.right-column[
<div align="center" style="margin-top: 50px;">
  <img height="400px" src="/img/slides/creme/qr_code.svg" />
</div>
]

    </textarea>
<script src=https://remarkjs.com/downloads/remark-latest.min.js></script><script src=https://gnab.github.io/remark/downloads/remark-latest.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/contrib/auto-render.min.js></script><link rel=stylesheet href=https://unpkg.com/purecss@1.0.1/build/pure-min.css integrity=sha384-oAOxQR6DkCoMliIh8yFnu25d7Eq/PHS21PClpwjOTeU2jRSq11vu66rf90/cZr47 crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css><script type=text/javascript>var options={},renderMath=function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}]})},slideshow=remark.create({slideNumberFormat:function(e){return e===1?"":e},highlightStyle:"github",highlightLines:!0,ratio:"16:9"},renderMath)</script></body></html></div><script src=https://cdnjs.cloudflare.com/ajax/libs/elevator.js/1.0.1/elevator.min.js></script><script>var elementButton=document.querySelector(".elevator"),elevator=new Elevator({element:elementButton,mainAudio:"/music/elevator.mp3",endAudio:"/music/ding.mp3"})</script><style>.down-arrow{font-size:120px;margin-top:90px;margin-bottom:90px;text-shadow:0 -20px #0c1f31,0 0 #c33329;color:transparent;-webkit-transform:scaleY(.8);-moz-transform:scaleY(.8);transform:scaleY(.8)}.elevator{text-align:center;cursor:pointer;width:140px;margin:auto}.elevator:hover{opacity:.7}.elevator svg{width:40px;height:40px;display:block;margin:auto;margin-bottom:5px}</style><div class=site-footer><div class=site-footer-item><a href=/index.xml><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M12.8 16C12.8 8.978 7.022 3.2.0 3.2V0c8.777.0 16 7.223 16 16h-3.2zM2.194 11.61c1.21.0 2.195.985 2.195 2.196.0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017.0 13.806c0-1.21.983-2.195 2.194-2.195zM10.606 16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818.0 10.606 4.79 10.606 10.607z"/></svg></span></a></div><div class=site-footer-item><a href=https://github.com/MaxHalford><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M8 0C3.58.0.0 3.582.0 8c0 3.535 2.292 6.533 5.47 7.59.4.075.547-.172.547-.385.0-.19-.007-.693-.01-1.36-2.226.483-2.695-1.073-2.695-1.073-.364-.924-.89-1.17-.89-1.17-.725-.496.056-.486.056-.486.803.056 1.225.824 1.225.824.714 1.223 1.873.87 2.33.665.072-.517.278-.87.507-1.07-1.777-.2-3.644-.888-3.644-3.953.0-.873.31-1.587.823-2.147-.09-.202-.36-1.015.07-2.117.0.0.67-.215 2.2.82.64-.178 1.32-.266 2-.27.68.004 1.36.092 2 .27 1.52-1.035 2.19-.82 2.19-.82.43 1.102.16 1.915.08 2.117.51.56.82 1.274.82 2.147.0 3.073-1.87 3.75-3.65 3.947.28.24.54.73.54 1.48.0 1.07-.01 1.93-.01 2.19.0.21.14.46.55.38C13.71 14.53 16 11.53 16 8c0-4.418-3.582-8-8-8"/></svg></span></a></div><div class=site-footer-item><a href=https://linkedin.com/in/maxhalford><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M13.632 13.635h-2.37V9.922c0-.886-.018-2.025-1.234-2.025-1.235.0-1.424.964-1.424 1.96v3.778h-2.37V6H8.51v1.04h.03c.318-.6 1.092-1.233 2.247-1.233 2.4.0 2.845 1.58 2.845 3.637v4.188zM3.558 4.955c-.762.0-1.376-.617-1.376-1.377.0-.758.614-1.375 1.376-1.375.76.0 1.376.617 1.376 1.375.0.76-.617 1.377-1.376 1.377zm1.188 8.68H2.37V6h2.376v7.635zM14.816.0H1.18C.528.0.0.516.0 1.153v13.694C0 15.484.528 16 1.18 16h13.635c.652.0 1.185-.516 1.185-1.153V1.153C16 .516 15.467.0 14.815.0z" fill-rule="nonzero"/></svg></span></a></div><div class=site-footer-item><a href=https://twitter.com/halford_max><span class=inline-svg><svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="1.414"><path fill="currentcolor" d="M16 3.038c-.59.26-1.22.437-1.885.517.677-.407 1.198-1.05 1.443-1.816-.634.37-1.337.64-2.085.79-.598-.64-1.45-1.04-2.396-1.04-1.812.0-3.282 1.47-3.282 3.28.0.26.03.51.085.75-2.728-.13-5.147-1.44-6.766-3.42C.83 2.58.67 3.14.67 3.75c0 1.14.58 2.143 1.46 2.732-.538-.017-1.045-.165-1.487-.41v.04c0 1.59 1.13 2.918 2.633 3.22-.276.074-.566.114-.865.114-.21.0-.41-.02-.61-.058.42 1.304 1.63 2.253 3.07 2.28-1.12.88-2.54 1.404-4.07 1.404-.26.0-.52-.015-.78-.045 1.46.93 3.18 1.474 5.04 1.474 6.04.0 9.34-5 9.34-9.33.0-.14.0-.28-.01-.42.64-.46 1.2-1.04 1.64-1.7z" fill-rule="nonzero"/></svg></span></a></div><div class=site-footer-item><a href=https://kaggle.com/maxhalford><span class=inline-svg><svg role="img" viewBox="0 0 26 26" xmlns="http://www.w3.org/2000/svg"><title>Kaggle icon</title><path fill="currentcolor" d="M18.825 23.859c-.022.092-.117.141-.281.141h-3.139c-.187.0-.351-.082-.492-.248l-5.178-6.589-1.448 1.374v5.111c0 .235-.117.352-.351.352H5.505c-.236.0-.354-.117-.354-.352V.353c0-.233.118-.353.354-.353h2.431c.234.0.351.12.351.353v14.343l6.203-6.272c.165-.165.33-.246.495-.246h3.239c.144.0.236.06.285.18.046.149.034.255-.036.315l-6.555 6.344 6.836 8.507c.095.104.117.208.07.358"/></svg></span></a></div><div class=site-footer-item><a href=/files/resume_max_halford.pdf><span class=inline-svg><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 392.533 392.533" style="enable-background:new 0 0 392.533 392.533"><g><g><path fill="currentcolor" d="M292.396 324.849H99.879c-6.012.0-10.925 4.848-10.925 10.925.0 6.012 4.849 10.925 10.925 10.925h192.582c6.012.0 10.925-4.849 10.925-10.925C303.321 329.697 298.473 324.849 292.396 324.849z"/></g></g><g><g><path fill="currentcolor" d="M292.396 277.01H99.879c-6.012.0-10.925 4.848-10.925 10.925.0 6.012 4.849 10.925 10.925 10.925h192.582c6.012.0 10.925-4.849 10.925-10.925C303.321 281.859 298.473 277.01 292.396 277.01z"/></g></g><g><g><path fill="currentcolor" d="M196.137 45.834c-25.859.0-46.998 21.075-46.998 46.998.0 25.859 21.139 46.933 46.998 46.933s46.998-21.075 46.998-46.998-21.139-46.933-46.998-46.933zm0 72.017c-13.77.0-25.083-11.313-25.083-25.083s11.248-25.083 25.083-25.083 25.083 11.313 25.083 25.083c0 13.769-11.313 25.083-25.083 25.083z"/></g></g><g><g><path fill="currentcolor" d="M258.521 163.362c-39.887-15.515-84.752-15.515-124.638.0-13.059 5.107-21.786 18.101-21.786 32.388v44.347c-.065 6.012 4.849 10.925 10.861 10.925h146.424c6.012.0 10.925-4.848 10.925-10.925V195.75C280.307 181.463 271.58 168.469 258.521 163.362zm0 65.874H133.883v-33.422c0-5.301 3.168-10.214 7.887-12.024 34.844-13.511 74.02-13.511 108.865.0 4.719 1.875 7.887 6.659 7.887 12.024v33.422z"/></g></g><g><g><path fill="currentcolor" d="M313.083.0H131.491c-8.404.0-16.291 3.232-22.238 9.18L57.018 61.414c-5.947 5.948-9.18 13.834-9.18 22.238v277.333c0 17.39 14.158 31.547 31.547 31.547h233.762c17.39.0 31.547-14.158 31.547-31.547V31.547C344.501 14.158 330.343.0 313.083.0zM112.032 37.236v27.022H85.01l27.022-27.022zm210.683 79.58h-40.598c-6.012.0-10.925 4.849-10.925 10.925.0 6.012 4.848 10.925 10.925 10.925h40.598v19.394h-14.869c-6.012.0-10.925 4.848-10.925 10.925.0 6.012 4.849 10.925 10.925 10.925h14.869v181.139c0 5.366-4.331 9.697-9.632 9.697H79.192c-5.301.0-9.632-4.331-9.632-9.632V86.044h53.398c6.012.0 10.925-4.848 10.925-10.925V21.721h179.2c5.301.0 9.632 4.331 9.632 9.632v85.463z"/></g></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></span></a></div><div class=site-footer-item><a href="https://scholar.google.com/citations?user=erRNNi0AAAAJ&hl=en"><span class=inline-svg><svg viewBox="0 0 1755 1755" xmlns="http://www.w3.org/2000/svg"><path fill="currentcolor" transform="translate(0 1610) scale(1 -1)" d="M896.76 1130.189c-27.618 30.838-59.618 46.19-95.802 46.19-40.952.0-72.382-14.738-94.288-44.15-21.906-29.322-32.864-64.848-32.864-106.584.0-35.548 5.998-71.738 18-108.64 11.958-36.886 31.524-69.814 58.954-98.838 27.334-29.096 59.144-43.616 95.284-43.616 40.288.0 71.76 13.502 94.332 40.492 22.476 26.954 33.756 60.98 33.756 101.962.0 34.904-5.954 71.454-17.906 109.664-11.894 38.262-31.752 72.784-59.466 103.52zm762.098 382.384c-64.358 64.424-141.86 96.57-232.572 96.57H329.144c-90.712.0-168.14-32.146-232.572-96.57-64.424-64.286-96.57-141.86-96.57-232.572V182.859c0-90.712 32.146-168.288 96.57-232.712 64.432-64.146 142-96.432 232.572-96.432h1097.142c90.712.0 168.214 32.286 232.572 96.57 64.432 64.432 96.644 141.86 96.644 232.572v1097.142c0 90.712-32.22 168.288-96.644 232.572zM1297.81 1154.159V762.033c0-18.154-14.856-33.016-33.016-33.016h-12.156c-18.162.0-33.016 14.856-33.016 33.016v392.126c0 16.12-2.34 29.578 20.188 32.41v52.172l-173.43-142.24c2.004-3.716 3.906-6.092 5.712-9.208 15.242-26.976 23.004-60.526 23.004-101.53.0-31.43-5.238-59.662-15.858-84.598-10.57-24.928-23.428-45.29-38.43-60.972-15.002-15.74-30.048-30.128-45.092-43.074-15.046-12.976-27.904-26.506-38.436-40.55-10.614-14-15.894-28.474-15.894-43.476.0-15.024 6.854-30.288 20.524-45.67 13.62-15.426 30.376-30.376 50.19-45.144 19.85-14.666 39.658-30.946 59.472-48.662 19.858-17.694 36.52-40.456 50.14-68.096 13.722-27.744 20.568-58.288 20.568-91.86.0-44.288-11.294-84.282-33.806-119.882-22.58-35.446-51.998-63.73-88.144-84.472-36.242-20.882-75-36.6-116.334-47.214-41.42-10.518-82.52-15.806-123.568-15.806-25.908.0-52.048 1.996-78.336 6.1-26.382 4.096-52.81 11.33-79.426 21.526-26.668 10.262-50.286 22.864-70.758 37.998-20.524 14.98-37.046 34.312-49.716 57.856-12.668 23.552-18.958 50.022-18.958 79.426.0 34.882 9.714 67.24 29.192 97.404 19.478 29.944 45.282 54.952 77.378 74.76 55.998 34.838 143.858 56.364 263.432 64.498-27.334 34.172-41.048 66.334-41.048 96.432.0 17.122 4.476 35.474 13.334 55.288-14.284-1.996-28.994-3.124-44.002-3.124-64.234.0-118.476 20.882-162.524 62.932-44.046 41.976-66.048 94.522-66.048 158.048.0 6.642.19 12.492.672 18.974H292.574l393.618 342.17h651.856l-60.24-47.024v-82.996c22.368-2.874 20.004-16.318 20.004-32.394zM900.382 544.929c-7.52 1.36-18.088 2.122-31.708 2.122-29.382.0-58.288-2.596-86.666-7.782-28.38-5.046-56.378-13.568-83.998-25.592-27.722-11.952-50.096-29.528-67.146-52.766-17.144-23.208-25.666-50.542-25.666-81.994.0-29.974 7.52-56.714 22.572-80.004 15.002-23.142 34.808-41.26 59.428-54.236 24.62-12.998 50.432-22.814 77.378-29.264 26.998-6.408 54.476-9.736 82.476-9.736 55.376.0 103.05 12.47 143.046 37.406 39.906 24.928 59.904 63.422 59.904 115.382.0 10.928-1.522 21.686-4.528 32.19-3.138 10.62-6.24 19.712-9.282 27.26-3.05 7.41-8.858 16.332-17.43 26.616-8.522 10.314-15.046 17.934-19.434 23.004-4.476 5.238-12.852 12.712-25.19 22.594-12.236 9.926-20.048 16.114-23.522 18.402-3.43 2.406-12.332 8.908-26.668 19.456-14.328 10.634-22.184 16.274-23.566 16.94z"/></svg></span></a></div><div class=site-footer-item><a href=https://www.imdb.com/user/ur73044771><span class=inline-svg><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><g><g><path fill="currentcolor" d="M425.17 73.146c.179-1.577.268-3.169.268-4.771.0-23.25-18.915-42.165-42.165-42.165-6.849.0-13.444 1.619-19.354 4.678-9.531-14.757-26.054-24.056-44.185-24.056-11.414.0-22.244 3.62-31.163 10.214C280.754 6.589 268.271.0 254.743.0c-13.007.0-25.097 6.068-32.975 15.906-8.628-5.856-18.899-9.075-29.515-9.075-18.126.0-34.646 9.302-44.176 24.06-5.913-3.06-12.508-4.682-19.351-4.682-23.25.0-42.166 18.915-42.166 42.165.0 1.603.088 3.195.266 4.769-21.658 6.642-36.909 26.605-36.909 50.229.0 11.817 3.952 23.172 11.184 32.401l43.004 347.699c.603 4.871 4.74 8.528 9.648 8.528h284.485c4.907.0 9.046-3.658 9.648-8.528l43.004-347.7c7.238-9.225 11.194-20.578 11.194-32.4C462.083 99.751 446.832 79.789 425.17 73.146zM122.346 492.557 81.465 162.025h44.764l26.618 330.532H122.346zm50.007.0-26.618-330.532H201.2l3.161 104.598c-17.168 14.634-28.086 36.393-28.086 60.667.0 26.007 12.521 49.142 31.849 63.703l3.065 101.563H172.353zm108.993.0h-50.704l-2.736-90.671c8.743 3.303 18.205 5.125 28.09 5.125 9.887.0 19.352-1.823 28.096-5.128L281.346 492.557zm-25.35-104.989c-33.237.0-60.277-27.04-60.277-60.277s27.04-60.277 60.277-60.277 60.277 27.04 60.277 60.277-27.04 60.277-60.277 60.277zM220.653 162.025h70.696l-2.797 92.523c-9.95-4.469-20.962-6.977-32.555-6.977-11.591.0-22.602 2.507-32.548 6.975L220.653 162.025zm80.144 330.532 3.076-101.568c19.325-14.562 31.844-37.694 31.844-63.698.0-24.27-10.915-46.027-28.078-60.661l3.16-104.605h55.457l-26.618 330.532H300.797zm88.847.0h-30.501l26.618-330.532h44.766L389.644 492.557zm46.819-349.975H75.531c-3.986-5.588-6.171-12.266-6.171-19.21.0-15.23 10.052-28.041 24.192-31.923 5.136 7.347 14.332 15.089 27.853 15.089 1.412.0 2.87-.084 4.376-.262 5.086-.601 9.169-4.831 9.023-9.951-.169-5.868-5.336-10.151-11.005-9.396-10.908 1.458-15.263-7.828-16.038-9.747-.013-.032-.029-.062-.042-.095-.012-.027-.017-.057-.029-.084-.779-1.9-1.29-3.885-1.53-5.925-1.495-12.753 8.151-24.497 20.961-25.373 6.62-.452 12.93 1.908 17.606 6.533 1.819 1.799 4.249 2.929 6.806 2.967 4.322.064 8.035-2.652 9.379-6.564 4.598-13.379 17.192-22.369 31.338-22.369 9.432.0 18.433 4.035 24.706 11.075 1.729 1.94 4.172 3.177 6.769 3.314 4.373.231 8.223-2.412 9.675-6.342 3.285-8.897 11.862-14.876 21.341-14.876 9.948.0 18.848 6.611 21.743 16.113.844 2.769 2.688 5.187 5.322 6.388 4.237 1.929 9.045.642 11.766-2.852 6.344-8.145 15.88-12.817 26.163-12.817 12.52.0 23.811 7.04 29.437 17.921-1.79 2.84-3.768 6.681-5.037 11.285-3.664 13.302.342 26.651 11.28 37.59 1.898 1.899 4.386 2.848 6.874 2.848 2.445.0 4.889-.916 6.775-2.749 3.908-3.798 3.579-10.276-.227-14.178-5.623-5.764-7.618-11.593-6.097-17.81.165-.673.362-1.321.582-1.939 1.859-5.235 5.847-9.536 10.945-11.741 3.526-1.524 7.439-2.141 11.453-1.724 11.438 1.189 20.292 11.127 20.277 22.625-.004 2.949-.569 5.829-1.682 8.559-.872 2.139-.985 4.557-.26 6.751 1.247 3.773 4.581 6.325 8.393 6.66 16.932 1.484 30.195 15.978 30.195 33C442.642 130.32 440.454 136.998 436.463 142.582z"/></g></g><g><g><path fill="currentcolor" d="M261.257 62.341c-7.484.0-14.638 1.996-20.875 5.741-6.452-5.745-14.886-9.073-23.702-9.073-19.656.0-35.646 15.99-35.646 35.646s15.989 35.646 35.644 35.646c5.369.0 9.721-4.353 9.721-9.721.0-5.369-4.353-9.721-9.721-9.721-8.935.0-16.203-7.268-16.203-16.203s7.268-16.203 16.203-16.203c5.773.0 10.987 2.99 13.945 7.999 1.542 2.612 4.217 4.354 7.229 4.71 3.015.358 6.02-.714 8.128-2.893 4.047-4.182 9.473-6.484 15.277-6.484 11.725.0 21.264 9.539 21.264 21.266.0 5.369 4.351 9.722 9.721 9.722s9.721-4.353 9.721-9.722C301.965 80.603 283.704 62.341 261.257 62.341z"/></g></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></span></a></div><div class=site-footer-item><a href=https://play.spotify.com/user/1166811350><span class=inline-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 168 168"><path fill="currentcolor" d="m83.996.277C37.747.277.253 37.77.253 84.019c0 46.251 37.494 83.741 83.743 83.741 46.254.0 83.744-37.49 83.744-83.741.0-46.246-37.49-83.738-83.745-83.738l.001-.004zm38.404 120.78c-1.5 2.46-4.72 3.24-7.18 1.73-19.662-12.01-44.414-14.73-73.564-8.07-2.809.64-5.609-1.12-6.249-3.93-.643-2.81 1.11-5.61 3.926-6.25 31.9-7.291 59.263-4.15 81.337 9.34 2.46 1.51 3.24 4.72 1.73 7.18zm10.25-22.805c-1.89 3.075-5.91 4.045-8.98 2.155-22.51-13.839-56.823-17.846-83.448-9.764-3.453 1.043-7.1-.903-8.148-4.35-1.04-3.453.907-7.093 4.354-8.143 30.413-9.228 68.222-4.758 94.072 11.127 3.07 1.89 4.04 5.91 2.15 8.976v-.001zm.88-23.744c-26.99-16.031-71.52-17.505-97.289-9.684-4.138 1.255-8.514-1.081-9.768-5.219-1.254-4.14 1.08-8.513 5.221-9.771 29.581-8.98 78.756-7.245 109.83 11.202 3.73 2.209 4.95 7.016 2.74 10.733-2.2 3.722-7.02 4.949-10.73 2.739z"/></svg></span></a></div><div class=site-footer-item><a href=https://www.goodreads.com/user/show/67553795-lemax><span class=inline-svg><svg id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 463 463" style="enable-background:new 0 0 463 463"><g><path fill="currentcolor" d="M270.615 229.128l-24-72c-1.021-3.063-3.887-5.128-7.115-5.128s-6.094 2.066-7.115 5.128l-24 72c-.513 1.54-.513 3.204.0 4.743l24 72c1.021 3.063 3.887 5.128 7.115 5.128s6.094-2.066 7.115-5.128l24-72C271.128 232.332 271.128 230.668 270.615 229.128zM239.5 279.783 223.406 231.5l16.094-48.283 16.094 48.283L239.5 279.783z"/><path fill="currentcolor" d="M375.5 48h-64c-2.997.0-5.862.57-8.5 1.597V23.5C303 10.542 292.458.0 279.5.0h-80C186.542.0 176 10.542 176 23.5v42.097C173.362 64.57 170.497 64 167.5 64h-80C74.542 64 64 74.542 64 87.5v352c0 12.958 10.542 23.5 23.5 23.5h80c6.177.0 11.801-2.399 16-6.31 4.199 3.911 9.823 6.31 16 6.31h80c6.177.0 11.801-2.399 16-6.31 4.199 3.911 9.823 6.31 16 6.31h64c12.958.0 23.5-10.542 23.5-23.5v-368C399 58.542 388.458 48 375.5 48zM79 135h97v257H79V135zM191 87.5V87h97v289h-97V87.5zm97-16V72h-97V55h97V71.5zM191 391h97v17h-97V391zM303 119h81v273h-81V119zm8.5-56h64c4.687.0 8.5 3.813 8.5 8.5V104h-81V71.5C303 66.813 306.813 63 311.5 63zm-112-48h80c4.687.0 8.5 3.813 8.5 8.5V40h-97V23.5C191 18.813 194.813 15 199.5 15zM87.5 79h80c4.687.0 8.5 3.813 8.5 8.5V120H79V87.5c0-4.687 3.813-8.5 8.5-8.5zm80 369h-80c-4.687.0-8.5-3.813-8.5-8.5V407h97v32.5C176 444.187 172.187 448 167.5 448zm112 0h-80c-4.687.0-8.5-3.813-8.5-8.5V423h97v16.5C288 444.187 284.187 448 279.5 448zm96 0h-64c-4.687.0-8.5-3.813-8.5-8.5V407h81v32.5C384 444.187 380.187 448 375.5 448z"/><path fill="currentcolor" d="M374.615 253.128l-24-72c-1.021-3.063-3.887-5.128-7.115-5.128s-6.094 2.066-7.115 5.128l-24 72c-.513 1.54-.513 3.204.0 4.743l24 72c1.021 3.063 3.887 5.128 7.115 5.128s6.094-2.066 7.115-5.128l24-72C375.128 256.332 375.128 254.668 374.615 253.128zM343.5 303.783 327.406 255.5l16.094-48.283 16.094 48.283L343.5 303.783z"/><path fill="currentcolor" d="M158.615 261.128l-24-72c-1.021-3.063-3.887-5.128-7.115-5.128s-6.094 2.066-7.115 5.128l-24 72c-.513 1.54-.513 3.204.0 4.743l24 72c1.021 3.063 3.887 5.128 7.115 5.128s6.094-2.066 7.115-5.128l24-72C159.128 264.332 159.128 262.668 158.615 261.128zM127.5 311.783 111.406 263.5l16.094-48.283 16.094 48.283L127.5 311.783z"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></span></a></div><div class=site-footer-item><a href=mailto:maxhalford25@gmail.com><span class=inline-svg><svg viewBox="0 0 15 20" xmlns="http://www.w3.org/2000/svg"><title>mail</title><path fill="currentcolor" d="M0 4v8c0 .55.45 1 1 1h12c.55.0 1-.45 1-1V4c0-.55-.45-1-1-1H1c-.55.0-1 .45-1 1zm13 0L7 9 1 4h12zM1 5.5l4 3-4 3v-6zM2 12l3.5-3L7 10.5 8.5 9l3.5 3H2zm11-.5-4-3 4-3v6z" fill="#000" fill-rule="evenodd"/></svg></span></a></div></div></div></div></article></body></html>