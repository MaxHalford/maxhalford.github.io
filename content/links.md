---
layout: default
title: Links
---

## Papers

- PhD - Statistical learning for selectivity estimation in relational databases ([manuscript](/files/PhD_manuscript.pdf), [slides](/files/PhD_presentation.pdf))
- [Selectivity correction with online machine learning - BDA 2020](https://arxiv.org/abs/2009.09884)
- [Selectivity Estimation with Attribute Value Dependencies using Linked Bayesian Networks - TLDKS 2020](https://arxiv.org/abs/2009.09883)
- [An Approach Based on Bayesian Networks for Query Selectivity Estimation - DASFAA, 2019](https://arxiv.org/abs/1907.06295)
- [Entropic Variable Projection for Explainability and Intepretability - 2018](https://arxiv.org/abs/1810.07924)
- Master 2 year internship at [HelloFresh](https://www.hellofresh.com/) ([report](/files/M2_report.pdf), [slides](/files/M2_slides.pdf))
- Master 1 year internship at [Privateaser](https://www.privateaser.com/) ([report](/files/M1_report.pdf), [slides](/files/M1_slides.pdf))
- Undergraduate internship at [INSA Toulouse](http://www.insa-toulouse.fr/fr/index.html) ([report](/files/L3_report.pdf), [slides](/files/L3_slides.pdf))
- [Detailed solutions to the first 30 Project Euler problems](/files/project_euler_solutions.pdf)

## Talks

- [The challenges of online machine learning in production - Itaú Unibanco Meetup 2021](/slides/the-challenges-of-online-machine-learning-in-production.pdf)
- [Quelle est l’empreinte écologique du Big Data? - Toulouse Tech round table 2021](https://www.youtube.com/watch?v=8RubWlhwTjg&feature=youtu.be)
- [A brief introduction to online machine learning - Hong Kong Machine Learning, 2020](/slides/hkml2020.pdf)
- [Online machine learning with decision trees - Toulouse AOC workgroup, 2020](/slides/online-decision-trees.pdf)
- [Our solution to the IDAO 2020 qualifiers - virtual seminar, 2020](/slides/idao-2020-qualifiers.pdf)
- [Global explanation of machine learning with sensitivity analysis - MASCOT-NUM, Paris, 2020](/slides/gdr-mascotnum-2020.pdf)
- [The benefits of online learning - Quantmetry, Paris, 2019](/slides/the-benefits-of-online-learning)
- [The benefits of online learning - Element AI, London, 2019](/slides/the-benefits-of-online-learning)
- [The benefits of online learning - Airbus BizLab, Toulouse, 2019](/slides/the-benefits-of-online-learning)
- [An approach based on Bayesian networks for query selectivity estimation - DASFAA, 2019](/slides/dasfaa-2019.pdf)
- [Machine learning incrémental: des concepts à la pratique - Toulouse Data Science, 2019](/slides/creme-tds)
- [Online machine learning with creme - PyData, Amsterdam, 2019](/slides/creme-pydata)
- [Docker for data science - HelloFresh, Berlin, 2017](/slides/docker-data-science.pdf)
- [Challenge Big Data - Toulouse, 2017](https://www.youtube.com/watch?v=oQd1h-8Srf4&feature=youtu.be)
- [Forecasting bicycle-sharing usage - Toulouse Data Science, 2016](https://www.youtube.com/watch?v=vQGdzKkyPP0)

## Datasets

- [OpenBikes 2016 challenge](https://www.dropbox.com/s/ic8m0b3mf5wxk4r/challenge.zip?dl=0)

## Blogroll

This is a list of blogs I regularly scroll through.

- [Tim Salimans on Data Analysis](http://timsalimans.com/)
- [Randal Olson](http://www.randalolson.com/blog/)
- [Sam & Max](http://sametmax.com/) -- French and NSFW!
- [Sebastian Raschka](http://sebastianraschka.com/blog/index.html)
- [Clean Coder](https://sites.google.com/site/unclebobconsultingllc/)
- [Pythonic Perambulations](https://jakevdp.github.io/)
- [Erik Bernhardsson](http://erikbern.com/)
- [otoro](http://blog.otoro.net/)
- [Terra Incognita](http://blog.christianperone.com/)
- [Real Python](https://realpython.com/blog/)
- [Airbnb Engineering](http://nerds.airbnb.com/)
- [No Free Hunch](http://blog.kaggle.com/)
- [The Unofficial Google Data Science Blog](http://www.unofficialgoogledatascience.com/)
- [will wolf](http://willwolf.io/)
- [Edwin Chen](http://blog.echen.me/)
- [Use the index, Luke!](http://use-the-index-luke.com/)
- [Jack Preston](https://unwttng.com/)
- [Agustinus Kristiadi](https://wiseodd.github.io/)
- [DataGenetics](http://datagenetics.com/blog.html)
- [Katherine Bailey](https://katbailey.github.io/)
- [Netflix Research](https://research.netflix.com/)
- [inFERENce](https://www.inference.vc/)
- [Hyndsight](https://robjhyndman.com/hyndsight/) -- Rob Hyndman is a time series specialist.
- [While My MCMC Gently Samples](https://twiecki.io/)
- [Ines Montani](https://ines.io/) -- By one of the founders of [spaCy](https://spacy.io/).
- [Stephen Smerity](https://smerity.com/articles/articles.html)
- [Peter Norvig](http://norvig.com/)
- [IT Best Kept Secret Is Optimization](https://www.ibm.com/developerworks/community/blogs/jfp/?lang=en) -- By Jean-Francois Puget, aka [CPMP](https://www.kaggle.com/cpmpml).
- [explained.ai](https://explained.ai/)
- [Better Explained](https://betterexplained.com/)
- [Genetic Argonaut](https://geneticargonaut.blogspot.com/)
- [pandas blog](https://pandas-dev.github.io/pandas-blog/)
- [Towards Data Science](https://towardsdatascience.com/)
- [Linear Digressions](https://lineardigressions.com/) -- data science podcasts.
- [Not so standard deviations](http://nssdeviations.com/) -- more podcasts.
- [Talking Machines](http://www.thetalkingmachines.com/episodes) -- even more podcasts.
- [Practical AI](https://changelog.com/practicalai) -- here be podcasts.
- [Probably Overthinking It](https://www.allendowney.com/blog/)
- [Simply Statistics](https://simplystatistics.org/)
- [Practically Predictable](http://practicallypredictable.com/)
- [koaning](http://koaning.io/) -- By Vincent Warmerdam, who made [calmcode](https://calmcode.io/).
- [blogarithms](https://blogarithms.github.io/)
- [Possibly Wrong](https://possiblywrong.wordpress.com/)
- [FastML](http://fastml.com/)
- [Parameter-free Learning and Optimization Algorithms](https://parameterfree.com/)
- [Todd W. Schneider](https://toddwschneider.com/) -- This guy is really good at exploratory data analysis.
- [Yann Thaddée](https://espadrine.github.io/blog/) -- Not directly related to data science but interesting nonetheless.
- [Colins Blog](https://www.solipsys.co.uk/new/ColinsBlog.html)
- [Fabien Sanglard](https://fabiensanglard.net) -- Nothing to do with data science, but such good taste!
- [The Glowing Python](https://glowingpython.blogspot.com/) -- By the creator of [MiniSom](https://github.com/JustGlowing/minisom), which is worth checking out too.
- [Matt Hancock](https://notmatthancock.github.io/notes/)
- [Francis Bach](https://francisbach.com/) -- Someone with an h-index of 80+ who takes the time to blog is worth reading.
- [Gwern Branwen](https://www.gwern.net/index) -- Cool in a weird way.
- [Libres pensées d'un mathématicien ordinaire](http://djalil.chafai.net/blog/)
- [Count Bayesie](https://www.countbayesie.com/)
- [Jim Savage](https://khakieconomics.github.io/)
- [Nick Higham](https://nhigham.com/) -- A lot of well explained algebra.
- [Calmcode](https://calmcode.io/) -- Not a blog per se, but a nice collection of short to the point tutorials about various tools.
- [Chris Said](https://chris-said.io/)
<<<<<<< HEAD
- [Evan Miller](https://www.evanmiller.org/index.html)
- [Eric Jang](http://evjang.com/)
=======
- [Andrey Akinshin](https://aakinshin.net/)
- [Single Lunch](https://www.singlelunch.com/blog/)
>>>>>>> dev

## Hall of fame

The following is a hall of fame of papers, books, and blog posts that have a very high [signal to noise ratio](https://www.urbandictionary.com/define.php?term=signal%20to%20noise%20ratio) -- at least in my book. I highly recommend reading some of them when you get time.

- [The Elements of Statistical Learning - Jerome H. Friedman, Robert Tibshirani, and Trevor Hastie](http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf)
- [Machine Learning - Tom Mitchell](http://personal.disco.unimib.it/Vanneschi/McGrawHill_-_Machine_Learning_-Tom_Mitchell.pdf) -- I think this wonderful textbook is under-appreciated.
- [Artificial Intelligence: A Modern Approach - Russel & Norvig](http://web.cecs.pdx.edu/~mperkows/CLASS_479/2017_ZZ_00/02__GOOD_Russel=Norvig=Artificial%20Intelligence%20A%20Modern%20Approach%20(3rd%20Edition).pdf)
- [mlcourse.ai](https://mlcourse.ai/) -- Of all the introductions to machine learning, I think this is the one that strikes the best balance between theory and practice.
- [Machine learning cheat sheets - Shervine Amidi](https://stanford.edu/~shervine/teaching/cs-229.html)
- [Kalman and Bayesian Filters in Python - Roger Labbe](http://nbviewer.jupyter.org/github/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/table_of_contents.ipynb) -- Kalman filters are notoriously hard to grok, this tutorial nicely builds up the steps to understanding them.
- [CS231n Convolutional Neural Networks for Visual Recognition - Stanford](http://cs231n.github.io/convolutional-networks/)
- [Algorithmes d’optimisation non-linéaire sans contrainte (French) - Michel Bergmann](https://www.math.u-bordeaux.fr/~mbergman/PDF/These/annexeC.pdf)
- [Graphical Models in a Nutshell - Koller et al.](https://ai.stanford.edu/~koller/Papers/Koller+al:SRL07.pdf)
- [Rules of Machine Learning: Best Practices for ML Engineering - Martin Zinkevich](https://developers.google.com/machine-learning/guides/rules-of-ml/) -- You should read this once a year.
- [A Few Useful Things to Know about Machine Learning - Pedro Domingos](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf) -- This short paper summarizes basic truths in machine learning.
- [Choose Boring Technology - Dan McKinley](http://mcfunley.com/choose-boring-technology)
- [How to Write a Spelling Corrector - Peter Norvig](https://norvig.com/spell-correct.html) -- Magic in 36 lines of code.
- [MCMC sampling for dummies - Thomas Wiecki](http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/)
- [Your Easy Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)
- [An Intuitive Explanation of Convolutional Neural Networks - Ujjwal Karn](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)
- [An overview of gradient descent optimization algorithms - Sebastian Ruder](http://ruder.io/optimizing-gradient-descent/)
- [How to explain gradient boosting - Terence Parr and Jeremy Howard](https://explained.ai/gradient-boosting/index.html) -- A very good introduction to vanilla gradient boosting with step by step examples.
- [Why Does XGBoost Win "Every" Machine Learning Competition? - Didrik Nielsen](https://brage.bibsys.no/xmlui/bitstream/handle/11250/2433761/16128_FULLTEXT.pdf) -- This Master's thesis goes into some of the details of XGBoost without being too bloated.
- [Good sleep, good learning, good life - Piotr Wozniak](https://web.archive.org/web/20181017190008/https://www.supermemo.com/en/articles/sleep) -- Extremely long and nothing to do with data science, but a very thorough essay nonetheless on how to properly sleep.
- [Make for data scientists - Paul Butler](http://blog.kaggle.com/2012/10/15/make-for-data-scientists/) -- I believe Makefiles are yet to be rediscovered for managing data science pipelines.
- [Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations](https://fermatslibrary.com/s/statistical-tests-p-values-confidence-intervals-and-power-a-guide-to-misinterpretations) -- Just read it.
- [The Cramér-Rao Lower Bound on Variance: Adam and Eve’s "Uncertainty Principle" - Michael Powers](https://web.archive.org/web/20100613220918/http://astro.temple.edu/~powersmr/vol7no3.pdf)
- [Kaggle contest on Observing Dark World - Cam Davidson-Pilon](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC3.ipynb#Example:-Kaggle-contest-on-Observing-Dark-World) -- If you're not convinced about the power of Bayesian machine learning then read this and get your mind blown.
- [A Concrete Introduction to Probability (using Python) - Peter Norvig](https://nbviewer.jupyter.org/url/norvig.com/ipython/Probability.ipynb) -- Extremely elegant Python coding.
- [The Hungarian Maximum Likelihood Trick - Louis Abraham](https://louisabraham.github.io/notebooks/hungarian_trick.html)
- [Machine Learning for Signal Processing - University of Illinois](https://courses.engr.illinois.edu/cs598ps/fa2018/material.html)
- [Don't Call Yourself A Programmer, And Other Career Advice](https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/)
- [Tidy Data - Hadley Wickham](https://vita.had.co.nz/papers/tidy-data.pdf) -- If you like playing with data then you need to be aware of this one.
- [Gaussian Process, not quite for dummies - Yuge Shi](https://yugeten.github.io/posts/2019/09/GP/) -- Gaussian processes are quite difficult to understand (at least, for me) but Yuge gives some great visual intuitions.
- [Continuous Delivery for Machine Learning - Martin Fowler](https://martinfowler.com/articles/cd4ml.html)
- [Memos - Sriram Krishnan](https://sriramk.com/memos)
- [Frequentism and Bayesianism: A Python-driven Primer - Jake VanderPlas](https://arxiv.org/pdf/1411.5018.pdf)
- [A Few Useful Things To Know About Machine Learning - Pedro Domingos](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)
- [Multiworld Testing Decision Service: A System for Experimentation, Learning, And Decision-Making](https://arxiv.org/pdf/1606.03966.pdf)
- [Machine Learning: The High-Interest Credit Card of Technical Debt - Google](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43146.pdf)
- [Variational Inference: A Review for Statisticians - David Blei and his flock](https://arxiv.org/pdf/1601.00670.pdf)
- [The Performance of Decision Tree Evaluation Strategies - Andrew Tulloch](http://tullo.ch/articles/decision-tree-evaluation/)
- [Hidden Technical Debt in Machine Learning Systems - Google](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)
- [Distill: Why do we need Flask, Celery, and Redis? (with McDonalds in Between) - Lj Miranda](https://ljvmiranda921.github.io/notebook/2019/11/08/flask-redis-celery-mcdo/) -- A good example of the difference between abstract ideas and implementation details.
- [Darts, Dice, and Coins: Sampling from a Discrete Distribution - Keith Schwarz](https://www.keithschwarz.com/darts-dice-coins/)
- [Simplifying Graph Convolutional Networks - Felix Wu et al.](https://arxiv.org/pdf/1902.07153.pdf) -- A nice example of putting the horse before the cart.
- [MIT 6.867 machine learning course notes - Tommi Jaakola](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/lecture-notes/) -- For people who enjoy concise mathematical notation.
- [A Recipe for Training Neural Networks - Andrej Karpathy](https://karpathy.github.io/2019/04/25/recipe/)
- [The Bitter Lesson - Richard Sutton](http://incompleteideas.net/IncIdeas/BitterLesson.html)
- [The Best Medium-Hard Data Analyst SQL Interview Questions](https://quip.com/2gwZArKuWk7W) -- There are some great interactive SQL tutorials out there, such as [SQLBolt](https://sqlbolt.com/) and [Select Star SQL](https://selectstarsql.com/), but this one takes the cake due to its complexity.
- [Rules of Programming - Rob Pike](http://users.ece.utexas.edu/~adnan/pike.html)
- [Transformers from scratch - Peter Bloem](http://peterbloem.nl/blog/transformers)
- [Understanding Matrix capsules with EM Routing - Jonathan Hui](https://jhui.github.io/2017/11/14/Matrix-Capsules-with-EM-routing-Capsule-Network/)
- [A Machine Learning Primer - Mihail Eric](https://www.confetti.ai/assets/ml-primer/ml_primer.pdf) -- A good read for beginners in machine learning algorithms.
- [Fitting Bayesian structural time series with the bsts R package - Steven L. Scott](http://www.unofficialgoogledatascience.com/2017/07/fitting-bayesian-structural-time-series.html)
- [Novelist Cormac McCarthy’s tips on how to write a great science paper - Savage and Yeh](https://www.nature.com/articles/d41586-019-02918-5)
- [Emerging Architectures for Modern Data Infrastructure - Matt Bornstein, Martin Casado, and Jennifer Li](https://a16z.com/2020/10/15/the-emerging-architectures-for-modern-data-infrastructure/) -- Gives a good overview of the data analysis tooling landscape as of late 2020.
- [What your data team is using: the analytics stack - Technically](https://technically.dev/) -- Another solid article to understand what an analytics stack looks like in 2021.
- [Fred's ImageMagick Scripts](http://www.fmwconcepts.com/imagemagick/index.php)
- [Unprojecting text with ellipses - Matt Zucker](https://mzucker.github.io/2016/10/11/unprojecting-text-with-ellipses.html) -- See also [this article on page dewarping](https://mzucker.github.io/2016/08/15/page-dewarping.html) by the same author.
- [The Log: What every software engineer should know about real-time data's unifying abstraction - Jay Kreps](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)
- [Language models, classification and dbacl - Laird A. Breyer](http://dbacl.sourceforge.net/tutorial.html) -- machine learning on text with a UNIX philosophy.
- [Cameras and Lenses - Bartosz Ciechanowski](https://ciechanow.ski/cameras-and-lenses/) -- 100% worth a read.
- [Ditherpunk - Surma](https://surma.dev/things/ditherpunk/)
- [Command-line Tools can be 235x Faster than your Hadoop Cluster - Adam Drake](https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html)
- [Teaching An Old Dog A New Trick - Chris Kamphuis](https://www.chriskamphuis.com/2019/03/06/teaching-an-old-dog-a-new-trick.html)
- [Git scraping, the five minute lightning talk - Simon Willison](https://simonwillison.net/2021/Mar/5/git-scraping/) -- I wish I had thought about this first!
## Eye candy

- [Tyler Hobbs](https://tylerxhobbs.com/) -- The god of generative arts.
- [Some Jean Giraud stuff](https://imgur.com/gallery/AZvIf)
- [Mauro Martins](https://www.mauromartins.com/)
- [A new way to knit by Petros Vrellis](http://artof01.com/vrellis/works/knit.html)
- [A fascinating article about Manolo Gamboa Naon](https://www.artnome.com/news/2018/8/8/generative-art-finds-its-prodigy)
- [Some Ukiyo-e](https://ukiyo-e.org/)
- [Turtletoy](https://turtletoy.net/)
- [Dwitter](https://www.dwitter.net/)
- [generated.space](https://generated.space/)
- [Pixel art by Marcus Blättermann](https://essenmitsosse.de/pixel/)
- [Nick Barnes' football bible](https://www.the42.ie/bbc-nick-barnes-football-notes-2111888-May2015/)
- [Simon Stålenhag](http://www.simonstalenhag.se/)
- [Syd Mead](https://www.iamag.co/the-art-of-syd-mead/) (who worked on Blade Runner)
- [Michael Fogleman's blog](https://www.michaelfogleman.com/)
- [World of Warcraft art by Dreamwalker](https://imgur.com/user/imadreamwalker/posts)
- [*Hors-sol* de AKOREACRO](https://www.artcena.fr/artcena-tv/hors-sol-de-akoreacro)
- [Erica Anderson](https://ericaofanderson.com/)
- [Jack Sharp](https://www.jacksharp.co.uk/)
- [Archillect](https://archillect.com/) -- An AI that curates cool pictures, how awesome is that?
- [Martin Kleppe](https://aem1k.com/)
- [Zoomquilt](https://zoomquilt.org/)
- [lossfunctions.tumblr.com](https://lossfunctions.tumblr.com/) -- Yes, that's a thing.
